<!DOCTYPE html>

<html lang="zh">
    <head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <!--
        © SukkaW
        GitHub: https://github.com/SukkaW/hexo-theme-suka
        Version: 1.3.2
    -->
    <script>
window.lsVersion = "1.3.2",
window.oldVersion = [
    
        
            "0.2.0","0.0.1","0.1.0","1.0.0","1.0.1","1.1.0","1.1.1","1.2.0","1.3.0"
        
    
]
</script>

    <!-- ### DNS Prefetch ### -->
    <meta http-equiv="x-dns-prefetch-control" content="on">
<!-- busuanzi -->

    <link rel="dns-prefetch" href="//busuanzi.ibruce.info">


<!-- comment -->







<!-- analytics -->








    <!-- ### Preload ### -->
    
    <!-- Busuanzi -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/busuanzi@2.3.0/bsz.pure.mini.js" as="script">







    <!-- ### Meta & Title & Info ### -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge, chrome=1">
<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">

<!-- Title -->
<title>GAN:Generative Adversarial Nets阅读笔记 | 幻华&#39;s Blog</title>

<!-- favicon -->
<!-- Favicons -->

    <link rel="shortcut icon" type="image/ico" href="/img/cbhq3-nfw26-006.ico">






<!-- Android Chrome Color -->



<meta name="format-detection" content="telephone=no">

<!-- Description -->
<meta name="description" content="

1. Generative Adversarial Nets
">

<!-- Keywords -->
<meta name="keywords" content=", 深度学习, 论文阅读">

<!-- Disable Fucking Bloody Baidu Tranformation -->
<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

    <!-- ### Import File ### -->
    
        <!-- spectre.css -->

    <link rel="stylesheet" href="/lib/spectre/spectre.min.css">


<style>
    body {
        background-color: #f8f9fa;
    }

    a, a:visited {
        color: #0070ff;
    }

    a:active, a:focus, a:hover {
        color: #0070ff;
        opacity: .75;
    }

    #post-content a,
    #post-content a:hover,
    #post-content a:focus,
    #post-content a:visited {
        color: #005eb9;
        opacity: 1;
    }

    .post-entry .card-body a {
        color: #0070ff;
    }

    .avatar {
        background: #444;
    }

    .navbar-link,
    .navbar-link:visited,
    .timeline .timeline-item .timeline-icon.icon-lg {
        color: #0070ff;
    }

    .navbar-link:hover {
        color: #0070ff;
        opacity: .8;
    }

    #search-input .btn,
    #disqus_click_btn,
    #disqus-switch-to-direct,
    #disqus-loadmore-button {
        background: #727e96;
        border-color: #727e96;
        color: #fff;
    }

    #post-toc a.post-toc-link,
    #post-toc a.post-toc-link:visited,
    .share-menu.menu .menu-item>a {
        color: #727e96;
    }

    .share-menu.menu .menu-item>a:hover,
    .share-menu.menu .menu-item>a:focus,
    .share-menu.menu .menu-item>a:visited {
        color: #50596c;
        background: #f8f9fa;
        opacity: .85;
    }
</style>

<!-- style.css -->

    <link rel="stylesheet" href="/css/style.min.css">









    <!-- Prettify Theme -->
    
    
        <link rel="stylesheet" href="/css/highlight/github.min.css">
    



    

    <!-- ### Site Verification ### -->
    


    <!-- ### RSS ### -->
    
    
        <link rel="alternate" type="application/atom+xml" href="/atom.xml">
    


    <!-- ### WebApp ### -->
    <meta name="mobile-web-app-capable" content="yes">
<meta name="application-name" content="幻华&#39;s Blog">
<meta name="msapplication-starturl" content="http://www.zkhweb.top">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="幻华&#39;s Blog">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<!-- Manifest Import -->

<!-- Open Search -->


    <!-- ### The Open Graph & Twitter Card Protocol ### -->
    <meta property="og:title" content="GAN:Generative Adversarial Nets阅读笔记 | 幻华&#39;s Blog">
<meta property="og:site_name" content="幻华&#39;s Blog">

<meta property="og:locale" content="zh">

<meta property="og:url" content="http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/">
<meta property="og:image" content="http://www.zkhweb.top/img/cbhq3-nfw26-006.ico">

<meta property="og:description" content="

1. Generative Adversarial Nets
">

<meta name="twitter:card" content="summary">


    <meta property="og:type" content="article">
    <meta property="article:published_time" content="2020-02-05T03:14:42.000Z">
    <meta property="article:modified_time" content="2020-02-05T03:14:42.000Z">
    <meta property="article:author" content="幻华(Zkher)">
    <meta property="og:article:tag" content=", 深度学习, 论文阅读"> 





    <!-- ### Analytics ### -->
    








    <!-- ### Canonical link ### -->
    <link rel="canonical" href="http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/">

    <!-- ### Structured Data ### -->
    



<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "url": "http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/",
    "@type": "BlogPosting",
    "logo": "http://www.zkhweb.top/img/cbhq3-nfw26-006.ico",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/"
    },
    "headline": "GAN:Generative Adversarial Nets阅读笔记 | 幻华&#39;s Blog",
    
    "image": {
        "@type": "ImageObject",
        "url": "http://www.zkhweb.top/img/cbhq3-nfw26-006.ico"
    },
    
    "datePublished": "2020-02-05T03:14:42.000Z",
    "dateModified": "2020-02-12T15:20:54.936Z",
    "author": {
        "@type": "Person",
        "name": "幻华(Zkher)",
        "image": {
            "@type": "ImageObject",
            "url": "http://www.zkhweb.top/img/my.jpg"
        },
        "description": "Hi, nice to meet you."
    },
    "publisher": {
        "@type": "Organization",
        "name": "幻华&#39;s Blog",
        "logo": {
            "@type": "ImageObject",
            "url": "http://www.zkhweb.top/img/cbhq3-nfw26-006.ico"
        }
    },
    
    "potentialAction": {
        "@type": "SearchAction",
        "target": "http://www.zkhweb.top/search/?s={search_term_string}",
        "query-input": "required name=search_term_string"
    },
    
    "keywords": ", 深度学习, 论文阅读",
    "description": "

1. Generative Adversarial Nets
"
}
</script>



    <!-- ### Custom Head ### --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    


</head>

    <body>
        

            

            <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- ### Main content ### -->
            <!-- ## Header ##-->
<header>
    <h1 class="header-title text-center"><a href="/">幻华&#39;s Blog</a></h1>

    <p class="text-center header-slogan">
        
            
                Hi, nice to meet you.
            
        
    </p>

    <nav class="navbar-section text-center">
    
        <a href="/" class="navbar-link">首页</a>
    
    
        <a href="/archives/" class="navbar-link">归档</a>
    
    
        <a href="/search/" class="navbar-link">搜索</a>
    
    
        <a href="/about/" class="navbar-link">关于</a>
    
        <a href="/tag/" class="navbar-link">标签</a>
    
        <a href="/gallery/" class="navbar-link">画廊</a>
    
        <a href="/links/" class="navbar-link">友链</a>
    
        <a href="/en/" class="navbar-link">英语</a>
    
    
        <div class="dropdown dropdown-right">
    <a class="navbar-link dropdown-toggle" tabindex="0">分享</a>
    <ul class="menu share-menu">

        <!-- Share Weibo -->
        
        <li class="menu-item">
            <a href="http://service.weibo.com/share/share.php?appkey=&title=幻华's Blog&url=http://www.zkhweb.top&pic=http://www.zkhweb.top/img/cbhq3-nfw26-006.ico&searchPic=false&style=simple" target="_blank" rel="noopener noreferrer nofollow">分享到微博</a>
        </li>
        

        <!-- Share Twitter -->
        
        <li class="menu-item">
            <a href="https://twitter.com/intent/tweet?text=幻华's Blog&url=http://www.zkhweb.top&via=幻华(Zkher)" target="_blank" rel="noopener noreferrer nofollow">分享到 Twitter</a>
        </li>
        

        <!-- Share Facebook -->
        
        <li class="menu-item">
            <a href="https://www.facebook.com/sharer/sharer.php?u=http://www.zkhweb.top" target="_blank" rel="noopener noreferrer nofollow">分享到 Facebook</a>
        </li>
        

        <!-- Share Google+ -->
        
        <li class="menu-item">
            <a href="https://plus.google.com/share?url=http://www.zkhweb.top" target="_blank" rel="noopener noreferrer nofollow">分享到 Google+</a>
        </li>
        

        <!-- Share LinkedIn -->
        
        <li class="menu-item">
            <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://www.zkhweb.top&title=GAN:Generative Adversarial Nets阅读笔记" target="_blank" rel="noopener noreferrer nofollow">分享到 LinkedIn</a>
        </li>
        

        <!-- Share QQ -->
        
        <li class="menu-item">
            <a href="http://connect.qq.com/widget/shareqq/index.html?site=幻华's Blog&title=GAN:Generative Adversarial Nets阅读笔记&summary=&pics=http://www.zkhweb.top/img/cbhq3-nfw26-006.ico&url=http://www.zkhweb.top" target="_blank" rel="noopener noreferrer nofollow"> 分享到 QQ</a>
        </li>
        

        <!-- Share Telegram -->
        
        <li class="menu-item">
            <a href="https://t.me/share/url?url=http://www.zkhweb.top&text=GAN:Generative Adversarial Nets阅读笔记" target="_blank" rel="noopener noreferrer nofollow">分享到 Telegram</a>
        </li>
        

        <!-- QRCode -->
        
        <li class="menu-item">
            <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKQAAACkCAAAAAA83tqdAAACLElEQVR42u2aQW7DMAwE8/9Pt9cisHeHRoIm5uhStFHNERDRyyUfP1+wHkIKKaSQHwD5COv586P9f/92tP/5cxpXyN2Qh1/apyAt4Bng0R4cV8jVkEeXIV2K+IUvl4rEFVLIuBkk+LOLlQ4ipJBXIc/2tmScEryQQl4VGC1pTw7wNhUk5O0gWyH2rp8vrRaFvA0kNo+AcEgvg1SkvcxVE/IWkO2hSdQ2uPTM9DIQcjckCd7EBSnW0vPOxImQOyGb4d6Sd0v05BDjQkzI20OSf0jG/jR5kzhC7oUkDaME2wquibhAAkPI20OSxEyKs2aUvkRgCLkCkiTtS+JgYB5UgSHkKshWPJGhEdLwpIVfVEFCroEkTaGpOKCmahQhQq6FJANME/j2EsCGgpBrIVOinjSdiFnQDiukkC3pNgFLf6dGwalhJeQayCtBkWANAgJfNCHXQhJBMAVP+9rLQkghafE+ad5T8YwNKyHXQJJGUAtGkjYx8oUUkl6G1iydDDqR4SYhhZw0NYnxenWgrk4OCLkCkgwSt4Z9A5kMQwkpZBMKTdSmJidtngop5NnFaYmZNEqnyTxeTCFXQrbVEjsRzK1xXxugQq6CpGYTMefTAVrjHiVzIddANmFADYQmOibDekIKORkiJsYoMVdHoldIIaFZ34qqapSmmEIKGRpLraiaJm7UyBJyNSQ1B9LFGhdaxfASci8kNZGaKUUbVVT4CrkT8pOXkEIKKeQ/rl/YC9dmo/QdgAAAAABJRU5ErkJggg==" alr="QRCode">
        </li>
        

    </ul>
</div>
    
    
        <a href="/atom.xml" target="_blank" class="navbar-link">RSS</a>
    
</nav>
</header>

            
    <!-- ## Post ## -->
    
    


<div class="post-container">
    <div id="post-card" class="card">
        
        <div class="card-item-container">
            <div class="card-inner-cell">
                <!-- # Post Header Info # -->
                <div class="card-header">
                    
    <h1 class="card-title h3 mb-2">GAN:Generative Adversarial Nets阅读笔记</h1>




<div class="post-header-info">
    <p class="post-header-info-left text-gray">
        <img class="author-thumb lazyload" data-src="/img/my.jpg" src="/img/suka-lazyload.gif" alt="幻华(Zkher)'s Avatar">
        <span>2020-02-05</span>
        
            <span class="suka-devide-dot"></span>
            <a class="category-link" href="/categories/深度学习论文阅读/">深度学习论文阅读</a>
        
        
            <!-- Busuanzi Post Views -->
<span id="busuanzi_container_page_pv" hidden>
    <span class="suka-devide-dot"></span>
    <span></span>
    <span id="busuanzi_value_page_pv"></span>
    <span>Views</span>
</span>
        
        
    </p>
    <div class="post-header-info-right">
        
            <div class="dropdown dropdown-right">
<a class="dropdown-toggle" tabindex="0">分享本文</a>
<ul class="menu share-menu">
    <!-- Share Weibo -->
    
    <li class="menu-item">
        <a href="http://service.weibo.com/share/share.php?appkey=&title=GAN:Generative Adversarial Nets阅读笔记&url=http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/&pic=http://www.zkhweb.top/img/cbhq3-nfw26-006.ico&searchPic=false&style=simple" target="_blank" rel="noopener noreferrer nofollow">分享到微博</a>
    </li>
    

    <!-- Share Twitter -->
    
    <li class="menu-item">
        <a href="https://twitter.com/intent/tweet?text=GAN:Generative Adversarial Nets阅读笔记&url=http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/&via=幻华(Zkher)" target="_blank" rel="noopener noreferrer nofollow">分享到 Twitter</a>
    </li>
    

    <!-- Share Facebook -->
    
    <li class="menu-item">
        <a href="https://www.facebook.com/sharer/sharer.php?u=http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/" target="_blank" rel="noopener noreferrer nofollow">分享到 Facebook</a>
    </li>
    

    <!-- Share Google+ -->
    
    <li class="menu-item">
        <a href="https://plus.google.com/share?url=http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/" target="_blank" rel="noopener noreferrer nofollow">分享到 Google+</a>
    </li>
    

    <!-- Share LinkedIn -->
    
    <li class="menu-item">
        <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/&title=幻华's Blog" target="_blank" rel="noopener noreferrer nofollow">分享到 LinkedIn</a>
    </li>
    

    <!-- Share QQ -->
    
    <li class="menu-item">
        <a href="http://connect.qq.com/widget/shareqq/index.html?site=幻华's Blog&title=幻华's Blog&summary=&pics=http://www.zkhweb.top/img/cbhq3-nfw26-006.ico&url=http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/" target="_blank" rel="noopener noreferrer nofollow"> 分享到 QQ</a>
    </li>
    

    <!-- Share Telegram -->
    
    <li class="menu-item">
        <a href="https://t.me/share/url?url=http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/&text=幻华's Blog" target="_blank" rel="noopener noreferrer nofollow">分享到 Telegram</a>
    </li>
    

    <!-- QRCode -->
    
    <li class="menu-item">
        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKQAAACkCAAAAAA83tqdAAACLElEQVR42u2aQW7DMAwE8/9Pt9cisHeHRoIm5uhStFHNERDRyyUfP1+wHkIKKaSQHwD5COv586P9f/92tP/5cxpXyN2Qh1/apyAt4Bng0R4cV8jVkEeXIV2K+IUvl4rEFVLIuBkk+LOLlQ4ipJBXIc/2tmScEryQQl4VGC1pTw7wNhUk5O0gWyH2rp8vrRaFvA0kNo+AcEgvg1SkvcxVE/IWkO2hSdQ2uPTM9DIQcjckCd7EBSnW0vPOxImQOyGb4d6Sd0v05BDjQkzI20OSf0jG/jR5kzhC7oUkDaME2wquibhAAkPI20OSxEyKs2aUvkRgCLkCkiTtS+JgYB5UgSHkKshWPJGhEdLwpIVfVEFCroEkTaGpOKCmahQhQq6FJANME/j2EsCGgpBrIVOinjSdiFnQDiukkC3pNgFLf6dGwalhJeQayCtBkWANAgJfNCHXQhJBMAVP+9rLQkghafE+ad5T8YwNKyHXQJJGUAtGkjYx8oUUkl6G1iydDDqR4SYhhZw0NYnxenWgrk4OCLkCkgwSt4Z9A5kMQwkpZBMKTdSmJidtngop5NnFaYmZNEqnyTxeTCFXQrbVEjsRzK1xXxugQq6CpGYTMefTAVrjHiVzIddANmFADYQmOibDekIKORkiJsYoMVdHoldIIaFZ34qqapSmmEIKGRpLraiaJm7UyBJyNSQ1B9LFGhdaxfASci8kNZGaKUUbVVT4CrkT8pOXkEIKKeQ/rl/YC9dmo/QdgAAAAABJRU5ErkJggg==" alt="QRCode">
    </li>
    

</ul>
</div>
        
    </div>
</div>
                </div>
                <div class="card-body">
                    
                        
                            <div id="post-toc">
                                <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.</span> <span class="post-toc-text">1. Generative Adversarial Nets</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">1.1. 摘要</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">1.2. 介绍</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">1.3. 对抗网络</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.3.1.</span> <span class="post-toc-text">1.3.1. 符号定义</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.3.2.</span> <span class="post-toc-text">1.3.2. 极大似然估计</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.3.3.</span> <span class="post-toc-text">1.3.3. 目标函数</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.3.4.</span> <span class="post-toc-text">1.3.4. 对抗</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.3.5.</span> <span class="post-toc-text">1.3.5. Loss Function</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.3.6.</span> <span class="post-toc-text">1.3.6. 具体算法过程</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.4.</span> <span class="post-toc-text">1.4. 改进</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.4.1.</span> <span class="post-toc-text">1.4.1. G替代版的Loss Function</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.5.</span> <span class="post-toc-text">1.5. 补充知识</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.5.1.</span> <span class="post-toc-text">1.5.1. 信息量</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.5.2.</span> <span class="post-toc-text">1.5.2. 信息熵</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.5.3.</span> <span class="post-toc-text">1.5.3. 交叉熵</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.5.4.</span> <span class="post-toc-text">1.5.4. KL散度(Kullback–Leibler散度，相对熵)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.5.5.</span> <span class="post-toc-text">1.5.5. JS散度(Jensen-Shannon散度)</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.6.</span> <span class="post-toc-text">1.6. 理论结果</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.6.1.</span> <span class="post-toc-text">1.6.1. 最优判别器D：$D^{*}(x) =\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}$</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.6.2.</span> <span class="post-toc-text">1.6.2. 最优生成器：$p_{g}=p_{\text {data }}$</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.6.3.</span> <span class="post-toc-text">1.6.3. 定理1：全局最优</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.6.4.</span> <span class="post-toc-text">1.6.4. 算法的收敛性</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.7.</span> <span class="post-toc-text">1.7. 优势和劣势</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.7.1.</span> <span class="post-toc-text">1.7.1. 优势</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.7.2.</span> <span class="post-toc-text">1.7.2. 劣势</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.8.</span> <span class="post-toc-text">1.8. 结论和未来研究方向</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#undefined"><span class="post-toc-number">1.9.</span> <span class="post-toc-text">1.9. 参考资料</span></a></li></ol></li></ol>
                            </div>
                        
                    
                    <article id="post-content">
                        <!-- toc -->
<ul>
<li><a href="#1-generative-adversarial-nets">1. Generative Adversarial Nets</a><ul>
<li><a href="#11-摘要">1.1. 摘要</a></li>
<li><a href="#12-介绍">1.2. 介绍</a></li>
<li><a href="#13-对抗网络">1.3. 对抗网络</a><ul>
<li><a href="#131-符号定义">1.3.1. 符号定义</a></li>
<li><a href="#132-极大似然估计">1.3.2. 极大似然估计</a></li>
<li><a href="#133-目标函数">1.3.3. 目标函数</a></li>
<li><a href="#134-对抗">1.3.4. 对抗</a></li>
<li><a href="#135-loss-function">1.3.5. Loss Function</a></li>
<li><a href="#136-具体算法过程">1.3.6. 具体算法过程</a></li>
</ul>
</li>
<li><a href="#14-改进">1.4. 改进</a><ul>
<li><a href="#141-g替代版的loss-function">1.4.1. G替代版的Loss Function</a></li>
</ul>
</li>
<li><a href="#15-补充知识">1.5. 补充知识</a><ul>
<li><a href="#151-信息量">1.5.1. 信息量</a></li>
<li><a href="#152-信息熵">1.5.2. 信息熵</a></li>
<li><a href="#153-交叉熵">1.5.3. 交叉熵</a></li>
<li><a href="#154-kl散度kullbackleibler散度相对熵">1.5.4. KL散度(Kullback–Leibler散度，相对熵)</a></li>
<li><a href="#155-js散度jensen-shannon散度">1.5.5. JS散度(Jensen-Shannon散度)</a></li>
</ul>
</li>
<li><a href="#16-理论结果">1.6. 理论结果</a><ul>
<li><a href="#161-最优判别器ddx-fracp_text-dataxp_text-dataxp_gx">1.6.1. 最优判别器D：$D^{*}(x) =\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}$</a></li>
<li><a href="#162-最优生成器p_gp_text-data">1.6.2. 最优生成器：$p_{g}=p_{\text {data }}$</a></li>
<li><a href="#163-定理1全局最优">1.6.3. 定理1：全局最优</a></li>
<li><a href="#164-算法的收敛性">1.6.4. 算法的收敛性</a></li>
</ul>
</li>
<li><a href="#17-优势和劣势">1.7. 优势和劣势</a><ul>
<li><a href="#171-优势">1.7.1. 优势</a></li>
<li><a href="#172-劣势">1.7.2. 劣势</a></li>
</ul>
</li>
<li><a href="#18-结论和未来研究方向">1.8. 结论和未来研究方向</a></li>
<li><a href="#19-参考资料">1.9. 参考资料</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<hr>
<h1><span id="1-generative-adversarial-nets">1. Generative Adversarial Nets</span></h1><blockquote>
<p>arXiv:1406.2661 [stat.ML]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p>
</blockquote>
<hr>
<h2><span id="11-摘要">1.1. 摘要</span></h2><p>通过对抗过程估计生成模型的框架，同时训练两个模型：<br><strong>生成模型G</strong>用来获取数据分布<br><strong>判别模型D</strong>估计样本来自训练数据而不是G的概率<br>G的训练目标是为了最大化D产生错误的概率<br>在任意函数G和D的空间中存在唯一的解，其中G恢复训练数据分布，并且D处处都等于$\frac{1}{2}$。</p>
<hr>
<h2><span id="12-介绍">1.2. 介绍</span></h2><p>最成功的的模型之一就是<strong>判别式模型</strong><br>通常它们将高维丰富的感知器输入映射到类标签上。<br>主要是<strong>基于反向传播和丢弃算法</strong>来实现的，特别是具有特别良好梯度的分段线性单元。</p>
<p>对抗网络</p>
<ol>
<li>生成模型通过将随机噪声传输到多层感知机来生成样本的特例</li>
<li>判别模型通过多层感知机去判别一个样本是来自模型分布还是数据分布</li>
<li>生成模型和判别模型互相对抗</li>
</ol>
<p>可以仅使用非常成熟的反向传播和丢弃算法训练两个模型，生成模型在生成样本时只使用前向传播算法。并且不需要近似推理和马尔可夫链作为前提。</p>
<hr>
<h2><span id="13-对抗网络">1.3. 对抗网络</span></h2><p>对抗模型框架是最直接的应用是多层感知机</p>
<h3><span id="131-符号定义">1.3.1. 符号定义</span></h3><p>$x$ $\rightarrow$ 真实数据<br>$z$ $\rightarrow$ 噪音（生成器的输入数据）<br>$p_x$ $\rightarrow$ 真实数据的分布<br>$p_{z}(z)$ $\rightarrow$ 原始噪音数据的分布<br>$p_g$ $\rightarrow$ 经过生成器后数据的分布<br>$G()$ $\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\theta_{g}$<br>$D()$ $\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\theta_{d}$<br>$G(z;\theta_{g})$ $\rightarrow$ 将噪音$z$映射到新的数据空间<br>$D(x ; \theta_{d})$ $\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）</p>
<h3><span id="132-极大似然估计">1.3.2. 极大似然估计</span></h3><p>对于真实数据$x$和生成数据$G(z)$，经过判别器判别后的，$D$认为$x$是真样本的概率为$D(x)$，$D$认为$G(z)$是假样本的概率为$1-D(G(z))$，那么对于$D$有$log$似然函数为：</p>
<script type="math/tex; mode=display">L=log[D(x)*(1-D(G(z)))] \tag{1}</script><h3><span id="133-目标函数">1.3.3. 目标函数</span></h3><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] \tag{2}</script><p>$D(x)$和$D(G(z))$分别表示$x$和$G(z)$经过判别器$D$的判别后，$D$认为输入样本是真样本的概率，则$1-D(G(z))$表示$D$将假样本判断为假的概率；那么，真实的概率分布与$D$判断出来的情况列表如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">$D$</th>
<th style="text-align:center">$D$将真样本$x$判断为真的概率:$D(x)$</th>
<th style="text-align:center">$D$将假样本$G(z)$判断为假的概率:$1-D(G(z))$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">真实情况</td>
<td style="text-align:center">真样本$x$为真的概率:1</td>
<td style="text-align:center">假样本$G(z)$为假的概率:1</td>
</tr>
<tr>
<td style="text-align:center">用交叉熵作为目标函数</td>
<td style="text-align:center">$1*log[D(x)]对应第一项$</td>
<td style="text-align:center">$1*log[1-D(G(z))]$对应第二项</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Note:$D$输出的是概率，那么$D$的输出层的激活函数必须是$sigmoid$</strong></p>
<h3><span id="134-对抗">1.3.4. 对抗</span></h3><p>判别器$D$的目标</p>
<ol>
<li>要尽可能把真的样本判断为真，对应最大化第一项：${ E }_{ x ～ { p }_  { data } (x) }[logD(x)]$</li>
<li>把假的样本判断为假，对应最大化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $</li>
</ol>
<ul>
<li>总之，也就是说<strong>判别器$D$要最大化目标函数</strong>；</li>
</ul>
<p>生成器$G$的目标</p>
<ol>
<li>要尽可能的让$D$将生成的假样本判断为真，对应最小化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $</li>
</ol>
<ul>
<li>总之，也就是说<strong>生成器$G$要最小化目标函数</strong>；</li>
</ul>
<p>总的来说，这是一个<strong>MinMax Game</strong>；<br><strong>Note:实际训练当中，训练$G$的时候$D$的参数是固定的，$G$并不干扰$D$对真实数据的判断，$G$需要$D$的正确引导，$G$只是不断提升自己生成数据的能力。</strong></p>
<h3><span id="135-loss-function">1.3.5. Loss Function</span></h3><p>$D$的损失函数（最小化）：</p>
<script type="math/tex; mode=display">Loss_D = -[1*logD(x) + 1*log(1-D(G(z)))] \tag{3}</script><p>$G$的损失函数（最小化）：</p>
<script type="math/tex; mode=display">Loss_G = 0*logD(x) + 1*log(1-D(G(z)))=log(1-D(G(z))) \tag{4}</script><h3><span id="136-具体算法过程">1.3.6. 具体算法过程</span></h3><p><img src="https://image.zkhweb.top/20190816181118.png" alt="20190816181118.png"></p>
<p>Note：</p>
<ol>
<li>生成对抗网络的minibatch随机梯度下降训练 </li>
<li>先更新$D$，再更新$G$，只有$D$有了正确的判断能力，$G$才能按照$D$的指示来更新;</li>
<li>可以设置一个超参数k来协调$D$、$G$两者之间更新的次数比例，在实验中k=1，使消耗最小;</li>
<li>在训练$G$的时候$D$的参数要固定，在训练$D$的时候$G$的参数要固定;</li>
</ol>
<hr>
<h2><span id="14-改进">1.4. 改进</span></h2><h3><span id="141-g替代版的loss-function">1.4.1. G替代版的Loss Function</span></h3><p>由于$G(z)$是从噪声中生成的样本，所以在最开始$G$生成的样本非常假，很容易被$D$抓出来，也就是说$D(G(z))$非常小,那么$Loss_G = log(1-D(G(z)))$就非常接近0，在反向传播的时候就不能够传播足够的梯度给$G$来更新参数，所以我们从Heuristic的角度来理解：我们本身是要最小化$D$抓出来假样本的概率，现在我们可以换成最大化$D$抓不出来的概率（$\log D(G(z))$），也就是将$G$的损失函数换成：</p>
<script type="math/tex; mode=display">Loss_G=-logD(G(z))</script><p>由于$D$是按照：</p>
<script type="math/tex; mode=display">Loss_G = log(1-D(G(z)))</script><p>训练的，那么如果损失函数更换，这两项不是等价的，所以$D$给出的值就能够提供足够的梯度。</p>
<p><strong>Note:<br>$Loss_G =log(1-D(G(z)))$对应的GAN叫做MMGAN<br>$Loss_G=-logD(G(z)) $对应的GAN叫做NSGAN<br>改进后的仍然存在些许问题，见与<a href="#1">定理1：全局最优的Note3</a></strong></p>
<p>从函数图像上，可以直观的看出，两种损失函数的梯度变化趋势：<br><img src="https://image.zkhweb.top/损失函数图像" alt="损失函数图像"></p>
<hr>
<h2><span id="15-补充知识">1.5. 补充知识</span></h2><h3><span id="151-信息量">1.5.1. 信息量</span></h3><p>$ I(x) = -\log {p(x)} = \log { \frac { 1}{ p (x) }  } $<br>一个事件发生的概率越大，这件事情发生所包含的信息量就越小，比如说一个高富帅追求一个白富美，追到手了没有什么稀奇的，因为这是一件概率很高的事情，但是如果一个矮穷矬追求一个白富美，追到手了，这种事情发生的概率很低，其中一定有其他的原因：比如这个矮穷矬救过白富美的命或者这个矮穷矬器大活好不黏人，所以概率低的事情发生所包含的信息量大；两个相互独立的事情同时发生的信息量是两者单独发生的信息量之和。</p>
<h3><span id="152-信息熵">1.5.2. 信息熵</span></h3><p>信息量的均值</p>
<script type="math/tex; mode=display">H(x) = - \sum _{ x } p(x)log p(x)</script><h3><span id="153-交叉熵">1.5.3. 交叉熵</span></h3><script type="math/tex; mode=display">H(P, Q) = - \sum _{ x } p(x)log q(x)</script><p>用估计编码$q(x)$近似真实编码$p(x)$需要的平均编码长度</p>
<h3><span id="154-kl散度kullbackleibler散度相对熵">1.5.4. KL散度(Kullback–Leibler散度，相对熵)</span></h3><p>统计中的一个概念，时衡量两种概率分布的相似程度，其越小，表示两种概率分布越接近。（当P(x)和Q(x)的相似度越高，KL散度越小）<br>对于离散的概率分布定义如下：</p>
<script type="math/tex; mode=display">D_{KL}(P||Q)=- \sum _{ x } p(x)log q(x) + \sum _{ x } p(x)log p(x) =H(P, Q)-H(P)</script><p>对于连续的概率分布定义如下：</p>
<script type="math/tex; mode=display">
D_{K L}(P \| Q)=\int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} d x</script><p>想要将一个随机高斯噪声$z$通过一个生成网络G得到一个和</p>
<ul>
<li>性质：<ol>
<li>不对称性<br>尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即$D(P||Q) \not= D(Q||P)$。</li>
<li>非负性<br>相对熵的值是非负值，即$D(P||Q)&gt;0$。</li>
</ol>
</li>
</ul>
<h3><span id="155-js散度jensen-shannon散度">1.5.5. JS散度(Jensen-Shannon散度)</span></h3><script type="math/tex; mode=display">D_{JS}(P||Q)={\frac{1}{2}} KL(P||M) + {\frac{1}{2}} KL(Q||M) \quad \quad M = {\frac{1}{2}}(P+Q)</script><ul>
<li>不同于KL主要又两方面：<ol>
<li>值域范围<br>JS散度的值域范围是[0,1]，相同则是0，相反为1。相较于KL，对相似度的判别更确切了。</li>
<li>对称性<br>即 JS(P||Q)=JS(Q||P)，从数学表达式中就可以看出。</li>
</ol>
</li>
</ul>
<hr>
<h2><span id="16-理论结果">1.6. 理论结果</span></h2><h3><span id="161-最优判别器ddx-fracp_text-dataxp_text-dataxp_gx">1.6.1. 最优判别器D：$D^{*}(x) =\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}$</span></h3><p>对于给定生成器G，最大化$V(D,G)$而得出最优判别器D。原论文中价值函数可写为在$x$上的积分，即将数学期望展开为积分形式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\max _{ D } V(D,G)&={ E }_{ x ～ { p }_  { data } (x) }[logD(x)] + { E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]\\
&=\int_{x} p_{d a t a}(x) \log D(x) \mathrm{d} x+\int_{z} p(z) \log (1-D(G(z))) \mathrm{d} z\\
&=\int_{x} p_{d a t a}(x) \log D(x)+p_{G}(x) \log (1-D(x)) \mathrm{d} x
\end{aligned}</script><p>取函数，求偏导数<br>（对于任意的$(a, b) \in \mathbb{R}^{2} \backslash\{0,0\}$,函数$y \rightarrow a \log (y)+b \log (1-y)$在$[0,1]$中的$\frac{a}{a+b}$处达到最大值）</p>
<script type="math/tex; mode=display">
\begin{aligned}
f(D) &=a \log (D)+b \log (1-D) \\
\frac{d f(D)}{d D}&= a \times \frac{1}{D}+b \times \frac{1}{1-D} \times(-1)=0 \\
a \times \frac{1}{D^{*}} &= b \times \frac{1}{1-D^{*}} \\
\Leftrightarrow a \times & (1-D^{*}) =b \times D^{*} & \\
\text{得到最优判别器}&{ D }^{ * }(x)：\\
D^{*}(x) &=\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}
\end{aligned}</script><h3><span id="162-最优生成器p_gp_text-data">1.6.2. 最优生成器：$p_{g}=p_{\text {data }}$</span></h3><p>我们知道对于$G$来说，最好的$G$是让：</p>
<script type="math/tex; mode=display">{ P }_{ r }(x) = { P }_{ g }(x)</script><p>此时，有：</p>
<script type="math/tex; mode=display">{ D }^{ * }(x)=1/2</script><p>也就是说最好的生成器使最好的判别器无法判别出来样本是生成样本还是真实样本。</p>
<h3><span id="163-定理1全局最优">1.6.3. 定理1：全局最优</span></h3><p><strong>定理1：当且仅当$p_{g}=p_{\text {data }}$时，$C(G)$达到全局最小。此时，$C(G)$的值为$−log4$。</strong><br>注意到，判别器$D$的训练目标可以看作为条件概率$P(Y=y | x)$的最大似然估计，当$y=1$时，x来自于$p_{\text {data }}$；当$y=0$时，$x$来自$p_{g}$。公式1中的极小化极大问题可以变形为： </p>
<script type="math/tex; mode=display">
\begin{aligned} C(G) &=\max _{D} V(G, D) \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}}\left[\log \left(1-D_{G}^{*}(G(\boldsymbol{z}))\right)\right] \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right] \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log \frac{p_{\text {data }}(\boldsymbol{x})}{P_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \frac{p_{g}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right] \\ &=\int_{x} p_{\text {data}}(x) \log \left(\frac{p_{\text {data}}(x)}{p_{\text {data}}(x)+p_{g}(x)}\right)+p_{g}(x) \log \left(\frac{p_{g}(x)}{p_{\text {data}}(x)+p_{g}(x)}\right) d x\\&=\int_{x} p_{d a t a}(x) \log \left(\frac{p_{d a t a}(x)}{\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\right)+p_{g}(x) \log \left(\frac{p_{g}(x)}{\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\right) d x-\log (4)\\
&=\underbrace{K L\left(p_{\text {data}}(x) \| \frac{p_{\text {data}}(x)+p_{g}(x)}{2}\right)}_{\geq 0}+\underbrace{K L\left(p_{g}(x) \| \frac{p_{\text {data}}(x)+p_{g}(x)}{2}\right)}_{\geq 0}-\log (4)\\&=2\underbrace{\cdot JSD(p_{data}\|p_{g})}_{\geq 0}-log(4)\\\min _{G} C(G)&=0+0-\log (4)=-\log (4)
\end{aligned}</script><p>当且仅当$p_{\text {data}}(x)=\frac{p_{\text {data}}(x)+p_{g}(x)}{2}$即$p_{g}=p_{\text {data }}$时成立，此时$C(G)$达到全局最小，$C(G)$的值为$−log4$。<br><strong>Note1</strong><br>$KL$散度：$KL({ P }_{ 1 }||{ P }_{ 2 })={ P }_{ 1 }\log { \frac { { P }_{ 1 } }{ { P }_{ 2 } }  } $<br>$JS$散度：$ JS({ P }_{ 1 }||{ P }_{ 2 })=\frac { 1 }{ 2 } KL({ P }_{ 1 }||\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } )+\frac { 1 }{ 2 } KL({ P }_{ 2 }||\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } ) $<br><strong>Note2（MMGAN）</strong>$Loss_G =log(1-D(G(z)))$<br>当判别器$D$最优的时候，生成器$G$是在减小真实分布与生成分布之间的$JS$散度<br><strong><span id="1">Note3（NSGAN）</span></strong>$Loss_G=-logD(G(z)) $ </p>
<script type="math/tex; mode=display">\begin{aligned}
KL({ P }_{ g }(x)||{ P }_{ r }(x))
&={ P }_{ g }(x)*\log { \frac { { P }_{ g }(x) }{ { P }_{ r }(x) }  } \\ 
&={ P }_{ g }(x)*\log { \frac { { P }_{ g }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }{ { P }_{ r }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }  } \\ 
&={ P }_{ g }(x)*\log  \frac { 1-D^{ * }(x) }{ D^{ * }(x) } \\ 
&={ P }_{ g }(x)log[1-D^{ * }(x)]-{ P }_{ g }(x)logD^{ * }(x)\\
-{P}_{g}(x)*logD^*(x)&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\
Loss_{ G }&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\
\because {P}_{r}(x)*log[D^*(x)] &+ {P}_{g}(x)*log[1-D^*(x)]=2JS({ P }_{ r }||{ P }_{ g })-2log2\\
\therefore Loss_{ G }=KL({ P }_{ g }(&x)||{ P }_{ r }(x))-2JS({ P }_{ r }||{ P }_{ g })+{P}_{r}(x)*log[D^*(x)]+2log2[1-D^{ * }(x)]
\end{aligned}</script><p><strong>从上面的式子可以看出KL散度和JS散度同时存在且方向相反，而JS散度和KL散度都是衡量两个分布距离的度量，且是单调性同步的函数，这样的话就会导致梯度的方向不稳定，一会儿上升一会儿下降，所以这个替代版的损失函数也不是一个好的选择。</strong></p>
<h3><span id="164-算法的收敛性">1.6.4. 算法的收敛性</span></h3><p>**命题：如果$G$和$D$有足够的性能，对于算法1中的每一步，给定$G$时，判别器能够达到它的最优，并且通过更新$p_g$来提高这个判别准则。 </p>
<script type="math/tex; mode=display">\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right]</script><p>则$p_g$收敛为$p_{data}$。**</p>
<!-- 证明.如上述准则，考虑$V(G, D)=U\left(p_{g}, D\right)$为关于$p_{g}$的函数。注意到$U\left(p_{g}, D\right)$为$p_g$的凸函数。该凸函数上确界的一次导数包括达到最大值处的该函数的导数。换句话说，如果$f(x)=\sup _{\alpha \in \mathcal{A}} f_{\alpha}(x)$且对于每一个$α$，$f_α(x)$ 是关于$x$的凸函数，那么如果$\beta=\operatorname{argsup}_{\alpha \in \mathcal{A}} f_{\alpha}(x)$，则$\partial f_{\beta}(x) \in \partial f$。这等价于给定对应的$G$和最优的$D$，计算$p_g$的梯度更新。如定理1所证明，$\sup _{D} U\left(p_{g}, D\right)$是关于$p_g$的凸函数且有唯一的全局最优解，因此，当$p_g$的更新足够小时，$p_g$收敛到$p_x$，证毕。 -->
<p><strong>Note</strong><br>优化$θ_g$而不是$p_g$本身</p>
<hr>
<h2><span id="17-优势和劣势">1.7. 优势和劣势</span></h2><h3><span id="171-优势">1.7.1. 优势</span></h3><ul>
<li>根据实际的结果，它们看上去可以比其它模型产生了更好的样本（图像更锐利、清晰）。</li>
<li>生成对抗式网络框架能训练任何一种生成器网络（理论上-实践中，用 REINFORCE 来训练带有离散输出的生成网络非常困难）。大部分其他的框架需要该生成器网络有一些特定的函数形式，比如输出层是高斯的。重要的是所有其他的框架需要生成器网络遍布非零质量（non-zero mass）。生成对抗式网络能学习可以仅在与数据接近的细流形（thin manifold）上生成点。</li>
<li>不需要设计遵循任何种类的因式分解的模型，任何生成器网络和任何鉴别器都会有用。</li>
<li>无需利用马尔科夫链反复采样，无需在学习过程中进行推断（Inference），回避了近似计算棘手的概率的难题。</li>
</ul>
<h3><span id="172-劣势">1.7.2. 劣势</span></h3><ul>
<li><p>解决不收敛（non-convergence）的问题。<br>目前面临的基本问题是：所有的理论都认为 GAN 应该在纳什均衡（Nash equilibrium）上有卓越的表现，但梯度下降只有在凸函数的情况下才能保证实现纳什均衡。当博弈双方都由神经网络表示时，在没有实际达到均衡的情况下，让它们永远保持对自己策略的调整是可能的【OpenAI Ian Goodfellow的Quora】。</p>
</li>
<li><p>难以训练：崩溃问题（collapse problem）<br>GAN模型被定义为极小极大问题，没有损失函数，在训练过程中很难区分是否正在取得进展。GAN的学习过程可能发生崩溃问题（collapse problem），生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。<a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">Improved Techniques for Training GANs</a></p>
</li>
<li><p>无需预先建模，模型过于自由不可控。<br>与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，即不需要formulate p(x)，而是使用一种分布直接进行采样sampling，从而真正达到理论上可以完全逼近真实数据，这也是GAN最大的优势。然而，这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了(超高维)。在GAN[Goodfellow Ian, Pouget-Abadie J] 中，每次学习参数的更新过程，被设为D更新k回，G才更新1回，也是出于类似的考虑。</p>
</li>
</ul>
<hr>
<h2><span id="18-结论和未来研究方向">1.8. 结论和未来研究方向</span></h2><p>该框架允许许多直接的扩展：</p>
<ul>
<li>条件生成模型$p(x | c)$可以通过将$c$作为$G$和$D$的输入来获得。</li>
<li>给定$x$，可以通过训练一个任意的模型来学习近似推理，以预测$z$。这和wake-sleep算法训练出的推理网络类似，但是它具有一个优势，就是在生成器训练完成后，这个推理网络可以针对固定的生成器进行训练。</li>
<li>能够用来近似模型所有的条件概率$p\left(\boldsymbol{x}_{S} | \boldsymbol{x}_{\beta}\right)$，其中$S$通过训练共享参数的条件模型簇的关于$x$索引的一个子集。本质上，可以使用生成对抗网络来随机拓展MP-DBM。</li>
<li>半监督学习：当标签数据有限时，判别网络或推理网络的特征不会提高分类器效果。</li>
<li>效率改善：为协调$G$和$D$设计更好的方法，或训练期间确定更好的分布来采样$z$，能够极大的加速训练。</li>
</ul>
<hr>
<h2><span id="19-参考资料">1.9. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener">Paper—-Generative Adversarial Nets</a><br><a href="https://zhuanlan.zhihu.com/p/28853704" target="_blank" rel="noopener">知乎—-GAN入门理解及公式推导</a><br><a href="https://blog.csdn.net/stalbo/article/details/79283399" target="_blank" rel="noopener">CSDN—-GAN论文阅读——原始GAN（基本概念及理论推导）</a><br><a href="https://blog.csdn.net/FrankieHello/article/details/80614422" target="_blank" rel="noopener">CSDN—-KL散度、JS散度以及交叉熵对比</a><br><a href="https://blog.csdn.net/wspba/article/details/54582391" target="_blank" rel="noopener">CSDN—-Generative Adversarial Nets论文笔记+代码解析</a><br><a href="https://blog.csdn.net/wspba/article/details/54577236" target="_blank" rel="noopener">CSDN—-Generative Adversarial Nets（译）</a><br><a href="https://github.com/andyhujinzhao/Generative_Adversarial_Nets" target="_blank" rel="noopener">Github—-andyhujinzhao/Generative_Adversarial_Nets</a></p>
<hr>

                    </article>
                    
    <blockquote class="post-license">
        <p>
            <strong>本文作者&nbsp;:&nbsp;幻华(Zkher)</strong>
            <br>
            <strong>
            
                本文使用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0)</a> 协议
            </strong>
            <br>
            <strong>本文链接&nbsp;:&nbsp;</strong><a href="http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/">http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/</a>
        </p>
    </blockquote>



    <blockquote id="date-expire-notification" class="post-expired-notify">本文最后更新于 <span id="date-expire-num"></span> 天前，文中所描述的信息可能已发生改变</blockquote>
    <script>
        var dateUpdate = Date.parse("2020-02-12");
        var nowDate = new Date();
        var a = nowDate.getTime();
        var b = a - dateUpdate;
        var daysUpdateExpire = Math.floor(b/(24*3600*1000));
        if (daysUpdateExpire >= 120) {
            document.getElementById('date-expire-num').innerHTML = daysUpdateExpire;
        } else {
            document.getElementById('date-expire-notification').style.display = 'none';
        }
    </script>


<p class="post-footer-info mb-0 pt-0">本文发表于&nbsp;<time datetime="2020-02-05T03:14:42.000Z" itemprop="datePublished">2020-02-05</time>

    , 最后修改于&nbsp;<time datetime="2020-02-12T15:20:54.936Z" itemprop="dateModified">2020-02-12</time>

</p>
<p class="post-footer-info mb-0 pt-2">

<span class="post-categories-list mt-2">


<a class="post-categories-list-item" href="/categories/深度学习论文阅读/">深度学习论文阅读</a>

</span>



<span class="post-tags-list mt-2">


<a class="post-tags-list-item" href="/tags/深度学习/">#&nbsp;深度学习</a>

<a class="post-tags-list-item" href="/tags/论文阅读/">#&nbsp;论文阅读</a>

</span>


</p>

                </div>
                
<div class="post-nav px-2 bg-gray">
<ul class="pagination">
    <!-- Prev Nav -->
    
        <li class="page-item page-prev">
            <a href="/2020/02/07/bookmarklet/bookmarklet 发布/">
                <div class="page-item-title"><i class="icon icon-back" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">Maxout Networks阅读笔记</div>
            </a>
        </li>
    

    <!-- Next Nav -->
    
        <li class="page-item page-next">
            <a href="/2019/06/02/欢迎到我的博客= =（测试ing）/">
                <div class="page-item-title"><i class="icon icon-forward" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">欢迎到我的博客= =（测试ing）</div>
            </a>
        </li>
    
</ul>
</div>

                
                    <!-- # Comment # -->
                    
                
            </div>
        </div>
    </div>
</div>

            <!-- ### Footer ### -->
            <footer class="text-center">
    <!-- footer copyright -->
    <p class="footer-copyright mb-0">Copyright&nbsp;©&nbsp;<span data-year></span>
        <a class="footer-copyright-a" href="http://www.zkhweb.top">幻华&#39;s Blog</a>
        <a target="_blank" class="footer-develop-a">&nbsp;|</a>
        <img src="https://static.dy208.cn/o_1dfilp8ruo521thr1hvf18ji17soa.png">
        <a href="http://www.beian.miit.gov.cn/" style="color:#f72b07" target="_blank">京ICP备18049834号</a>
    </p>
    
    <!-- footer custom text -->
    <p class="footer-text mb-0">
    
    </p>
    <!-- footer develop info -->
    <p class="footer-develop mb-0">
        
            
    <!-- Busuanzi User Views -->
    <span id="busuanzi_container_site_uv" hidden>
        <span></span>
        <span id="busuanzi_value_site_uv"></span>
        <span>Viewers</span>
        
            <span>|</span>
        
    </span>


    <!-- Busuanzi Post Views -->
    <span id="busuanzi_container_site_pv" hidden>
        <span></span>
        <span id="busuanzi_value_site_pv"></span>
        <span>Views</span>
        
    </span>


        
        
        Powered by&nbsp;<!--
         --><a href="https://hexo.io" target="_blank" class="footer-develop-a" rel="nofollow noopener noreferrer">Hexo</a><span class="footer-develop-divider"></span>Theme&nbsp;-&nbsp;<!--
         --><a href="https://github.com/SukkaW/hexo-theme-suka" target="_blank" class="footer-develop-a" rel="noopener">Suka</a>
    </p>
</footer>

        

        <!-- ### Import File ### -->
        <!-- ### Footer JS Import ### -->

<script>
window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 50
};



    /* Copyright */
    var copyrightNow = new Date().getFullYear();
    var copyrightContent = document.querySelector('span[data-year]')
    
        copyrightContent.textContent = copyrightNow
    



/* Cnosole Log */
console.log('\n %c Suka Theme (hexo-theme-suka) | © SukkaW | Verision 1.3.2 %c https://github.com/SukkaW/hexo-theme-suka \n', 'color: #fff; background: #444; padding:5px 0;', 'background: #bbb; padding:5px 0;');
</script>

<!-- vanilla-lazyload -->

    <script src="/lib/vanilla-lazyload/lazyload.min.js" async></script>



    <!-- Busuanzi -->
    
    <script src="https://cdn.jsdelivr.net/npm/busuanzi@2.3.0/bsz.pure.mini.js" async></script>


<!-- Offset -->







<!-- gallery.js -->


<!-- Comment -->


<!-- ### Custom Footer ### -->


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>

</html>