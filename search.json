                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{"title":"Maxout Networks阅读笔记","date":"2020-02-07T03:14:42.000Z","url":"/2020/02/07/2013-Maxout_Networks/","tags":["深度学习","论文阅读"],"categories":["深度学习论文阅读"],"content":"Maxout Networks摘要介绍回顾droupt模型maxout描述Maxout是一个通用的近似器maxout与relu模型平均优化参考资料Maxout NetworksarXiv:1302.4389 [stat.ML]tensorflow2代码：摘要maxout：旨在通过dropout来加快优化过程，并提高准确度（与drop共同使用）；模型的输出是模型输入的最大值介绍dropout可以训练集成模型共享参数并近似的对这些模型的预测进行了平均一种不加区分的适用型工具，几乎可以应用于任何模型，都可以产生一定的性能改进。dropout与SDGdropout在更新时最有效的方式是使用更大的步长，因为这样可以在不同的训练子集上对不同的模型有明显的影响来使得目标函数有持续的波动性，理想情况下整个训练过程就类似于使用bagging来训练集成的模型（带有参数共享的约束）。SGD更新时一般会使用更小的步长，来使得目标函数平滑的下降。对于深度网络模型，dropout只能作为模型平均的一种近似，显式的设计模型来最小化这种近似误差也可以提高dropout的性能。回顾droupt在给定输入向量$v$后，输出预测向量$y$，该构成包含了一系列的隐含层$h=\\{h^{(1)},…,h^{(L)}\\}$。Dropout训练一组由包含$v$和$h$中变量的子集组成的所有模型组成的模型。使用同一组参数$\\theta$来标识一组分组$p(y | v ; \\theta, \\mu)$，其中$\\mu \\in M$是一个二进制掩码，用来决定模型中哪些变量参与运算。每次在训练集上进行训练时，我们都按照$\\log p(y | v ; \\theta, \\mu)$的梯度对不同的$\\mu$随机取样训练不同的子模型。可以通过$v$和$h$和掩码的按元素相乘得到不同子模型$p(y | v ; \\theta, \\mu)$的实例当集合需要将所有子模型的预测平均起来进行预测时，函数形式就变得非常重要。多个指数模型的预测平均值可以简单的通过运行权重除以2的完整模型来得到。即当$p(y|v;\\theta) = softmax(v^Tw+b)$时，通过重整$p(y|v;\\theta,\\mu)$的几何平均定义的预测分布，可以很简单的由$softmax(v^tw/2+b)$dropout与bagging都是在不同子集上训练出不同模型dropout只训练一次，且所有模型共享参数。像是在训练一个模型集合而不是训练单个模型，每次的更新都必须有重大的影响，这样才能使得该子模型能较好的拟合当前的输入$v$bagging对子模型的输出进行算数平均，dropout是几何平均模型maxout描述是一个简单的前馈框架模型使用了一个新的激活函数：maxout unit给定一个输入$ x \\in \\mathbb{R}^d$ （$x$可能是输入$v$,也可能是隐含层的状态），maxout隐含层的采用下式实现：h_{i}(x)=\\max _{j \\in[1, k]} z_{i j}其中$z_{i j}=x^{T} W_{\\ldots i j}+b_{i j}$，$x \\in \\mathbb{R}^{d \\times n}$，$W \\in \\mathbb{R}^{d \\times m \\times k}$, $b \\in \\mathbb{R}^{m \\times k}$。$w$，$b$都是可训练参数。$k$表示每个隐藏节点对应k个“隐隐层”节点，这$k$个“隐隐层”节点都是线性输出。maxout的每个节点就从这k个“隐隐层”节点输出值中取最大的。所以使得maxout为一种非线性的变换Notesmaxout因为有参数同时为非线性，所以既可以是网络也可以是激活器单个maxout单元可以解释为对任意凸函数进行线性逼近。（任意的凸函数都可由分段线性函数来拟合）。它在每处都是局部线性的（k个“隐隐层”节点都是线性的，取其最大值则为局部线性，分段的个数与k值有关），而一般的激活函数都有明显的曲率。如同MLP一样，maxout网络也可以拟合任意连续函数。只要maxout单元含有任意多个“隐隐层”节点，那么只要两个隐层的maxout网络就可以实现任意连续函数的近似。maxout网络不仅可以学习到隐层之间的关系，还可以学习到每个隐层单元的激活函数。maxout放弃了传统激活函数的设计，它产生的表示不再是稀疏的，但是它的梯度是稀疏的，且dropout可以将它稀疏化。maxout没有上下界，所以让它在某一端饱和是零概率事件。如果训练时使用dropout，则dropout操作在矩阵相乘之前，而并不对max操作的输入执行dropout。使用maxout会默认一个先验：样本集是凸集可分的。Maxout是一个通用的近似器命题1：对于任意的正整数$m$,$n$,都存在两组$n+1$维的实数参数向量$[W_{1j}, b_{1j}], j \\in [1, k]$和$[W_{2j}, b_{2j}], j \\in [1, k]$使得g(v) = h_1(v) - h_(v) 即任意的分段连续函数都可以使用两个凸分段线性函数的差来表示。命题2：根据Stone-Weierstrass近似定理，令$C$属于紧空间(compact domain)$C \\subset \\mathbb{R}^{n}$, 函数$f: C \\rightarrow \\mathbb{R}$是一个连续函数，一个正实数$\\epsilon&gt;0$。存在分段线性函数(PWL function)$g$，使得$v \\in C,|f(v)-g(v)|&lt;\\epsilon$(取决于$\\epsilon$)命题3：万能近似理论：任何连续函数$f$，在紧空间上都可以使用具有两个maxout单元的maxout网络近似。证明：命题2，一个分段线性函数可以尽可能近似（取决于$\\epsilon$）一个连续函数；命题1，一个分段线性函数的表示正好和一个maxout网络完全匹配，该maxout网络具有两个maxout单元$h_1(v)$和$h_2(v)$，且k足够大的，可以达到所需的近似程度$ \\epsilon$。综上所述，我们可以得出结论：一个具有两个maxout单元的maxout网络可以任意程度的逼近任何一个紧空间内的连续函数$f(v)$。通常情况下，近似程度越大（即$\\epsilon \\rightarrow 0$），k越大（即$ k \\rightarrow \\infty$）。maxout与relurelu表达式$h_{i}(x)=\\operatorname{relu}\\left(x^{T} W_{\\cdots i}+b_{i}\\right)=\\max \\left(x^{T} W_{\\cdots i}+b_{i}, 0\\right)$maxout表达式$h_{i}(x)=\\max _{j \\in[1, k]}\\left(x^{T} W \\ldots i j+b_{i j}\\right)$唯一区别relu使用的max(x,0)是对隐层每一个单元执行的与0比较最大化操作maxout是对$k$个“隐隐层”单元的值执行最大化操作(k为最大池化步长,max pooling stride。一般最大池化步长与k相等，如果步长小，则会有重叠最大池化)（一种实现方式2-4-1，maxout是对5个“隐隐层”单元的值执行最大化操作。如果将“隐隐层”单元在隐层展开，那么隐层就有20个“隐隐层”单元，maxout做的就是在这20个中每5个取一个最大值作为最后的隐层单元，最后的隐层单元仍然为4个。实现的时候，可以将隐层单元数设置为20个，权重维度（2，20）偏置维度（1，20），然后在20个中每5个取一个最大值得到4个隐层单元。）模型平均单层softmax有对模型进行平均的能力，但是通过观察，多层模型中使用dropout也存在这样的模型平均，只是有拟合精度的问题。训练中使用dropout使得maxout单元有了更大的输入附近的线性区域，因为每个子模型都要预测输出，每个maxout单元就要学习输出相同的预测而不管哪些输入被丢弃。改变dropout mask将经常明显移动有效输入，从而决定了输入被映射到分段线性函数的哪一段。使用dropout训练的maxout具有一种特性，即当dropout mask改变时每个maxout单元的最大化滤波器相对很少变化。maxout网络中的线性和最大化操作可以让dropout的拟合模型平均的精度很高。而一般的激活函数几乎处处都是弯曲的，因而dropout的拟合模型平均的精度不高。优化训练中使用dropout时，maxout的优化性能比relu+max pooling好dropout使用更大的步长最有效，使得目标函数有持续的波动性。而一般的SGD会使用更小的步长，来使得目标函数平滑的下降。dropout快速的探索着许多不同的方向然后拒绝那些损害性能的方向，而SGD缓慢而平稳的朝向最可能的方向移动。实验中SGD使得relu饱和在0值的时间少于5%，而dropout则超过60%。由于relu激活函数中的0值是一个常数，这就会阻止梯度在这些单元上传播（无论正向还是反向），这也就使得这些单元很难再次激活，这会导致很多单元由激活转变为非激活。而maxout就不会存在这样的问题，梯度在maxout单元上总是能够传播，即使maxout出现了0值，但是这些0值是参数的函数可以被改变，从而maxout单元总是激活的。单元中较高比例的且不易改变的0值会损害优化性能。dropout要求梯度随着dropout mask的改变而明显改变，而一旦梯度几乎不随着dropout mask的改变而改变时，dropout就简化成为了SGD。relu网络的低层部分会有梯度衰减的问题（梯度的方差在高层较大而反向传播到低层后较小）。maxout更好的将变化的信息反向传播到低层并帮助dropout以类似bagging的方式训练低层参数。relu则由于饱和使得梯度损失，导致dropout在低层的训练类似于一般的SGD。参考资料Paper—-Maxout NetworksCSD—-Maxout NetworksCSDN—-论文笔记_Maxout Networks"},{"title":"Conditional Generative Adversarial Nets阅读笔记","date":"2020-02-07T03:14:42.000Z","url":"/2020/02/07/2014-Conditional_Generative_Adversarial_Nets/","tags":["深度学习","论文阅读"],"categories":["深度学习论文阅读"],"content":"Conditional Generative Adversarial Nets摘要介绍条件对抗网络符号定义知识回顾——生成对抗网络直观感受目标函数对抗实验单模式——MNIST多模式——MIR Flickr参考资料Conditional Generative Adversarial NetsarXiv:1411.1784 [cs.LG]tensorflow2代码：摘要在GAN的基础上引入标签y，同时使用在生成器和判别器中.可以应用于多模态模型中。介绍生成对抗网络规避了棘手的概率计算不需要使用马尔科夫链，仅使用反向传播算法去获得梯度训练时不需要推断，可以轻松的将各种因素和相互作用纳入模型但无条件生成模型无法控制生成的数据，给模型加入附加信息可以知道数据的生成条件对抗网络符号定义$x$ $\\rightarrow$ 真实数据$y$ $\\rightarrow$ 标签（辅助信息）$z$ $\\rightarrow$ 噪音（生成器的输入数据）$p_x$ $\\rightarrow$ 真实数据的分布$p_{z}(z)$ $\\rightarrow$ 原始噪音数据的分布$p_g$ $\\rightarrow$ 经过生成器后数据的分布$G()$ $\\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\\theta_{g}$$D()$ $\\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\\theta_{d}$$G(z;\\theta_{g})$ $\\rightarrow$ 将噪音$z$映射到新的数据空间$D(x ; \\theta_{d})$ $\\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）知识回顾——生成对抗网络生成器G，判别器D，相互对抗使目标函数，达到最优。\\min _{G}\\max _{ D } V(D,G)={ \\mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \\mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]直观感受目标函数\\min _{G}\\max _{ D } V(D,G)={ \\mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x|y)] + { \\mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z|y)))]和原始GAN相近，只是G，D在y的条件下生成或判别对抗生成器G通过z，y联合生成图片判别器D在y的条件下判别G(z)主要是在y条件下的MinMax Game实验单模式——MNIST多模式——MIR Flickr参考资料Paper—-Conditional Generative Adversarial Nets知乎—-《Conditional Generative Adversarial Nets》阅读笔记CSDN—-Conditional Generative Adversarial Nets论文翻译CSDN—-Conditional Generative Adversarial Nets论文笔记"},{"title":"Generative Adversarial Nets阅读笔记","date":"2020-02-05T03:14:42.000Z","url":"/2020/02/05/2014-Generative_Adversarial_Networks/","tags":["深度学习","论文阅读"],"categories":["深度学习论文阅读"],"content":"1. Generative Adversarial Nets1.1. 摘要1.2. 介绍1.3. 对抗网络1.3.1. 符号定义1.3.2. 极大似然估计1.3.3. 目标函数1.3.4. 对抗1.3.5. Loss Function1.3.6. 具体算法过程1.4. 改进1.4.1. G替代版的Loss Function1.5. 补充知识1.5.1. 信息量1.5.2. 信息熵1.5.3. 交叉熵1.5.4. KL散度(Kullback–Leibler散度，相对熵)1.5.5. JS散度(Jensen-Shannon散度)1.6. 理论结果1.6.1. 最优判别器D：$D^{*}(x) =\\frac{P_{\\text {data}}(x)}{P_{\\text {data}}(x)+P_{G}(x)}$1.6.2. 最优生成器：$p_{g}=p_{\\text {data }}$1.6.3. 定理1：全局最优1.6.4. 算法的收敛性1.7. 优势和劣势1.7.1. 优势1.7.2. 劣势1.8. 结论和未来研究方向1.9. 参考资料1. Generative Adversarial NetsarXiv:1406.2661 [stat.ML]tensorflow2代码：. 摘要通过对抗过程估计生成模型的框架，同时训练两个模型：生成模型G用来获取数据分布判别模型D估计样本来自训练数据而不是G的概率G的训练目标是为了最大化D产生错误的概率在任意函数G和D的空间中存在唯一的解，其中G恢复训练数据分布，并且D处处都等于$\\frac{1}{2}$。1.2. 介绍最成功的的模型之一就是判别式模型通常它们将高维丰富的感知器输入映射到类标签上。主要是基于反向传播和丢弃算法来实现的，特别是具有特别良好梯度的分段线性单元。对抗网络生成模型通过将随机噪声传输到多层感知机来生成样本的特例判别模型通过多层感知机去判别一个样本是来自模型分布还是数据分布生成模型和判别模型互相对抗可以仅使用非常成熟的反向传播和丢弃算法训练两个模型，生成模型在生成样本时只使用前向传播算法。并且不需要近似推理和马尔可夫链作为前提。1.3. 对抗网络对抗模型框架是最直接的应用是多层感知机1.3.1. 符号定义$x$ $\\rightarrow$ 真实数据$z$ $\\rightarrow$ 噪音（生成器的输入数据）$p_x$ $\\rightarrow$ 真实数据的分布$p_{z}(z)$ $\\rightarrow$ 原始噪音数据的分布$p_g$ $\\rightarrow$ 经过生成器后数据的分布$G()$ $\\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\\theta_{g}$$D()$ $\\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\\theta_{d}$$G(z;\\theta_{g})$ $\\rightarrow$ 将噪音$z$映射到新的数据空间$D(x ; \\theta_{d})$ $\\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）1.3.2. 极大似然估计对于真实数据$x$和生成数据$G(z)$，经过判别器判别后的，$D$认为$x$是真样本的概率为$D(x)$，$D$认为$G(z)$是假样本的概率为$1-D(G(z))$，那么对于$D$有$log$似然函数为：L=log[D(x)*(1-D(G(z)))] \\tag{1}1.3.3. 目标函数\\min _{G}\\max _{ D } V(D,G)={ \\mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \\mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] \\tag{2}$D(x)$和$D(G(z))$分别表示$x$和$G(z)$经过判别器$D$的判别后，$D$认为输入样本是真样本的概率，则$1-D(G(z))$表示$D$将假样本判断为假的概率；那么，真实的概率分布与$D$判断出来的情况列表如下：$D$$D$将真样本$x$判断为真的概率:$D(x)$$D$将假样本$G(z)$判断为假的概率:$1-D(G(z))$真实情况真样本$x$为真的概率:1假样本$G(z)$为假的概率:1用交叉熵作为目标函数$1*log[D(x)]对应第一项$$1*log[1-D(G(z))]$对应第二项Note:$D$输出的是概率，那么$D$的输出层的激活函数必须是$sigmoid$1.3.4. 对抗判别器$D$的目标要尽可能把真的样本判断为真，对应最大化第一项：${ E }_{ x ～ { p }_  { data } (x) }[logD(x)]$把假的样本判断为假，对应最大化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $总之，也就是说判别器$D$要最大化目标函数；生成器$G$的目标要尽可能的让$D$将生成的假样本判断为真，对应最小化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $总之，也就是说生成器$G$要最小化目标函数；总的来说，这是一个MinMax Game；Note:实际训练当中，训练$G$的时候$D$的参数是固定的，$G$并不干扰$D$对真实数据的判断，$G$需要$D$的正确引导，$G$只是不断提升自己生成数据的能力。1.3.5. Loss Function$D$的损失函数（最小化）：Loss_D = -[1*logD(x) + 1*log(1-D(G(z)))] \\tag{3}$G$的损失函数（最小化）：Loss_G = 0*logD(x) + 1*log(1-D(G(z)))=log(1-D(G(z))) \\tag{4}1.3.6. 具体算法过程Note：生成对抗网络的minibatch随机梯度下降训练 先更新$D$，再更新$G$，只有$D$有了正确的判断能力，$G$才能按照$D$的指示来更新;可以设置一个超参数k来协调$D$、$G$两者之间更新的次数比例，在实验中k=1，使消耗最小;在训练$G$的时候$D$的参数要固定，在训练$D$的时候$G$的参数要固定;1.4. 改进1.4.1. G替代版的Loss Function由于$G(z)$是从噪声中生成的样本，所以在最开始$G$生成的样本非常假，很容易被$D$抓出来，也就是说$D(G(z))$非常小,那么$Loss_G = log(1-D(G(z)))$就非常接近0，在反向传播的时候就不能够传播足够的梯度给$G$来更新参数，所以我们从Heuristic的角度来理解：我们本身是要最小化$D$抓出来假样本的概率，现在我们可以换成最大化$D$抓不出来的概率（$\\log D(G(z))$），也就是将$G$的损失函数换成：Loss_G=-logD(G(z))由于$D$是按照：Loss_G = log(1-D(G(z)))训练的，那么如果损失函数更换，这两项不是等价的，所以$D$给出的值就能够提供足够的梯度。Note:$Loss_G =log(1-D(G(z)))$对应的GAN叫做MMGAN$Loss_G=-logD(G(z)) $对应的GAN叫做NSGAN改进后的仍然存在些许问题，见与定理1：全局最优的Note3从函数图像上，可以直观的看出，两种损失函数的梯度变化趋势：1.5. 补充知识1.5.1. 信息量$ I(x) = -\\log {p(x)} = \\log { \\frac { 1}{ p (x) }  } $一个事件发生的概率越大，这件事情发生所包含的信息量就越小，比如说一个高富帅追求一个白富美，追到手了没有什么稀奇的，因为这是一件概率很高的事情，但是如果一个矮穷矬追求一个白富美，追到手了，这种事情发生的概率很低，其中一定有其他的原因：比如这个矮穷矬救过白富美的命或者这个矮穷矬器大活好不黏人，所以概率低的事情发生所包含的信息量大；两个相互独立的事情同时发生的信息量是两者单独发生的信息量之和。1.5.2. 信息熵信息量的均值H(x) = - \\sum _{ x } p(x)log p(x)1.5.3. 交叉熵H(P, Q) = - \\sum _{ x } p(x)log q(x)用估计编码$q(x)$近似真实编码$p(x)$需要的平均编码长度1.5.4. KL散度(Kullback–Leibler散度，相对熵)统计中的一个概念，时衡量两种概率分布的相似程度，其越小，表示两种概率分布越接近。（当P(x)和Q(x)的相似度越高，KL散度越小）对于离散的概率分布定义如下：D_{KL}(P||Q)=- \\sum _{ x } p(x)log q(x) + \\sum _{ x } p(x)log p(x) =H(P, Q)-H(P)对于连续的概率分布定义如下：D_{K L}(P \\| Q)=\\int_{-\\infty}^{\\infty} p(x) \\log \\frac{p(x)}{q(x)} d x想要将一个随机高斯噪声$z$通过一个生成网络G得到一个和性质：不对称性尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即$D(P||Q) \\not= D(Q||P)$。非负性相对熵的值是非负值，即$D(P||Q)&gt;0$。1.5.5. JS散度(Jensen-Shannon散度)D_{JS}(P||Q)={\\frac{1}{2}} KL(P||M) + {\\frac{1}{2}} KL(Q||M) \\quad \\quad M = {\\frac{1}{2}}(P+Q)不同于KL主要又两方面：值域范围JS散度的值域范围是[0,1]，相同则是0，相反为1。相较于KL，对相似度的判别更确切了。对称性即 JS(P||Q)=JS(Q||P)，从数学表达式中就可以看出。1.6. 理论结果1.6.1. 最优判别器D：$D^{*}(x) =\\frac{P_{\\text {data}}(x)}{P_{\\text {data}}(x)+P_{G}(x)}$对于给定生成器G，最大化$V(D,G)$而得出最优判别器D。原论文中价值函数可写为在$x$上的积分，即将数学期望展开为积分形式：\\begin{aligned}\\max _{ D } V(D,G)&={ E }_{ x ～ { p }_  { data } (x) }[logD(x)] + { E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]\\\\&=\\int_{x} p_{d a t a}(x) \\log D(x) \\mathrm{d} x+\\int_{z} p(z) \\log (1-D(G(z))) \\mathrm{d} z\\\\&=\\int_{x} p_{d a t a}(x) \\log D(x)+p_{G}(x) \\log (1-D(x)) \\mathrm{d} x\\end{aligned}取函数，求偏导数（对于任意的$(a, b) \\in \\mathbb{R}^{2} \\backslash\\{0,0\\}$,函数$y \\rightarrow a \\log (y)+b \\log (1-y)$在$[0,1]$中的$\\frac{a}{a+b}$处达到最大值）\\begin{aligned}f(D) &=a \\log (D)+b \\log (1-D) \\\\\\frac{d f(D)}{d D}&= a \\times \\frac{1}{D}+b \\times \\frac{1}{1-D} \\times(-1)=0 \\\\a \\times \\frac{1}{D^{*}} &= b \\times \\frac{1}{1-D^{*}} \\\\\\Leftrightarrow a \\times & (1-D^{*}) =b \\times D^{*} & \\\\\\text{得到最优判别器}&{ D }^{ * }(x)：\\\\D^{*}(x) &=\\frac{P_{\\text {data}}(x)}{P_{\\text {data}}(x)+P_{G}(x)}\\end{aligned}1.6.2. 最优生成器：$p_{g}=p_{\\text {data }}$我们知道对于$G$来说，最好的$G$是让：{ P }_{ r }(x) = { P }_{ g }(x)此时，有：{ D }^{ * }(x)=1/2也就是说最好的生成器使最好的判别器无法判别出来样本是生成样本还是真实样本。1.6.3. 定理1：全局最优定理1：当且仅当$p_{g}=p_{\\text {data }}$时，$C(G)$达到全局最小。此时，$C(G)$的值为$−log4$。注意到，判别器$D$的训练目标可以看作为条件概率$P(Y=y | x)$的最大似然估计，当$y=1$时，x来自于$p_{\\text {data }}$；当$y=0$时，$x$来自$p_{g}$。公式1中的极小化极大问题可以变形为： \\begin{aligned} C(G) &=\\max _{D} V(G, D) \\\\ &=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}}\\left[\\log D_{G}^{*}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}}\\left[\\log \\left(1-D_{G}^{*}(G(\\boldsymbol{z}))\\right)\\right] \\\\ &=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}}\\left[\\log D_{G}^{*}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{g}}\\left[\\log \\left(1-D_{G}^{*}(\\boldsymbol{x})\\right)\\right] \\\\ &=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}}\\left[\\log \\frac{p_{\\text {data }}(\\boldsymbol{x})}{P_{\\text {data }}(\\boldsymbol{x})+p_{g}(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{g}}\\left[\\log \\frac{p_{g}(\\boldsymbol{x})}{p_{\\text {data }}(\\boldsymbol{x})+p_{g}(\\boldsymbol{x})}\\right] \\\\ &=\\int_{x} p_{\\text {data}}(x) \\log \\left(\\frac{p_{\\text {data}}(x)}{p_{\\text {data}}(x)+p_{g}(x)}\\right)+p_{g}(x) \\log \\left(\\frac{p_{g}(x)}{p_{\\text {data}}(x)+p_{g}(x)}\\right) d x\\\\&=\\int_{x} p_{d a t a}(x) \\log \\left(\\frac{p_{d a t a}(x)}{\\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\\right)+p_{g}(x) \\log \\left(\\frac{p_{g}(x)}{\\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\\right) d x-\\log (4)\\\\&=\\underbrace{K L\\left(p_{\\text {data}}(x) \\| \\frac{p_{\\text {data}}(x)+p_{g}(x)}{2}\\right)}_{\\geq 0}+\\underbrace{K L\\left(p_{g}(x) \\| \\frac{p_{\\text {data}}(x)+p_{g}(x)}{2}\\right)}_{\\geq 0}-\\log (4)\\\\&=2\\underbrace{\\cdot JSD(p_{data}\\|p_{g})}_{\\geq 0}-log(4)\\\\\\min _{G} C(G)&=0+0-\\log (4)=-\\log (4)\\end{aligned}当且仅当$p_{\\text {data}}(x)=\\frac{p_{\\text {data}}(x)+p_{g}(x)}{2}$即$p_{g}=p_{\\text {data }}$时成立，此时$C(G)$达到全局最小，$C(G)$的值为$−log4$。Note1$KL$散度：$KL({ P }_{ 1 }||{ P }_{ 2 })={ P }_{ 1 }\\log { \\frac { { P }_{ 1 } }{ { P }_{ 2 } }  } $$JS$散度：$ JS({ P }_{ 1 }||{ P }_{ 2 })=\\frac { 1 }{ 2 } KL({ P }_{ 1 }||\\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } )+\\frac { 1 }{ 2 } KL({ P }_{ 2 }||\\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } ) $Note2（MMGAN）$Loss_G =log(1-D(G(z)))$当判别器$D$最优的时候，生成器$G$是在减小真实分布与生成分布之间的$JS$散度Note3（NSGAN）$Loss_G=-logD(G(z)) $ \\begin{aligned}KL({ P }_{ g }(x)||{ P }_{ r }(x))&={ P }_{ g }(x)*\\log { \\frac { { P }_{ g }(x) }{ { P }_{ r }(x) }  } \\\\ &={ P }_{ g }(x)*\\log { \\frac { { P }_{ g }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }{ { P }_{ r }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }  } \\\\ &={ P }_{ g }(x)*\\log  \\frac { 1-D^{ * }(x) }{ D^{ * }(x) } \\\\ &={ P }_{ g }(x)log[1-D^{ * }(x)]-{ P }_{ g }(x)logD^{ * }(x)\\\\-{P}_{g}(x)*logD^*(x)&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\\\Loss_{ G }&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\\\\\because {P}_{r}(x)*log[D^*(x)] &+ {P}_{g}(x)*log[1-D^*(x)]=2JS({ P }_{ r }||{ P }_{ g })-2log2\\\\\\therefore Loss_{ G }=KL({ P }_{ g }(&x)||{ P }_{ r }(x))-2JS({ P }_{ r }||{ P }_{ g })+{P}_{r}(x)*log[D^*(x)]+2log2[1-D^{ * }(x)]\\end{aligned}从上面的式子可以看出KL散度和JS散度同时存在且方向相反，而JS散度和KL散度都是衡量两个分布距离的度量，且是单调性同步的函数，这样的话就会导致梯度的方向不稳定，一会儿上升一会儿下降，所以这个替代版的损失函数也不是一个好的选择。1.6.4. 算法的收敛性**命题：如果$G$和$D$有足够的性能，对于算法1中的每一步，给定$G$时，判别器能够达到它的最优，并且通过更新$p_g$来提高这个判别准则。 \\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}}\\left[\\log D_{G}^{*}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{g}}\\left[\\log \\left(1-D_{G}^{*}(\\boldsymbol{x})\\right)\\right]则$p_g$收敛为$p_{data}$。**Note优化$θ_g$而不是$p_g$本身1.7. 优势和劣势1.7.1. 优势根据实际的结果，它们看上去可以比其它模型产生了更好的样本（图像更锐利、清晰）。生成对抗式网络框架能训练任何一种生成器网络（理论上-实践中，用 REINFORCE 来训练带有离散输出的生成网络非常困难）。大部分其他的框架需要该生成器网络有一些特定的函数形式，比如输出层是高斯的。重要的是所有其他的框架需要生成器网络遍布非零质量（non-zero mass）。生成对抗式网络能学习可以仅在与数据接近的细流形（thin manifold）上生成点。不需要设计遵循任何种类的因式分解的模型，任何生成器网络和任何鉴别器都会有用。无需利用马尔科夫链反复采样，无需在学习过程中进行推断（Inference），回避了近似计算棘手的概率的难题。1.7.2. 劣势解决不收敛（non-convergence）的问题。目前面临的基本问题是：所有的理论都认为 GAN 应该在纳什均衡（Nash equilibrium）上有卓越的表现，但梯度下降只有在凸函数的情况下才能保证实现纳什均衡。当博弈双方都由神经网络表示时，在没有实际达到均衡的情况下，让它们永远保持对自己策略的调整是可能的【OpenAI Ian Goodfellow的Quora】。难以训练：崩溃问题（collapse problem）GAN模型被定义为极小极大问题，没有损失函数，在训练过程中很难区分是否正在取得进展。GAN的学习过程可能发生崩溃问题（collapse problem），生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。Improved Techniques for Training GANs无需预先建模，模型过于自由不可控。与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，即不需要formulate p(x)，而是使用一种分布直接进行采样sampling，从而真正达到理论上可以完全逼近真实数据，这也是GAN最大的优势。然而，这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了(超高维)。在GAN[Goodfellow Ian, Pouget-Abadie J] 中，每次学习参数的更新过程，被设为D更新k回，G才更新1回，也是出于类似的考虑。1.8. 结论和未来研究方向该框架允许许多直接的扩展：条件生成模型$p(x | c)$可以通过将$c$作为$G$和$D$的输入来获得。给定$x$，可以通过训练一个任意的模型来学习近似推理，以预测$z$。这和wake-sleep算法训练出的推理网络类似，但是它具有一个优势，就是在生成器训练完成后，这个推理网络可以针对固定的生成器进行训练。能够用来近似模型所有的条件概率$p\\left(\\boldsymbol{x}_{S} | \\boldsymbol{x}_{\\beta}\\right)$，其中$S$通过训练共享参数的条件模型簇的关于$x$索引的一个子集。本质上，可以使用生成对抗网络来随机拓展MP-DBM。半监督学习：当标签数据有限时，判别网络或推理网络的特征不会提高分类器效果。效率改善：为协调$G$和$D$设计更好的方法，或训练期间确定更好的分布来采样$z$，能够极大的加速训练。1.9. 参考资料Paper—-Generative Adversarial Nets知乎—-GAN入门理解及公式推导CSDN—-GAN论文阅读——原始GAN（基本概念及理论推导）CSDN—-KL散度、JS散度以及交叉熵对比CSDN—-Generative Adversarial Nets论文笔记+代码解析CSDN—-Generative Adversarial Nets（译）Github—-andyhujinzhao/Generative_Adversarial_Nets"},{"title":"欢迎到我的博客= =（测试ing）","date":"2019-06-02T03:14:42.000Z","url":"/2019/06/02/欢迎到我的博客= =（测试ing）/","tags":["PS3","Games"],"content":"[toc]123352223s"},{"title":"404 Not Found：该页无法显示","date":"2019-06-04T11:08:41.025Z","url":"/404/index.html","content":"&lt;!DOCTYPE html&gt;                      404                                                                                                                                                             "},{"title":"about","date":"2019-06-04T09:41:17.000Z","url":"/about/index.html","content":"幻华的博客"},{"title":"en","date":"2019-08-13T14:18:22.146Z","url":"/en/index.html","content":"2333"},{"title":"categories","date":"2019-06-02T10:45:50.000Z","url":"/categories/index.html"},{"title":"links","date":"2019-06-04T10:41:06.923Z","url":"/links/index.html"},{"title":"Search","date":"2019-06-04T10:34:38.712Z","url":"/search/index.html"},{"title":"tags","date":"2019-06-04T10:21:29.080Z","url":"/tag/index.html"},{"title":"Gallery","date":"2019-06-04T10:31:01.942Z","url":"/gallery/index.html"}]