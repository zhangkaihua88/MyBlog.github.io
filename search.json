                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [{"title":"InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets阅读笔记","date":"2020-02-09T15:54:52.000Z","url":"/2020/02/09/2016-InfoGAN-Interpretable-Representation-Learning-by-Information-Maximizing-Generative-Adversarial-Nets阅读笔记/","tags":["深度学习","论文阅读"],"categories":["深度学习论文阅读"],"content":"1. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets1.1. 摘要1.2. 引言1.3. 相关工作1.4. 补充知识1.4.1. 信息量1.4.2. 信息熵1.4.3. 互信息1.5. InfoGAN1.5.1. 知识回顾——生成对抗网络1.5.2. 符号定义1.5.3. 直观感受1.5.4. 目标函数1.5.5. 对抗1.5.6. 目标函数由来1.5.7. 变分互信息最大化1.6. 实现1.7. 实验1.7.1. 互信息的最大化1.7.2. 有区分度的表示1.8. 结论1.9. 附录——解释为“sleep-sleep”算法1.10. 参考资料1. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial NetsarXiv:1606.03657 [cs.LG]tensorflow2代码：. 摘要InfoGAN对生成对抗网络的信息理论扩展完全无监督的方式学习特征分离表示能最大化潜在变量的一小部分与观察(生成)结果之间的互信息本文有效优化的互信息目标的下界InfoGAN可以学习与现有监督方法学习得到了具有竞争力的可解释性表征。1.2. 引言无监督学习一般可以被描述为从大量存在的未标记数据中提取数值的问题。流行框架是表征学习目标是使用未标记的数据来学习一种表示，以从重要语义特征中找到易于解释的要素。特征分离的表示对于需要知道数据的显著属性的自然任务可能是有用的无监督学习算法必须对下游分类任务有正确的效果（在不直接接触下游任务的情况下）。很大一部分是由生成模型驱动的。动力源于对生成模型能力的相信，或为观察数据“创造”某种形式的理解，并希望良好的生成模型能自动学习一个有区分度的表示，即便通过随便一个不好的表示也容易构造完美的生成模型。最突出的生成模型是变分自动编码器（VAE）和生成对抗网络（GAN）。本文生成对抗网络目标进行了简单的修改，鼓励其学习可解释和有意义的表示。通过最大化GAN噪声变量的固定小子集与观测值之间的互信息来实现，这一点相对比较直观。增加互信息成本的生成模型是学习特征表示的有效途径。1.3. 相关工作现在存在大量关于无监督表示学习的工作。早期的方法是基于堆叠的（通常是去噪）自动编码器或受限玻尔兹曼机阶梯网络，它在MNIST数据集的半监督变学习上取得了惊人的成果。此外，先前的研究试图使用监督数据来学习分离的特征表示。使用监督学习训练表示的一部分来匹配所提供的标签弱监督方法来消除对明确标记变量的需要1.4. 补充知识1.4.1. 信息量$ I(x) = -\\log {p(x)} = \\log { \\frac { 1}{ p (x) }  } $一个事件发生的概率越大，这件事情发生所包含的信息量就越小，比如说一个高富帅追求一个白富美，追到手了没有什么稀奇的，因为这是一件概率很高的事情，但是如果一个矮穷矬追求一个白富美，追到手了，这种事情发生的概率很低，其中一定有其他的原因：比如这个矮穷矬救过白富美的命或者这个矮穷矬器大活好不黏人，所以概率低的事情发生所包含的信息量大；两个相互独立的事情同时发生的信息量是两者单独发生的信息量之和。1.4.2. 信息熵信息量的均值H(x) = - \\sum _{ x } p(x)log p(x)1.4.3. 互信息在信息论中，X和Y之间的互信息 $I(X;Y)$测量从随机变量Y的知识中学习的关于另一个随机变量X的“信息量”。I(X;Y)=H(X)-H(X|Y)=H(Y)-H(Y|X)这个定义有一个直观的解释： $I(X,Y)$是观察到 $Y$ 时， $X$的不确定性的减少量。如果 $X$ 和 $Y$ 是独立的，那么 $I(X;Y)=0$ ，因为一个变量与另一个变量毫无关系；相反，如果$X$和$Y$通过确定性可逆函数相关，则获得最大互信息。1.5. InfoGAN1.5.1. 知识回顾——生成对抗网络生成器G，判别器D，相互对抗使目标函数，达到最优。\\min _{G}\\max _{ D } V(D,G)={ \\mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \\mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]但是无约束、不可控、噪声信号z很难解释等问题。1.5.2. 符号定义$x$ $\\rightarrow$ 真实数据$y$ $\\rightarrow$ 标签（辅助信息）$z$ $\\rightarrow$ 噪音（生成器的输入数据）$c$ $\\rightarrow$ 潜在代码(latent code)$p_c$ $\\rightarrow$ 潜在代码的分布，可以为连续分布，也可以为离散分布$p_x$ $\\rightarrow$ 真实数据的分布$p_{z}(z)$ $\\rightarrow$ 原始噪音数据的分布$p_g$ $\\rightarrow$ 经过生成器后数据的分布$G()$ $\\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\\theta_{g}$$D()$ $\\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\\theta_{d}$$Q(c|x)$ $\\rightarrow$ 辅助分布用于逼近后验概率$P(c|x)$$G(z,c;\\theta_{g})$ $\\rightarrow$ 将噪音$z$和潜在代码映射到新的数据空间$D(x ; \\theta_{d})$ $\\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）1.5.3. 直观感受当Q与D共享参数1.5.4. 目标函数\\begin{aligned}\\min _{G} \\max _{D} V_{I}(D, G)&=V(D, G)-\\lambda I(c ; G(z, c)) \\\\&= { \\mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \\mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]-\\lambda I(c ; G(z, c))\\end{aligned}和原始GAN相近，只是G中加入了潜码$c$（和$G(z,c)$有关），可以调节$c$来改变生成样式(加入了互信息的惩罚)当用分布$Q(c|x)$逼近后验概率$P(c|x)$时，目标函数变为\\min_{G,Q}\\max_D V_{InfoGAN}(D,G,Q)=V(D,G)-\\lambda L_I(G,Q)Note:此处的$V(D, G)$不局限于原始GAN的代价函数，可以使用其他的代价函数，以获得更好的训练1.5.5. 对抗判别器$D$的目标要尽可能把真的样本判断为真，对应最大化第一项：${ E }_{ x ～ { p }_  { data } (x) }[logD(x)]$把假的样本判断为假，对应最大化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z,c)))] $总之，也就是说判别器$D$要最大化目标函数；生成器$G$的目标要尽可能的让$D$将生成的假样本判断为真，对应最小化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $同时加入潜码$c$是为了使生成$G(z,c)$和$c$有很强的关联：$I(c ; G(z, c))$最大化，即$-\\lambda I(c ; G(z, c))$($\\lambda$为整数)最小总之，也就是说生成器$G$要最小化目标函数；总的来说，这是一个信息正则化的MinMax Game；当用分布$Q(c|x)$逼近后验概率$P(c|x)$时，InfoGAN具有互信息和超参数λ的变分正则化的MinMax Game1.5.6. 目标函数由来为了让让网络学习到了可解释的特征表示将提出将输入噪声向量分成为两部分：$z$:被视为不可压缩的噪声源；$c$1:将其称为潜在代码(latent code)，其目的在于数据分布的显著结构化的语义特征。1:在数学上，$c_1,c_2,…,c_L$​ 表示结构化潜在变量的集合。在其最简单的形式中，可以假设一个因式分布，由 $P\\left(c_{1}, c_{2}, \\ldots, c_{L}\\right)=\\prod_{i=1}^{L} P\\left(c_{i}\\right)$ 给出。为了便于表示，使用潜在代码 $c$ 来表示所有潜在变量 $c_i$​ 的联合。但是在标准GAN中，通过找到满足 $P_G(x|c)= P_G(x)$ 的解，生成器可以自由地忽略附加潜在代码$c$ 。提出了一种基于信息论的正则化方法：潜在码 $c$ 和生成分布 $G(z,c)$ 之间应该有很高的互信息。因此 $I(c;G(z,c))$ 应该很高。给定任何 $x \\sim P_{G}(x)$ ，希望 $P_G(c|x)$ 具有小的熵。换句话说，潜在码 $c$ 中的信息不应该在生成过程中丢失。在聚类的背景下，之前已经有过类似的互信息启发目标函数。因此，本文建议通过以下信息正则化的minimax游戏来解决问题：\\min _{G} \\max _{D} V_{I}(D, G)=V(D, G)-\\lambda I(c ; G(z, c))1.5.7. 变分互信息最大化引理1对于随机变量$X$，$Y$和函数$f(x,y)$在适当的正则条件下$\\mathbb{E}_{x \\sim X, y \\sim Y | x}[f(x, y)]=\\mathbb{E}_{x \\sim X, y \\sim Y\\left|x, x^{\\prime} \\sim X\\right| y\\left[f\\left(x^{\\prime}, y\\right)\\right]}$证明：\\begin{aligned}\\mathbb{E}_{x \\sim X, y \\sim Y | x}[f(x, y)] &=\\int_{x} P(x) \\int_{y} P(y | x) f(x, y) d y d x \\\\&=\\int_{x} \\int_{y} P(x, y) f(x, y) d y d x \\\\&=\\int_{x} \\int_{y} P(x, y) f(x, y) \\int_{x^{\\prime}} P\\left(x^{\\prime} | y\\right) d x^{\\prime} d y d x \\\\&=\\int_{x} P(x) \\int_{y} P(y | x) \\int_{x^{\\prime}} P\\left(x^{\\prime} | y\\right) f\\left(x^{\\prime}, y\\right) d x^{\\prime} d y d x \\\\&=\\mathbb{E}_{x \\sim X, y \\sim Y\\left|x, x^{\\prime} \\sim X\\right| y}\\left[f\\left(x^{\\prime}, y\\right)\\right]\\end{aligned}变分信息最大化互信息项 $I(c;G(z,c))$ 难以直接最大化，因为它先得到后验概率 $P(c|x)$ 。通过定义辅助分布 $Q(c|x)$ 来逼近 $P(c|x)$ ，可以得到它的下界：\\begin{aligned}I(c ; G(z, c)) &=H(c)-H(c | G(z, c)) \\\\&=\\mathbb{E}_{c \\sim P(c),x \\sim G(z, c)}[\\log P(c |x)]+H(c)\\\\根据引理1&=\\mathbb{E}_{x \\sim G(z, c)} \\left[\\mathbb{E}_{c^{\\prime} \\sim P(c | x)} \\left[\\log P(c^{\\prime}|x) \\right] \\right]+H(c)\\\\&=\\mathbb{E}_{x \\sim G(z, c)}\\left[\\mathbb{E}_{c^{\\prime} \\sim P(c | x)}\\left[\\log P\\left(c^{\\prime} | x\\right)\\right]\\right]+H(c) \\\\&=\\mathbb{E}_{x \\sim G(z, c)}\\left[\\mathbb{E}_{c^{\\prime} \\sim P(c | x)} \\left[ \\frac{P(c^{\\prime} | x) Q(c^{\\prime} | x)}{Q(c^{\\prime} | x)} \\right] \\right] \\\\&=\\mathbb{E}_{x \\sim G(z, c)}\\left[  \\mathbb{E}_{c^{\\prime} \\sim P(c | x)} \\left[ \\log \\frac{P(c^{\\prime} | x)}{Q(c^{\\prime} | x)}\\right]+ \\mathbb{E}_{c^{\\prime} \\sim P(c | x)}\\left[\\log Q\\left(c^{\\prime} | x\\right)\\right]\\right]+H(c)\\\\&=\\mathbb{E}_{x \\sim G(z, c)}\\left[\\underbrace{D_{K L}(P(\\cdot | x) \\| Q(\\cdot | x))}_{\\geq 0}+\\mathbb{E}_{c^{\\prime} \\sim P(c | x)}\\left[\\log Q\\left(c^{\\prime} | x\\right)\\right]\\right]+H(c) \\\\& \\geq \\mathbb{E}_{x \\sim G(z, c)}[{\\left.D_{c^{\\prime} \\sim P(c | x)}\\left[\\log Q\\left(c^{\\prime} | x\\right)\\right]\\right]}+H(c)\\end{aligned}潜在编码 $H(c)$ 的熵也可以优化，因为对于常见分布，它具有简单的分析形式。然而，在本文中，通过修复潜在编码分布来选择简化的表示，并将 $H(c)$ 视为常量。引理2 对随机变量 $X$,$Y$ 和函数 $f(x,y)$ ，在合适的规则条件下： $\\mathbb{E}_{x \\sim X, y \\sim Y | x}[f(x, y)]=\\mathbb{E}_{x \\sim X, y \\sim Y|x, x^{\\prime} \\sim X| y}[f\\left(x^{\\prime}, y\\right)]$证明：通过使用引理1可以定义互信息 $I(c;G(z,c))$ 变分的下界 $L_I(G,Q)$:\\begin{aligned}L_{I}(G, Q) &=E_{c \\sim P(c), x \\sim G(z, c)}[\\log Q(c | x)]+H(c) \\\\&=E_{x \\sim G(z, c)}\\left[\\mathbb{E}_{c^{\\prime} \\sim P(c | x)}\\left[\\log Q\\left(c^{\\prime} | x\\right)\\right]\\right]+H(c) \\\\& \\leq I(c ; G(z, c))\\end{aligned}注意到 $L_I(G,Q)$ 很容易用蒙特卡罗模拟近似。 特别是，可以对于 w.r.t.$Q$ 和 w.r.t.$G$ 使用重参数化技巧将 $L_I$​ 最大化。 因此， $L_I(G,Q)$ 可以添加到GAN的目标而不改变GAN的训练过程，称之为信息最大化生成对抗网络(InfoGAN)。变分互信息最大化表明，当辅助分布 $Q$ 接近真实的后验分布 $\\mathbb E_x[D_{KL}P(·|x)||Q(·|x))]→0$ 时，下限变紧了。另外，当变分下界达到离散潜码的最大值 $L_I(G,Q)= H(c)$ 时，边界变紧并且达到最大互信息。1.6. 实现整体将辅助分布 $Q$ 参数化为神经网络。 在大多数实验中， $Q$ 和 $D$ 共享所有卷积层存在一个最终完全连接的层以输出条件分布 $Q(c|x)$ 的参数(softmax)这意味着InfoGAN仅向GAN添加了可忽略的计算成本在实验中， $L_I(G,Q)$ 总是比正常的GAN目标更快收敛分类的潜在代码$c_i$​使用非线性softmax来表示 $Q(c_i|x)$对于连续潜在代码 $c_j$​ ，根据真正的后验概率 $P(c_j|x)$ ，有更多的选项。可以简单地将 $Q(c_j|x)$ 作为因子化的高斯来处理就足够了。c为离散变量$Q(c|x)$可以表示为一个神经网络$Q(X)$的输出\\begin{aligned}&\\because L_{I}(G, Q)=c \\cdot \\log Q(G(z, c))+H(c)\\\\&\\therefore \\max L_{I}(G, Q) \\text{等价于} \\max c \\cdot \\log Q(G(z, c))\\end{aligned}其中$\\cdot$表示内积，c是一个选择计算哪个$\\log$的参数，$H(c)$可以消去$L_I(G,Q)$本质上是$x$与$G(z,x)$之间的KL散度\\begin{aligned}&\\because \\begin{aligned}D_{K L}(c \\| Q(G(z, c))) &=-c \\cdot \\log \\frac{Q(G(z, c))}{c} \\\\&=-c \\cdot \\log Q(G(z, c))+c \\cdot \\log c \\\\&=-c \\cdot \\log Q(G(z, c))+H(c) \\\\&=-L_{I}(G, Q)+2 H(c)\\end{aligned}\\\\&\\therefore \\max L_{I}(G, Q) \\text{等价于} \\min D_{K L}(c \\| Q(G(z, c)))\\end{aligned}$\\min D_{K L}(c | Q(G(z, c)))$意味着减少$c$与$Q(G(z, c)$c为连续变量设 $Q(x)$ 输出的参数潜码 $c$ 的均值 $\\mu$，标准差 $\\sigma$ 分别为 $Q(x)_{\\mu}$ 和$Q(x)_{\\sigma}$，那么对于参数潜码 c\\begin{aligned}&L_{I}(G, Q)=\\mathbb{E}_{x \\sim G(z, c)}\\left[\\mathbb{E}_{c^{\\prime} \\sim P(c | x)}\\left[\\log Q\\left(c^{\\prime} | x\\right)\\right]\\right]+H(c) \\\\&\\because p(x)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}}(\\text{c符合正态分布;均值 $\\mu$,标准差 $\\sigma$})\\\\&\\therefore \\log p(c) = -\\frac{(c-\\mu)^{2}}{2 \\sigma^{2}}-\\log (\\sigma \\sqrt{2 \\pi})\\\\&\\therefore L_{I}(G, Q)=-\\frac{\\left(c-Q(x)_{\\mu}\\right)^{2}}{2 Q(x)_{\\sigma}^{2}}-\\log \\left(Q(x)_{\\sigma} \\sqrt{2 \\pi}\\right)+H(c)\\\\&\\therefore \\max L_{I}(G, Q) \\text{等价于} \\min \\left(\\frac{\\left(c-Q(x)_{\\mu}\\right)^{2}}{2 Q(x)_{\\sigma}^{2}}+\\log \\left(Q(x)_{\\sigma} \\sqrt{2 \\pi}\\right)\\right)\\end{aligned}不考虑$Q(x)_{\\sigma}$的影响则\\max L_{I}(G, Q) \\text{等价于} \\min \\left(c-Q(x)_{\\mu}\\right)^{2}$\\min \\left(c-Q(x)_{\\mu}\\right)^{2}$意味这减小$c$与$Q(x)_{\\mu}$的差总之$L_{I}$的优化过程，实质上是以G为编码器(Encoder)，Q为解码器(Decoder)，生成图像作为要编码的码(code)，训练一个自编码器(Autoencoder)超参数 $\\lambda$对于离散的潜在代码，它很容易调整，简单地设置为1就足够。当潜在编码包含连续变量时，较小的 $\\lambda$ 通常用于确保包含差分熵的 $L_I(G,Q)$ 的规模与GAN目标的规模相同。1.7. 实验目标调查是否可以有效地最大化互信息评估InfoGAN是否可以通过利用生成器一次仅改变一个潜在因子来学习有区分度的可解释的表示，以评估改变这样的因素是否导致生成的图像中只有一种类型的语义变化。 1.7.1. 互信息的最大化为了评估潜在编码 $c$ 和生成的图像 $G(z,c)$ 之间的互信息是否可以通过提出的方法有效地最大化，作者在MNIST数据集上训练InfoGAN，对潜在编码 $c$ 进行统一的分类分布 $c\\sim Cat(K=10,p=0.1)$ 。在 图1 中，下限 $L_I(G,Q)$ 被快速最大化为 $H(c)\\approx 2.30$ ，这意味着下限 (4) 快速紧贴到到最大的互信息。作为基准，当没有明确促使生成图像与潜在编码最大化的互信息时，作者还训练具有辅助分布 $Q$ 的常规GAN。由于作者使用神经网络对 $Q$ 进行参数化，假设 $Q$ 可以合理地近似真实的后验概率 $P(c|x)$ ，因此在常规GAN中潜在编码和生成图像之间几乎没有互信息。作者注意到，使用不同的神经网络架构，即使在实验中没有观察到这种情况，潜在代码和生成的图像之间可能存在更高的相互信息。这种比较是为了证明在常规GAN中，不能保证生成器能够利用潜在编码。1.7.2. 有区分度的表示离散的c捕捉离散变换，连续的c捕捉连续变换MNIST$c_1\\sim Cat(K=10,p=0.1)$ 控制数字$c_2 \\sim Unif(-1,1)$​ 控制旋转数字$c_3 \\sim Unif(-1,1)$​ 控制宽度但$c_2,c_3$​还调整其他细节，如厚度或笔触样式$c$处于$-2 \\sim 2$之间仍有用，表明InfoGAN学习的潜在表示可泛化Faces$c_i\\sim Unif(-1,1),1\\leq i\\leq 5$表示为方位角（姿势），仰角和照明等潜在因素看做连续潜在变量。CelebA$c_1,c_2,c_3,c_4\\sim (K=20,p=0.05)$和一个连续码 $c_5\\sim Unif(-1,1)$代表旋转的连续编码。使用单个连续代码连续插入不同宽度的类似椅子类型。SVHN利用四个10维分类变量和两个均匀连续变量作为潜在代码。1.8. 结论InfoGAN完全没有监督在具有挑战性的数据集上学习可解释和有区分度的表示。InfoGAN在GAN之上仅增加了可忽略不计的计算成本，并且易于训练。 使用互信息表示的核心思想可以应用于其他方法，1.9. 附录——解释为“sleep-sleep”算法InfoGAN可以看作是Helmholtz机（wake-sleep算法）：$P_{G}(x | c)$是生成分布$Q(c|x)$识别分布提出wake-sleep算法，通过执行wake阶段和sleep阶段更新Helmholtz机wake阶段：通过优化有关生成的变分下界$\\log P_G(x)$来更新\\max _{G} \\mathbb{E}_{x \\sim \\operatorname{Data}, c \\sim Q(c | x)}\\left[\\log P_{G}(x | c)\\right]sleep阶段：通过在当前生成分布中生成样本，而不是从实际数据分布中提取样本来更新辅助分布因此，当优化代理损失函数2$L_I$（关于$Q$），更新步骤正是wake-sleep算法中的sleep过程。InfoGAN与Wake-sleep不同之处在于优化$L_I$（关于$Q$）生成网络G在潜在代码$P(c)$整个先前分布中使用了潜在代码$c$。由于InfoGAN在sleep过程中更新了生成器，所以可以解释为sleep-sleep算法。这种解释突出了InfoGAN与以前生成建模技术的区别：明确鼓励生成器以潜在代码传达信息，并建议将相同原理应用于其他生成模型。2:代理损失函数:当原本的loss function不便计算的时候，我们就会考虑使用surrogate loss function。1.10. 参考资料Paper—-InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial NetsCSDN—-深度学习（四十八）InfoGAN学习笔记知乎—-InfoGAN解读个人Blog—-InfoGAN: using the variational bound on mutual information (twice)机器之心—-InfoGAN：一种无监督生成方法 | 经典论文复现程序员大本营—-【GAN ZOO翻译系列】InfoGAN： Interpretable Representation Learning by Information Maximizing GAN"},{"title":"Maxout Networks阅读笔记","date":"2020-02-07T03:14:42.000Z","url":"/2020/02/07/2013-Maxout-Networks阅读笔记/","tags":["深度学习","论文阅读"],"categories":["深度学习论文阅读"],"content":"1. Maxout Networks1.1. 摘要1.2. 介绍1.3. 回顾droupt1.4. 模型maxout描述1.5. Maxout是一个通用的近似器1.6. maxout与relu1.7. 模型平均1.8. 优化1.9. 参考资料1. Maxout NetworksarXiv:1302.4389 [stat.ML]tensorflow2代码：. 摘要maxout：旨在通过dropout来加快优化过程，并提高准确度（与drop共同使用）；模型的输出是模型输入的最大值1.2. 介绍dropout可以训练集成模型共享参数并近似的对这些模型的预测进行了平均一种不加区分的适用型工具，几乎可以应用于任何模型，都可以产生一定的性能改进。dropout与SDGdropout在更新时最有效的方式是使用更大的步长，因为这样可以在不同的训练子集上对不同的模型有明显的影响来使得目标函数有持续的波动性，理想情况下整个训练过程就类似于使用bagging来训练集成的模型（带有参数共享的约束）。SGD更新时一般会使用更小的步长，来使得目标函数平滑的下降。对于深度网络模型，dropout只能作为模型平均的一种近似，显式的设计模型来最小化这种近似误差也可以提高dropout的性能。1.3. 回顾droupt在给定输入向量$v$后，输出预测向量$y$，该构成包含了一系列的隐含层$h=\\{h^{(1)},…,h^{(L)}\\}$。Dropout训练一组由包含$v$和$h$中变量的子集组成的所有模型组成的模型。使用同一组参数$\\theta$来标识一组分组$p(y | v ; \\theta, \\mu)$，其中$\\mu \\in M$是一个二进制掩码，用来决定模型中哪些变量参与运算。每次在训练集上进行训练时，我们都按照$\\log p(y | v ; \\theta, \\mu)$的梯度对不同的$\\mu$随机取样训练不同的子模型。可以通过$v$和$h$和掩码的按元素相乘得到不同子模型$p(y | v ; \\theta, \\mu)$的实例当集合需要将所有子模型的预测平均起来进行预测时，函数形式就变得非常重要。多个指数模型的预测平均值可以简单的通过运行权重除以2的完整模型来得到。即当$p(y|v;\\theta) = softmax(v^Tw+b)$时，通过重整$p(y|v;\\theta,\\mu)$的几何平均定义的预测分布，可以很简单的由$softmax(v^tw/2+b)$dropout与bagging都是在不同子集上训练出不同模型dropout只训练一次，且所有模型共享参数。像是在训练一个模型集合而不是训练单个模型，每次的更新都必须有重大的影响，这样才能使得该子模型能较好的拟合当前的输入$v$bagging对子模型的输出进行算数平均，dropout是几何平均1.4. 模型maxout描述是一个简单的前馈框架模型使用了一个新的激活函数：maxout unit给定一个输入$ x \\in \\mathbb{R}^d$ （$x$可能是输入$v$,也可能是隐含层的状态），maxout隐含层的采用下式实现：h_{i}(x)=\\max _{j \\in[1, k]} z_{i j}其中$z_{i j}=x^{T} W_{\\ldots i j}+b_{i j}$，$x \\in \\mathbb{R}^{d \\times n}$，$W \\in \\mathbb{R}^{d \\times m \\times k}$, $b \\in \\mathbb{R}^{m \\times k}$。$w$，$b$都是可训练参数。$k$表示每个隐藏节点对应k个“隐隐层”节点，这$k$个“隐隐层”节点都是线性输出。maxout的每个节点就从这k个“隐隐层”节点输出值中取最大的。所以使得maxout为一种非线性的变换Notesmaxout因为有参数同时为非线性，所以既可以是网络也可以是激活器单个maxout单元可以解释为对任意凸函数进行线性逼近。（任意的凸函数都可由分段线性函数来拟合）。它在每处都是局部线性的（k个“隐隐层”节点都是线性的，取其最大值则为局部线性，分段的个数与k值有关），而一般的激活函数都有明显的曲率。如同MLP一样，maxout网络也可以拟合任意连续函数。只要maxout单元含有任意多个“隐隐层”节点，那么只要两个隐层的maxout网络就可以实现任意连续函数的近似。maxout网络不仅可以学习到隐层之间的关系，还可以学习到每个隐层单元的激活函数。maxout放弃了传统激活函数的设计，它产生的表示不再是稀疏的，但是它的梯度是稀疏的，且dropout可以将它稀疏化。maxout没有上下界，所以让它在某一端饱和是零概率事件。如果训练时使用dropout，则dropout操作在矩阵相乘之前，而并不对max操作的输入执行dropout。使用maxout会默认一个先验：样本集是凸集可分的。1.5. Maxout是一个通用的近似器命题1：对于任意的正整数$m$,$n$,都存在两组$n+1$维的实数参数向量$[W_{1j}, b_{1j}], j \\in [1, k]$和$[W_{2j}, b_{2j}], j \\in [1, k]$使得g(v) = h_1(v) - h_(v) 即任意的分段连续函数都可以使用两个凸分段线性函数的差来表示。命题2：根据Stone-Weierstrass近似定理，令$C$属于紧空间(compact domain)$C \\subset \\mathbb{R}^{n}$, 函数$f: C \\rightarrow \\mathbb{R}$是一个连续函数，一个正实数$\\epsilon&gt;0$。存在分段线性函数(PWL function)$g$，使得$v \\in C,|f(v)-g(v)|&lt;\\epsilon$(取决于$\\epsilon$)命题3：万能近似理论：任何连续函数$f$，在紧空间上都可以使用具有两个maxout单元的maxout网络近似。证明：命题2，一个分段线性函数可以尽可能近似（取决于$\\epsilon$）一个连续函数；命题1，一个分段线性函数的表示正好和一个maxout网络完全匹配，该maxout网络具有两个maxout单元$h_1(v)$和$h_2(v)$，且k足够大的，可以达到所需的近似程度$ \\epsilon$。综上所述，我们可以得出结论：一个具有两个maxout单元的maxout网络可以任意程度的逼近任何一个紧空间内的连续函数$f(v)$。通常情况下，近似程度越大（即$\\epsilon \\rightarrow 0$），k越大（即$ k \\rightarrow \\infty$）。1.6. maxout与relurelu表达式$h_{i}(x)=\\operatorname{relu}\\left(x^{T} W_{\\cdots i}+b_{i}\\right)=\\max \\left(x^{T} W_{\\cdots i}+b_{i}, 0\\right)$maxout表达式$h_{i}(x)=\\max _{j \\in[1, k]}\\left(x^{T} W \\ldots i j+b_{i j}\\right)$唯一区别relu使用的max(x,0)是对隐层每一个单元执行的与0比较最大化操作maxout是对$k$个“隐隐层”单元的值执行最大化操作(k为最大池化步长,max pooling stride。一般最大池化步长与k相等，如果步长小，则会有重叠最大池化)（一种实现方式2-4-1，maxout是对5个“隐隐层”单元的值执行最大化操作。如果将“隐隐层”单元在隐层展开，那么隐层就有20个“隐隐层”单元，maxout做的就是在这20个中每5个取一个最大值作为最后的隐层单元，最后的隐层单元仍然为4个。实现的时候，可以将隐层单元数设置为20个，权重维度（2，20）偏置维度（1，20），然后在20个中每5个取一个最大值得到4个隐层单元。）1.7. 模型平均单层softmax有对模型进行平均的能力，但是通过观察，多层模型中使用dropout也存在这样的模型平均，只是有拟合精度的问题。训练中使用dropout使得maxout单元有了更大的输入附近的线性区域，因为每个子模型都要预测输出，每个maxout单元就要学习输出相同的预测而不管哪些输入被丢弃。改变dropout mask将经常明显移动有效输入，从而决定了输入被映射到分段线性函数的哪一段。使用dropout训练的maxout具有一种特性，即当dropout mask改变时每个maxout单元的最大化滤波器相对很少变化。maxout网络中的线性和最大化操作可以让dropout的拟合模型平均的精度很高。而一般的激活函数几乎处处都是弯曲的，因而dropout的拟合模型平均的精度不高。1.8. 优化训练中使用dropout时，maxout的优化性能比relu+max pooling好dropout使用更大的步长最有效，使得目标函数有持续的波动性。而一般的SGD会使用更小的步长，来使得目标函数平滑的下降。dropout快速的探索着许多不同的方向然后拒绝那些损害性能的方向，而SGD缓慢而平稳的朝向最可能的方向移动。实验中SGD使得relu饱和在0值的时间少于5%，而dropout则超过60%。由于relu激活函数中的0值是一个常数，这就会阻止梯度在这些单元上传播（无论正向还是反向），这也就使得这些单元很难再次激活，这会导致很多单元由激活转变为非激活。而maxout就不会存在这样的问题，梯度在maxout单元上总是能够传播，即使maxout出现了0值，但是这些0值是参数的函数可以被改变，从而maxout单元总是激活的。单元中较高比例的且不易改变的0值会损害优化性能。dropout要求梯度随着dropout mask的改变而明显改变，而一旦梯度几乎不随着dropout mask的改变而改变时，dropout就简化成为了SGD。relu网络的低层部分会有梯度衰减的问题（梯度的方差在高层较大而反向传播到低层后较小）。maxout更好的将变化的信息反向传播到低层并帮助dropout以类似bagging的方式训练低层参数。relu则由于饱和使得梯度损失，导致dropout在低层的训练类似于一般的SGD。1.9. 参考资料Paper—-Maxout NetworksCSD—-Maxout NetworksCSDN—-论文笔记_Maxout Networks"},{"title":"Conditional Generative Adversarial Nets阅读笔记","date":"2020-02-07T03:14:42.000Z","url":"/2020/02/07/2014-Conditional-Generative-Adversarial-Nets阅读笔记/","tags":["深度学习","论文阅读"],"categories":["深度学习论文阅读"],"content":"1. Conditional Generative Adversarial Nets1.1. 摘要1.2. 介绍1.3. 条件对抗网络1.3.1. 符号定义1.3.2. 知识回顾——生成对抗网络1.3.3. 直观感受1.3.4. 目标函数1.3.5. 对抗1.4. 实验1.4.1. 单模式——MNIST1.4.2. 多模式——MIR Flickr1.5. 参考资料1. Conditional Generative Adversarial NetsarXiv:1411.1784 [cs.LG]tensorflow2代码：. 摘要在GAN的基础上引入标签y，同时使用在生成器和判别器中.可以应用于多模态模型中。1.2. 介绍生成对抗网络规避了棘手的概率计算不需要使用马尔科夫链，仅使用反向传播算法去获得梯度训练时不需要推断，可以轻松的将各种因素和相互作用纳入模型但无条件生成模型无法控制生成的数据，给模型加入附加信息可以知道数据的生成1.3. 条件对抗网络1.3.1. 符号定义$x$ $\\rightarrow$ 真实数据$y$ $\\rightarrow$ 标签（辅助信息）$z$ $\\rightarrow$ 噪音（生成器的输入数据）$p_x$ $\\rightarrow$ 真实数据的分布$p_{z}(z)$ $\\rightarrow$ 原始噪音数据的分布$p_g$ $\\rightarrow$ 经过生成器后数据的分布$G()$ $\\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\\theta_{g}$$D()$ $\\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\\theta_{d}$$G(z;\\theta_{g})$ $\\rightarrow$ 将噪音$z$映射到新的数据空间$D(x ; \\theta_{d})$ $\\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）1.3.2. 知识回顾——生成对抗网络生成器G，判别器D，相互对抗使目标函数，达到最优。\\min _{G}\\max _{ D } V(D,G)={ \\mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \\mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]1.3.3. 直观感受1.3.4. 目标函数\\min _{G}\\max _{ D } V(D,G)={ \\mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x|y)] + { \\mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z|y)))]和原始GAN相近，只是G，D在y的条件下生成或判别1.3.5. 对抗生成器G通过z，y联合生成图片判别器D在y的条件下判别G(z)主要是在y条件下的MinMax Game1.4. 实验1.4.1. 单模式——MNIST1.4.2. 多模式——MIR Flickr1.5. 参考资料Paper—-Conditional Generative Adversarial Nets知乎—-《Conditional Generative Adversarial Nets》阅读笔记CSDN—-Conditional Generative Adversarial Nets论文翻译CSDN—-Conditional Generative Adversarial Nets论文笔记"},{"title":"Generative Adversarial Nets阅读笔记","date":"2020-02-05T03:14:42.000Z","url":"/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/","tags":["深度学习","论文阅读"],"categories":["深度学习论文阅读"],"content":"1. Generative Adversarial Nets1.1. 摘要1.2. 介绍1.3. 对抗网络1.3.1. 符号定义1.3.2. 极大似然估计1.3.3. 目标函数1.3.4. 对抗1.3.5. Loss Function1.3.6. 具体算法过程1.4. 改进1.4.1. G替代版的Loss Function1.5. 补充知识1.5.1. 信息量1.5.2. 信息熵1.5.3. 交叉熵1.5.4. KL散度(Kullback–Leibler散度，相对熵)1.5.5. JS散度(Jensen-Shannon散度)1.6. 理论结果1.6.1. 最优判别器D：$D^{*}(x) =\\frac{P_{\\text {data}}(x)}{P_{\\text {data}}(x)+P_{G}(x)}$1.6.2. 最优生成器：$p_{g}=p_{\\text {data }}$1.6.3. 定理1：全局最优1.6.4. 算法的收敛性1.7. 优势和劣势1.7.1. 优势1.7.2. 劣势1.8. 结论和未来研究方向1.9. 参考资料1. Generative Adversarial NetsarXiv:1406.2661 [stat.ML]tensorflow2代码：. 摘要通过对抗过程估计生成模型的框架，同时训练两个模型：生成模型G用来获取数据分布判别模型D估计样本来自训练数据而不是G的概率G的训练目标是为了最大化D产生错误的概率在任意函数G和D的空间中存在唯一的解，其中G恢复训练数据分布，并且D处处都等于$\\frac{1}{2}$。1.2. 介绍最成功的的模型之一就是判别式模型通常它们将高维丰富的感知器输入映射到类标签上。主要是基于反向传播和丢弃算法来实现的，特别是具有特别良好梯度的分段线性单元。对抗网络生成模型通过将随机噪声传输到多层感知机来生成样本的特例判别模型通过多层感知机去判别一个样本是来自模型分布还是数据分布生成模型和判别模型互相对抗可以仅使用非常成熟的反向传播和丢弃算法训练两个模型，生成模型在生成样本时只使用前向传播算法。并且不需要近似推理和马尔可夫链作为前提。1.3. 对抗网络对抗模型框架是最直接的应用是多层感知机1.3.1. 符号定义$x$ $\\rightarrow$ 真实数据$z$ $\\rightarrow$ 噪音（生成器的输入数据）$p_x$ $\\rightarrow$ 真实数据的分布$p_{z}(z)$ $\\rightarrow$ 原始噪音数据的分布$p_g$ $\\rightarrow$ 经过生成器后数据的分布$G()$ $\\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\\theta_{g}$$D()$ $\\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\\theta_{d}$$G(z;\\theta_{g})$ $\\rightarrow$ 将噪音$z$映射到新的数据空间$D(x ; \\theta_{d})$ $\\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）1.3.2. 极大似然估计对于真实数据$x$和生成数据$G(z)$，经过判别器判别后的，$D$认为$x$是真样本的概率为$D(x)$，$D$认为$G(z)$是假样本的概率为$1-D(G(z))$，那么对于$D$有$log$似然函数为：L=log[D(x)*(1-D(G(z)))] \\tag{1}1.3.3. 目标函数\\min _{G}\\max _{ D } V(D,G)={ \\mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \\mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] \\tag{2}$D(x)$和$D(G(z))$分别表示$x$和$G(z)$经过判别器$D$的判别后，$D$认为输入样本是真样本的概率，则$1-D(G(z))$表示$D$将假样本判断为假的概率；那么，真实的概率分布与$D$判断出来的情况列表如下：$D$$D$将真样本$x$判断为真的概率:$D(x)$$D$将假样本$G(z)$判断为假的概率:$1-D(G(z))$真实情况真样本$x$为真的概率:1假样本$G(z)$为假的概率:1用交叉熵作为目标函数$1*log[D(x)]对应第一项$$1*log[1-D(G(z))]$对应第二项Note:$D$输出的是概率，那么$D$的输出层的激活函数必须是$sigmoid$1.3.4. 对抗判别器$D$的目标要尽可能把真的样本判断为真，对应最大化第一项：${ E }_{ x ～ { p }_  { data } (x) }[logD(x)]$把假的样本判断为假，对应最大化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $总之，也就是说判别器$D$要最大化目标函数；生成器$G$的目标要尽可能的让$D$将生成的假样本判断为真，对应最小化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $总之，也就是说生成器$G$要最小化目标函数；总的来说，这是一个MinMax Game；Note:实际训练当中，训练$G$的时候$D$的参数是固定的，$G$并不干扰$D$对真实数据的判断，$G$需要$D$的正确引导，$G$只是不断提升自己生成数据的能力。1.3.5. Loss Function$D$的损失函数（最小化）：Loss_D = -[1*logD(x) + 1*log(1-D(G(z)))] \\tag{3}$G$的损失函数（最小化）：Loss_G = 0*logD(x) + 1*log(1-D(G(z)))=log(1-D(G(z))) \\tag{4}1.3.6. 具体算法过程Note：生成对抗网络的minibatch随机梯度下降训练 先更新$D$，再更新$G$，只有$D$有了正确的判断能力，$G$才能按照$D$的指示来更新;可以设置一个超参数k来协调$D$、$G$两者之间更新的次数比例，在实验中k=1，使消耗最小;在训练$G$的时候$D$的参数要固定，在训练$D$的时候$G$的参数要固定;1.4. 改进1.4.1. G替代版的Loss Function由于$G(z)$是从噪声中生成的样本，所以在最开始$G$生成的样本非常假，很容易被$D$抓出来，也就是说$D(G(z))$非常小,那么$Loss_G = log(1-D(G(z)))$就非常接近0，在反向传播的时候就不能够传播足够的梯度给$G$来更新参数，所以我们从Heuristic的角度来理解：我们本身是要最小化$D$抓出来假样本的概率，现在我们可以换成最大化$D$抓不出来的概率（$\\log D(G(z))$），也就是将$G$的损失函数换成：Loss_G=-logD(G(z))由于$D$是按照：Loss_G = log(1-D(G(z)))训练的，那么如果损失函数更换，这两项不是等价的，所以$D$给出的值就能够提供足够的梯度。Note:$Loss_G =log(1-D(G(z)))$对应的GAN叫做MMGAN$Loss_G=-logD(G(z)) $对应的GAN叫做NSGAN改进后的仍然存在些许问题，见与定理1：全局最优的Note3从函数图像上，可以直观的看出，两种损失函数的梯度变化趋势：1.5. 补充知识1.5.1. 信息量$ I(x) = -\\log {p(x)} = \\log { \\frac { 1}{ p (x) }  } $一个事件发生的概率越大，这件事情发生所包含的信息量就越小，比如说一个高富帅追求一个白富美，追到手了没有什么稀奇的，因为这是一件概率很高的事情，但是如果一个矮穷矬追求一个白富美，追到手了，这种事情发生的概率很低，其中一定有其他的原因：比如这个矮穷矬救过白富美的命或者这个矮穷矬器大活好不黏人，所以概率低的事情发生所包含的信息量大；两个相互独立的事情同时发生的信息量是两者单独发生的信息量之和。1.5.2. 信息熵信息量的均值H(x) = - \\sum _{ x } p(x)log p(x)1.5.3. 交叉熵H(P, Q) = - \\sum _{ x } p(x)log q(x)用估计编码$q(x)$近似真实编码$p(x)$需要的平均编码长度1.5.4. KL散度(Kullback–Leibler散度，相对熵)统计中的一个概念，时衡量两种概率分布的相似程度，其越小，表示两种概率分布越接近。（当P(x)和Q(x)的相似度越高，KL散度越小）对于离散的概率分布定义如下：D_{KL}(P||Q)=- \\sum _{ x } p(x)log q(x) + \\sum _{ x } p(x)log p(x) =H(P, Q)-H(P)对于连续的概率分布定义如下：D_{K L}(P \\| Q)=\\int_{-\\infty}^{\\infty} p(x) \\log \\frac{p(x)}{q(x)} d x想要将一个随机高斯噪声$z$通过一个生成网络G得到一个和性质：不对称性尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即$D(P||Q) \\not= D(Q||P)$。非负性相对熵的值是非负值，即$D(P||Q)&gt;0$。1.5.5. JS散度(Jensen-Shannon散度)D_{JS}(P||Q)={\\frac{1}{2}} KL(P||M) + {\\frac{1}{2}} KL(Q||M) \\quad \\quad M = {\\frac{1}{2}}(P+Q)不同于KL主要又两方面：值域范围JS散度的值域范围是[0,1]，相同则是0，相反为1。相较于KL，对相似度的判别更确切了。对称性即 JS(P||Q)=JS(Q||P)，从数学表达式中就可以看出。1.6. 理论结果1.6.1. 最优判别器D：$D^{*}(x) =\\frac{P_{\\text {data}}(x)}{P_{\\text {data}}(x)+P_{G}(x)}$对于给定生成器G，最大化$V(D,G)$而得出最优判别器D。原论文中价值函数可写为在$x$上的积分，即将数学期望展开为积分形式：\\begin{aligned}\\max _{ D } V(D,G)&={ E }_{ x ～ { p }_  { data } (x) }[logD(x)] + { E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]\\\\&=\\int_{x} p_{d a t a}(x) \\log D(x) \\mathrm{d} x+\\int_{z} p(z) \\log (1-D(G(z))) \\mathrm{d} z\\\\&=\\int_{x} p_{d a t a}(x) \\log D(x)+p_{G}(x) \\log (1-D(x)) \\mathrm{d} x\\end{aligned}取函数，求偏导数（对于任意的$(a, b) \\in \\mathbb{R}^{2} \\backslash\\{0,0\\}$,函数$y \\rightarrow a \\log (y)+b \\log (1-y)$在$[0,1]$中的$\\frac{a}{a+b}$处达到最大值）\\begin{aligned}f(D) &=a \\log (D)+b \\log (1-D) \\\\\\frac{d f(D)}{d D}&= a \\times \\frac{1}{D}+b \\times \\frac{1}{1-D} \\times(-1)=0 \\\\a \\times \\frac{1}{D^{*}} &= b \\times \\frac{1}{1-D^{*}} \\\\\\Leftrightarrow a \\times & (1-D^{*}) =b \\times D^{*} & \\\\\\text{得到最优判别器}&{ D }^{ * }(x)：\\\\D^{*}(x) &=\\frac{P_{\\text {data}}(x)}{P_{\\text {data}}(x)+P_{G}(x)}\\end{aligned}1.6.2. 最优生成器：$p_{g}=p_{\\text {data }}$我们知道对于$G$来说，最好的$G$是让：{ P }_{ r }(x) = { P }_{ g }(x)此时，有：{ D }^{ * }(x)=1/2也就是说最好的生成器使最好的判别器无法判别出来样本是生成样本还是真实样本。1.6.3. 定理1：全局最优定理1：当且仅当$p_{g}=p_{\\text {data }}$时，$C(G)$达到全局最小。此时，$C(G)$的值为$−log4$。注意到，判别器$D$的训练目标可以看作为条件概率$P(Y=y | x)$的最大似然估计，当$y=1$时，x来自于$p_{\\text {data }}$；当$y=0$时，$x$来自$p_{g}$。公式1中的极小化极大问题可以变形为： \\begin{aligned} C(G) &=\\max _{D} V(G, D) \\\\ &=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}}\\left[\\log D_{G}^{*}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}}\\left[\\log \\left(1-D_{G}^{*}(G(\\boldsymbol{z}))\\right)\\right] \\\\ &=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}}\\left[\\log D_{G}^{*}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{g}}\\left[\\log \\left(1-D_{G}^{*}(\\boldsymbol{x})\\right)\\right] \\\\ &=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}}\\left[\\log \\frac{p_{\\text {data }}(\\boldsymbol{x})}{P_{\\text {data }}(\\boldsymbol{x})+p_{g}(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{g}}\\left[\\log \\frac{p_{g}(\\boldsymbol{x})}{p_{\\text {data }}(\\boldsymbol{x})+p_{g}(\\boldsymbol{x})}\\right] \\\\ &=\\int_{x} p_{\\text {data}}(x) \\log \\left(\\frac{p_{\\text {data}}(x)}{p_{\\text {data}}(x)+p_{g}(x)}\\right)+p_{g}(x) \\log \\left(\\frac{p_{g}(x)}{p_{\\text {data}}(x)+p_{g}(x)}\\right) d x\\\\&=\\int_{x} p_{d a t a}(x) \\log \\left(\\frac{p_{d a t a}(x)}{\\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\\right)+p_{g}(x) \\log \\left(\\frac{p_{g}(x)}{\\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\\right) d x-\\log (4)\\\\&=\\underbrace{K L\\left(p_{\\text {data}}(x) \\| \\frac{p_{\\text {data}}(x)+p_{g}(x)}{2}\\right)}_{\\geq 0}+\\underbrace{K L\\left(p_{g}(x) \\| \\frac{p_{\\text {data}}(x)+p_{g}(x)}{2}\\right)}_{\\geq 0}-\\log (4)\\\\&=2\\underbrace{\\cdot JSD(p_{data}\\|p_{g})}_{\\geq 0}-log(4)\\\\\\min _{G} C(G)&=0+0-\\log (4)=-\\log (4)\\end{aligned}当且仅当$p_{\\text {data}}(x)=\\frac{p_{\\text {data}}(x)+p_{g}(x)}{2}$即$p_{g}=p_{\\text {data }}$时成立，此时$C(G)$达到全局最小，$C(G)$的值为$−log4$。Note1$KL$散度：$KL({ P }_{ 1 }||{ P }_{ 2 })={ P }_{ 1 }\\log { \\frac { { P }_{ 1 } }{ { P }_{ 2 } }  } $$JS$散度：$ JS({ P }_{ 1 }||{ P }_{ 2 })=\\frac { 1 }{ 2 } KL({ P }_{ 1 }||\\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } )+\\frac { 1 }{ 2 } KL({ P }_{ 2 }||\\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } ) $Note2（MMGAN）$Loss_G =log(1-D(G(z)))$当判别器$D$最优的时候，生成器$G$是在减小真实分布与生成分布之间的$JS$散度Note3（NSGAN）$Loss_G=-logD(G(z)) $ \\begin{aligned}KL({ P }_{ g }(x)||{ P }_{ r }(x))&={ P }_{ g }(x)*\\log { \\frac { { P }_{ g }(x) }{ { P }_{ r }(x) }  } \\\\ &={ P }_{ g }(x)*\\log { \\frac { { P }_{ g }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }{ { P }_{ r }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }  } \\\\ &={ P }_{ g }(x)*\\log  \\frac { 1-D^{ * }(x) }{ D^{ * }(x) } \\\\ &={ P }_{ g }(x)log[1-D^{ * }(x)]-{ P }_{ g }(x)logD^{ * }(x)\\\\-{P}_{g}(x)*logD^*(x)&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\\\Loss_{ G }&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\\\\\because {P}_{r}(x)*log[D^*(x)] &+ {P}_{g}(x)*log[1-D^*(x)]=2JS({ P }_{ r }||{ P }_{ g })-2log2\\\\\\therefore Loss_{ G }=KL({ P }_{ g }(&x)||{ P }_{ r }(x))-2JS({ P }_{ r }||{ P }_{ g })+{P}_{r}(x)*log[D^*(x)]+2log2[1-D^{ * }(x)]\\end{aligned}从上面的式子可以看出KL散度和JS散度同时存在且方向相反，而JS散度和KL散度都是衡量两个分布距离的度量，且是单调性同步的函数，这样的话就会导致梯度的方向不稳定，一会儿上升一会儿下降，所以这个替代版的损失函数也不是一个好的选择。1.6.4. 算法的收敛性**命题：如果$G$和$D$有足够的性能，对于算法1中的每一步，给定$G$时，判别器能够达到它的最优，并且通过更新$p_g$来提高这个判别准则。 \\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}}\\left[\\log D_{G}^{*}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{g}}\\left[\\log \\left(1-D_{G}^{*}(\\boldsymbol{x})\\right)\\right]则$p_g$收敛为$p_{data}$。**Note优化$θ_g$而不是$p_g$本身1.7. 优势和劣势1.7.1. 优势根据实际的结果，它们看上去可以比其它模型产生了更好的样本（图像更锐利、清晰）。生成对抗式网络框架能训练任何一种生成器网络（理论上-实践中，用 REINFORCE 来训练带有离散输出的生成网络非常困难）。大部分其他的框架需要该生成器网络有一些特定的函数形式，比如输出层是高斯的。重要的是所有其他的框架需要生成器网络遍布非零质量（non-zero mass）。生成对抗式网络能学习可以仅在与数据接近的细流形（thin manifold）上生成点。不需要设计遵循任何种类的因式分解的模型，任何生成器网络和任何鉴别器都会有用。无需利用马尔科夫链反复采样，无需在学习过程中进行推断（Inference），回避了近似计算棘手的概率的难题。1.7.2. 劣势解决不收敛（non-convergence）的问题。目前面临的基本问题是：所有的理论都认为 GAN 应该在纳什均衡（Nash equilibrium）上有卓越的表现，但梯度下降只有在凸函数的情况下才能保证实现纳什均衡。当博弈双方都由神经网络表示时，在没有实际达到均衡的情况下，让它们永远保持对自己策略的调整是可能的【OpenAI Ian Goodfellow的Quora】。难以训练：崩溃问题（collapse problem）GAN模型被定义为极小极大问题，没有损失函数，在训练过程中很难区分是否正在取得进展。GAN的学习过程可能发生崩溃问题（collapse problem），生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。Improved Techniques for Training GANs无需预先建模，模型过于自由不可控。与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，即不需要formulate p(x)，而是使用一种分布直接进行采样sampling，从而真正达到理论上可以完全逼近真实数据，这也是GAN最大的优势。然而，这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了(超高维)。在GAN[Goodfellow Ian, Pouget-Abadie J] 中，每次学习参数的更新过程，被设为D更新k回，G才更新1回，也是出于类似的考虑。1.8. 结论和未来研究方向该框架允许许多直接的扩展：条件生成模型$p(x | c)$可以通过将$c$作为$G$和$D$的输入来获得。给定$x$，可以通过训练一个任意的模型来学习近似推理，以预测$z$。这和wake-sleep算法训练出的推理网络类似，但是它具有一个优势，就是在生成器训练完成后，这个推理网络可以针对固定的生成器进行训练。能够用来近似模型所有的条件概率$p\\left(\\boldsymbol{x}_{S} | \\boldsymbol{x}_{\\beta}\\right)$，其中$S$通过训练共享参数的条件模型簇的关于$x$索引的一个子集。本质上，可以使用生成对抗网络来随机拓展MP-DBM。半监督学习：当标签数据有限时，判别网络或推理网络的特征不会提高分类器效果。效率改善：为协调$G$和$D$设计更好的方法，或训练期间确定更好的分布来采样$z$，能够极大的加速训练。1.9. 参考资料Paper—-Generative Adversarial Nets知乎—-GAN入门理解及公式推导CSDN—-GAN论文阅读——原始GAN（基本概念及理论推导）CSDN—-KL散度、JS散度以及交叉熵对比CSDN—-Generative Adversarial Nets论文笔记+代码解析CSDN—-Generative Adversarial Nets（译）Github—-andyhujinzhao/Generative_Adversarial_Nets"},{"title":"欢迎到我的博客= =（测试ing）","date":"2019-06-02T03:14:42.000Z","url":"/2019/06/02/欢迎到我的博客= =（测试ing）/","tags":["PS3","Games"],"content":"[toc]123352223s"},{"title":"404 Not Found：该页无法显示","date":"2019-06-04T11:08:41.025Z","url":"/404/index.html","content":"&lt;!DOCTYPE html&gt;                      404                                                                                                                                                             "},{"title":"categories","date":"2019-06-02T10:45:50.000Z","url":"/categories/index.html"},{"title":"links","date":"2019-06-04T10:41:06.923Z","url":"/links/index.html"},{"title":"about","date":"2019-06-04T09:41:17.000Z","url":"/about/index.html","content":"幻华的博客"},{"title":"Gallery","date":"2019-06-04T10:31:01.942Z","url":"/gallery/index.html"},{"title":"Search","date":"2019-06-04T10:34:38.712Z","url":"/search/index.html"},{"title":"tags","date":"2019-06-04T10:21:29.080Z","url":"/tag/index.html"},{"title":"en","date":"2019-08-13T14:18:22.146Z","url":"/en/index.html","content":"2333"}]