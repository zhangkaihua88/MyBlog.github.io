<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>幻华&#39;s Blog</title>
  
  <subtitle>无聊的人的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.zkhweb.top/"/>
  <updated>2020-02-12T15:22:06.797Z</updated>
  <id>http://www.zkhweb.top/</id>
  
  <author>
    <name>幻华(Zkher)</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DCGAN:Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/12/2016-Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/12/2016-Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks阅读笔记/</id>
    <published>2020-02-12T15:17:28.000Z</published>
    <updated>2020-02-12T15:22:06.797Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-unsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks">1. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></li><li><a href="#2-总结">2. 总结</a></li><li><a href="#3-引言">3. 引言</a></li><li><a href="#4-相关工作">4. 相关工作</a></li><li><a href="#5-dcgan构建方法cnn">5. DCGAN构建方法(CNN)</a></li><li><a href="#6-对抗式训练的细节">6. 对抗式训练的细节</a></li><li><a href="#7-参考资料">7. 参考资料</a></li></ul><!-- tocstop --><hr><h1><span id="1-unsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks">1. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</span></h1><blockquote><p>arXiv:1511.06434 [cs]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h1><span id="2-总结">2. 总结</span></h1><ul><li>要解决什么问题<ul><li>结合CNN和GAN，提出了具体的实现细节和技巧</li><li>对CNN结果进行可视化，帮助理解CNN过程</li></ul></li><li>用什么方法解决<ul><li>通过CNN构建GAN中的生成器和判别器</li><li>在CNN具体实现中，提出了一些改进方案，提高稳定性</li></ul></li><li>还存在什么问题<ul><li>稳定性差——GAN通病</li></ul></li></ul><hr><h1><span id="3-引言">3. 引言</span></h1><ul><li>提出并评估了一系列卷积GAN体系结构拓扑上的约束条件，这些约束条件使得它们在大多数情况下可以稳定地训练。我们将这种架构称为Deep Convolutional GANs（DCGAN）</li><li>使用图像分类任务上训练出来的判别器和其他的非监督算法做了比较</li><li>对GAN学习到的特征做出了可视化，并经验性的证明了特殊的特征表征了特殊的对象</li><li>针对生成器，我们提出了一个很有趣的算法向量，这个向量能很简单的在语义层面上操作生成样例的质量</li></ul><hr><h1><span id="4-相关工作">4. 相关工作</span></h1><ul><li><p>无监督的表征学习</p><ul><li>一个经典的非监督表征学习手段是做出数据聚类，之后利用聚类结果来改善分类结果。</li><li>训练自编码器（卷积式的自编码器）都能将图像作成紧编码，并且尽可能的通过解码器还原图像<ul><li>分离编码中向量的意义和位置</li><li>分析编码的梯度结构</li></ul></li></ul></li><li><p>生成自然图像</p><ul><li>参数化领域<br>  是在图像数据库下做匹配，经常对成批的图像做匹配，它在纹理合成，超分辨率重建和in-paiting中用的较多。</li><li>非参数化领域</li></ul></li><li><p>CNN内部的可视化<br>使用反卷积，过滤最大激活，可以逼近网络中每一个卷积滤波器的结果</p></li></ul><hr><h1><span id="5-dcgan构建方法cnn">5. DCGAN构建方法(CNN)</span></h1><ul><li>全卷积网络<br>  使用<strong>逐步卷积替代确定性的空间池化函数</strong>,允许网络学习自身上采样(upsampling)或下采样(downsampling)方式（生成器G/判别器D）。在网络中，所有的pooling层使用步幅卷积(判别网络)和微步幅度卷积(生成网络)进行替换。</li><li>在卷积特征之上消除全连接层<br>  例如全局平均池化，全局平均pooling增强了模型稳定性，但减缓了收敛速度</li><li><p>批量归一化(Batch Normalization)<br>  将每个单元的输入都标准化为0均值与单位方差</p><ul><li>改进了训练问题</li><li><p>缓解了深层网络中的梯度溢出问题</p><p>但实际上，这种方法在深层的生成器中被证明是不适用的，它会<strong>导致生成器反复震荡生成单点数据</strong>。但是，将所有层都进行BN，会导致样本震荡和模型不稳定，所以，<strong>不要在生成器的输出层和判别器的输入层上使用BN</strong>。</p></li></ul></li><li>激活函数<br>  生成器：除了最终输出层使用<code>Tanh</code>，其他都使用<code>Relu</code><br>  判别器：都是用<code>leaky relu</code>(leaky rectified activation)</li></ul><p><strong>稳定DCGAN的架构指导：</strong></p><ul><li>判别器中，使用带步长的卷基层来替换所有pooling层，生成器中使用小步长卷积来代替pooling层。 </li><li>在生成器和判别器中使用BN。 </li><li>去除深度架构中的全连接隐藏层。</li><li>生成器中，除去最后一层使用Tanh之外，每一层都使用ReLU来激活。 </li><li>判别器中，每一层都使用LeakReLU来激活。</li></ul><hr><h1><span id="6-对抗式训练的细节">6. 对抗式训练的细节</span></h1><ul><li>基本对原始数据都不进行数据增强，只是将像素值变换到[-1,1]之间（与生成器最终输出层的tanh对应）</li><li>使用Adam作为优化器，初始学习率0.0002，beta_1=0.5</li><li>leaky relu=0.2</li></ul><p>判别器的网络构造<br><img src="https://image.zkhweb.top/20200212214025.png" alt="20200212214025.png"><br><strong>常用验证unsupervised representation learning algorithms</strong> 的方法是：<br>选择某个监督学习数据集，使用训练好的模型输入数据提取特征，使用线性模型用于监督数据集任务，查看性能。</p><hr><h1><span id="7-参考资料">7. 参考资料</span></h1><p><a href="http://arxiv.org/abs/1511.06434" target="_blank" rel="noopener">Paper—-Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a><br><a href="https://blog.csdn.net/xiening0618/article/details/79417734" target="_blank" rel="noopener">CSDN—-论文翻译——无监督DCGAN做表征学习</a><br><a href="https://blog.csdn.net/qq_40667584/article/details/79690043" target="_blank" rel="noopener">CSDN—-DCGAN论文译本</a><br><a href="https://blog.csdn.net/wspba/article/details/54730871" target="_blank" rel="noopener">CSDN—-DCGAN论文笔记+源码解析</a><br><a href="https://blog.csdn.net/stalbo/article/details/79359095" target="_blank" rel="noopener">CSDN—-GAN论文阅读——DCGAN</a><br><a href="https://zhuanlan.zhihu.com/p/40126869" target="_blank" rel="noopener">知乎—-精读深度学习论文(26) DCGAN</a><br><a href="https://buptldy.github.io/2016/10/29/2016-10-29-deconv/" target="_blank" rel="noopener">个人Blog—-Transposed Convolution, Fractionally Strided Convolution or Deconvolution</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-unsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks&quot;&gt;1. Unsupervi
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>InfoGAN:Interpretable Representation Learning by Information MaximizingGenerative Adversarial Nets阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/09/2016-InfoGAN-Interpretable-Representation-Learning-by-Information-Maximizing-Generative-Adversarial-Nets%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/09/2016-InfoGAN-Interpretable-Representation-Learning-by-Information-Maximizing-Generative-Adversarial-Nets阅读笔记/</id>
    <published>2020-02-09T15:54:52.000Z</published>
    <updated>2020-02-12T15:21:53.901Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets">1. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a><ul><li><a href="#11-摘要">1.1. 摘要</a></li><li><a href="#12-引言">1.2. 引言</a></li><li><a href="#13-相关工作">1.3. 相关工作</a></li><li><a href="#14-补充知识">1.4. 补充知识</a><ul><li><a href="#141-信息量">1.4.1. 信息量</a></li><li><a href="#142-信息熵">1.4.2. 信息熵</a></li><li><a href="#143-互信息">1.4.3. 互信息</a></li></ul></li><li><a href="#15-infogan">1.5. InfoGAN</a><ul><li><a href="#151-知识回顾生成对抗网络">1.5.1. 知识回顾——生成对抗网络</a></li><li><a href="#152-符号定义">1.5.2. 符号定义</a></li><li><a href="#153-直观感受">1.5.3. 直观感受</a></li><li><a href="#154-目标函数">1.5.4. 目标函数</a></li><li><a href="#155-对抗">1.5.5. 对抗</a></li><li><a href="#156-目标函数由来">1.5.6. 目标函数由来</a></li><li><a href="#157-变分互信息最大化">1.5.7. 变分互信息最大化</a></li></ul></li><li><a href="#16-实现">1.6. 实现</a></li><li><a href="#17-实验">1.7. 实验</a><ul><li><a href="#171-互信息的最大化">1.7.1. 互信息的最大化</a></li><li><a href="#172-有区分度的表示">1.7.2. 有区分度的表示</a></li></ul></li><li><a href="#18-结论">1.8. 结论</a></li><li><a href="#19-附录解释为sleep-sleep算法">1.9. 附录——解释为“sleep-sleep”算法</a></li><li><a href="#110-参考资料">1.10. 参考资料</a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets">1. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</span></h1><blockquote><p>arXiv:1606.03657 [cs.LG]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-摘要">1.1. 摘要</span></h2><p><strong>InfoGAN</strong></p><ul><li>对生成对抗网络的信息理论扩展</li><li>完全无监督的方式学习特征分离表示</li><li>能最大化潜在变量的一小部分与观察(生成)结果之间的互信息</li></ul><p><strong>本文</strong></p><ul><li>有效优化的互信息目标的下界</li><li>InfoGAN可以学习与现有监督方法学习得到了具有竞争力的可解释性表征。</li></ul><hr><h2><span id="12-引言">1.2. 引言</span></h2><p><strong>无监督学习</strong></p><ul><li>一般可以被描述为从大量存在的未标记数据中提取数值的问题。</li><li>流行框架是<strong>表征学习</strong><ul><li>目标是使用未标记的数据来学习一种表示，以从重要语义特征中找到易于解释的要素。</li></ul></li><li>特征分离的表示对于需要知道数据的显著属性的自然任务可能是有用的</li><li>无监督学习算法必须对下游分类任务有正确的效果（在不直接接触下游任务的情况下）。</li><li>很大一部分是由生成模型驱动的。<ul><li>动力源于对生成模型能力的相信，或为观察数据“创造”某种形式的理解，并希望良好的生成模型能自动学习一个有区分度的表示，即便通过随便一个不好的表示也容易构造完美的生成模型。最突出的生成模型是变分自动编码器（VAE）和生成对抗网络（GAN）。</li></ul></li></ul><p><strong>本文</strong></p><ul><li>生成对抗网络目标进行了简单的修改，鼓励其学习可解释和有意义的表示。</li><li>通过最大化GAN噪声变量的固定小子集与观测值之间的互信息来实现，这一点相对比较直观。</li><li>增加互信息成本的生成模型是学习特征表示的有效途径。</li></ul><hr><h2><span id="13-相关工作">1.3. 相关工作</span></h2><p>现在存在大量关于无监督表示学习的工作。</p><ul><li>早期的方法是基于堆叠的（通常是去噪）自动编码器或受限玻尔兹曼机</li><li>阶梯网络，它在MNIST数据集的半监督变学习上取得了惊人的成果。</li></ul><p>此外，先前的研究试图使用监督数据来学习分离的特征表示。</p><ul><li>使用监督学习训练表示的一部分来匹配所提供的标签</li><li>弱监督方法来消除对明确标记变量的需要</li></ul><hr><h2><span id="14-补充知识">1.4. 补充知识</span></h2><h3><span id="141-信息量">1.4.1. 信息量</span></h3><p>$ I(x) = -\log {p(x)} = \log { \frac { 1}{ p (x) }  } $<br>一个事件发生的概率越大，这件事情发生所包含的信息量就越小，比如说一个高富帅追求一个白富美，追到手了没有什么稀奇的，因为这是一件概率很高的事情，但是如果一个矮穷矬追求一个白富美，追到手了，这种事情发生的概率很低，其中一定有其他的原因：比如这个矮穷矬救过白富美的命或者这个矮穷矬器大活好不黏人，所以概率低的事情发生所包含的信息量大；两个相互独立的事情同时发生的信息量是两者单独发生的信息量之和。</p><h3><span id="142-信息熵">1.4.2. 信息熵</span></h3><p>信息量的均值</p><script type="math/tex; mode=display">H(x) = - \sum _{ x } p(x)log p(x)</script><h3><span id="143-互信息">1.4.3. 互信息</span></h3><p>在信息论中，X和Y之间的互信息 $I(X;Y)$测量从随机变量Y的知识中学习的关于另一个随机变量X的“信息量”。</p><ul><li>互信息可以表示为两个熵项的差值：<script type="math/tex; mode=display">I(X;Y)=H(X)-H(X|Y)=H(Y)-H(Y|X)</script>这个定义有一个直观的解释： $I(X,Y)$是观察到 $Y$ 时， $X$的不确定性的减少量。如果 $X$ 和 $Y$ 是独立的，那么 $I(X;Y)=0$ ，因为一个变量与另一个变量毫无关系；相反，如果$X$和$Y$通过确定性可逆函数相关，则获得最大互信息。<br><img src="https://image.zkhweb.top/20200209214308.png" alt="20200209214308.png"></li></ul><hr><h2><span id="15-infogan">1.5. InfoGAN</span></h2><h3><span id="151-知识回顾生成对抗网络">1.5.1. 知识回顾——生成对抗网络</span></h3><p>生成器G，判别器D，相互对抗使目标函数，达到最优。</p><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]</script><p>但是<strong>无约束、不可控、噪声信号z很难解释等问题。</strong></p><h3><span id="152-符号定义">1.5.2. 符号定义</span></h3><p>$x$ $\rightarrow$ 真实数据<br>$y$ $\rightarrow$ 标签（辅助信息）<br>$z$ $\rightarrow$ 噪音（生成器的输入数据）<br>$c$ $\rightarrow$ 潜在代码(latent code)<br>$p_c$ $\rightarrow$ 潜在代码的分布，可以为连续分布，也可以为离散分布<br>$p_x$ $\rightarrow$ 真实数据的分布<br>$p_{z}(z)$ $\rightarrow$ 原始噪音数据的分布<br>$p_g$ $\rightarrow$ 经过生成器后数据的分布<br>$G()$ $\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\theta_{g}$<br>$D()$ $\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\theta_{d}$<br>$Q(c|x)$ $\rightarrow$ 辅助分布用于逼近后验概率$P(c|x)$<br>$G(z,c;\theta_{g})$ $\rightarrow$ 将噪音$z$和潜在代码映射到新的数据空间<br>$D(x ; \theta_{d})$ $\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）</p><h3><span id="153-直观感受">1.5.3. 直观感受</span></h3><p><img src="https://image.zkhweb.top/20200209213237.png" alt="20200209213237.png"><br>当Q与D共享参数<br><img src="https://image.zkhweb.top/20200209213913.png" alt="20200209213913.png"></p><h3><span id="154-目标函数">1.5.4. 目标函数</span></h3><script type="math/tex; mode=display">\begin{aligned}\min _{G} \max _{D} V_{I}(D, G)&=V(D, G)-\lambda I(c ; G(z, c)) \\&= { \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]-\lambda I(c ; G(z, c))\end{aligned}</script><p>和原始GAN相近，只是G中加入了潜码$c$（和$G(z,c)$有关），可以调节$c$来改变生成样式(加入了互信息的惩罚)</p><p>当用分布$Q(c|x)$逼近后验概率$P(c|x)$时，目标函数变为</p><script type="math/tex; mode=display">\min_{G,Q}\max_D V_{InfoGAN}(D,G,Q)=V(D,G)-\lambda L_I(G,Q)</script><p><strong>Note</strong>:此处的$V(D, G)$不局限于原始GAN的代价函数，可以使用其他的代价函数，以获得更好的训练</p><h3><span id="155-对抗">1.5.5. 对抗</span></h3><p>判别器$D$的目标</p><ol><li>要尽可能把真的样本判断为真，对应最大化第一项：${ E }_{ x ～ { p }_  { data } (x) }[logD(x)]$</li><li>把假的样本判断为假，对应最大化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z,c)))] $</li></ol><ul><li>总之，也就是说<strong>判别器$D$要最大化目标函数</strong>；</li></ul><p>生成器$G$的目标</p><ol><li>要尽可能的让$D$将生成的假样本判断为真，对应最小化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $</li><li>同时加入潜码$c$是为了使生成$G(z,c)$和$c$有很强的关联：$I(c ; G(z, c))$最大化，即$-\lambda I(c ; G(z, c))$($\lambda$为整数)最小</li></ol><ul><li>总之，也就是说<strong>生成器$G$要最小化目标函数</strong>；</li></ul><p>总的来说，这是一个<strong>信息正则化的MinMax Game</strong>；<br>当用分布$Q(c|x)$逼近后验概率$P(c|x)$时，InfoGAN<strong>具有互信息和超参数λ的变分正则化的MinMax Game</strong></p><h3><span id="156-目标函数由来">1.5.6. 目标函数由来</span></h3><p>为了让让网络学习到了可解释的特征表示<br>将提出将<strong>输入噪声向量分成为两部分</strong>：</p><ul><li>$z$:被视为不可压缩的噪声源；</li><li>$c$<sup><a href="#fn_1" id="reffn_1">1</a></sup>:将其称为潜在代码(latent code)，其目的在于数据分布的显著结构化的语义特征。</li></ul><p><sup><a href="#fn_1" id="reffn_1">1</a></sup>:在数学上，$c_1,c_2,…,c_L$​ 表示结构化潜在变量的集合。在其最简单的形式中，可以假设一个因式分布，由 $P\left(c_{1}, c_{2}, \ldots, c_{L}\right)=\prod_{i=1}^{L} P\left(c_{i}\right)$ 给出。为了便于表示，使用潜在代码 $c$ 来表示所有潜在变量 $c_i$​ 的联合。</p><p>但是在标准GAN中，通过找到满足 $P_G(x|c)= P_G(x)$ 的解，生成器可以自由地忽略附加潜在代码$c$ 。</p><p>提出了一种<strong>基于信息论的正则化方法</strong>：潜在码 $c$ 和生成分布 $G(z,c)$ 之间应该有很高的互信息。因此 $I(c;G(z,c))$ 应该很高。</p><p>给定任何 $x \sim P_{G}(x)$ ，希望 $P_G(c|x)$ 具有小的熵。换句话说，<strong>潜在码 $c$ 中的信息不应该在生成过程中丢失</strong>。在聚类的背景下，之前已经有过类似的互信息启发目标函数。因此，本文建议通过以下信息正则化的minimax游戏来解决问题：</p><script type="math/tex; mode=display">\min _{G} \max _{D} V_{I}(D, G)=V(D, G)-\lambda I(c ; G(z, c))</script><h3><span id="157-变分互信息最大化">1.5.7. 变分互信息最大化</span></h3><p><strong>引理1</strong>对于随机变量$X$，$Y$和函数$f(x,y)$在适当的正则条件下$\mathbb{E}_{x \sim X, y \sim Y | x}[f(x, y)]=\mathbb{E}_{x \sim X, y \sim Y\left|x, x^{\prime} \sim X\right| y\left[f\left(x^{\prime}, y\right)\right]}$</p><p><strong>证明</strong>：</p><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}_{x \sim X, y \sim Y | x}[f(x, y)] &=\int_{x} P(x) \int_{y} P(y | x) f(x, y) d y d x \\&=\int_{x} \int_{y} P(x, y) f(x, y) d y d x \\&=\int_{x} \int_{y} P(x, y) f(x, y) \int_{x^{\prime}} P\left(x^{\prime} | y\right) d x^{\prime} d y d x \\&=\int_{x} P(x) \int_{y} P(y | x) \int_{x^{\prime}} P\left(x^{\prime} | y\right) f\left(x^{\prime}, y\right) d x^{\prime} d y d x \\&=\mathbb{E}_{x \sim X, y \sim Y\left|x, x^{\prime} \sim X\right| y}\left[f\left(x^{\prime}, y\right)\right]\end{aligned}</script><p><strong>变分信息最大化</strong><br>互信息项 $I(c;G(z,c))$ 难以直接最大化，因为它先得到后验概率 $P(c|x)$ 。<br><strong>通过定义辅助分布 $Q(c|x)$ 来逼近 $P(c|x)$</strong> ，可以得到它的下界：</p><script type="math/tex; mode=display">\begin{aligned}I(c ; G(z, c)) &=H(c)-H(c | G(z, c)) \\&=\mathbb{E}_{c \sim P(c),x \sim G(z, c)}[\log P(c |x)]+H(c)\\根据引理1&=\mathbb{E}_{x \sim G(z, c)} \left[\mathbb{E}_{c^{\prime} \sim P(c | x)} \left[\log P(c^{\prime}|x) \right] \right]+H(c)\\&=\mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log P\left(c^{\prime} | x\right)\right]\right]+H(c) \\&=\mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c | x)} \left[ \frac{P(c^{\prime} | x) Q(c^{\prime} | x)}{Q(c^{\prime} | x)} \right] \right] \\&=\mathbb{E}_{x \sim G(z, c)}\left[  \mathbb{E}_{c^{\prime} \sim P(c | x)} \left[ \log \frac{P(c^{\prime} | x)}{Q(c^{\prime} | x)}\right]+ \mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]+H(c)\\&=\mathbb{E}_{x \sim G(z, c)}\left[\underbrace{D_{K L}(P(\cdot | x) \| Q(\cdot | x))}_{\geq 0}+\mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]+H(c) \\& \geq \mathbb{E}_{x \sim G(z, c)}[{\left.D_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]}+H(c)\end{aligned}</script><p>潜在编码 $H(c)$ 的熵也可以优化，因为对于常见分布，它具有简单的分析形式。然而，在本文中，通过修复潜在编码分布来选择简化的表示，并<strong>将 $H(c)$ 视为常量</strong>。</p><p><strong>引理2</strong> 对随机变量 $X$,$Y$ 和函数 $f(x,y)$ ，在合适的规则条件下： $\mathbb{E}_{x \sim X, y \sim Y | x}[f(x, y)]=\mathbb{E}_{x \sim X, y \sim Y|x, x^{\prime} \sim X| y}[f\left(x^{\prime}, y\right)]$</p><p><strong>证明</strong>：<br>通过使用引理1可以定义互信息 $I(c;G(z,c))$ 变分的下界 $L_I(G,Q)$:</p><script type="math/tex; mode=display">\begin{aligned}L_{I}(G, Q) &=E_{c \sim P(c), x \sim G(z, c)}[\log Q(c | x)]+H(c) \\&=E_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]+H(c) \\& \leq I(c ; G(z, c))\end{aligned}</script><p>注意到 $L_I(G,Q)$ 很容易用<strong>蒙特卡罗模拟近似</strong>。 特别是，可以对于 w.r.t.$Q$ 和 w.r.t.$G$ 使用重参数化技巧将 $L_I$​ 最大化。 因此， $L_I(G,Q)$ 可以添加到GAN的目标而不改变GAN的训练过程，称之为<strong>信息最大化生成对抗网络(InfoGAN)</strong>。</p><p>变分互信息最大化表明，当辅助分布 $Q$ 接近真实的后验分布 $\mathbb E_x[D_{KL}P(·|x)||Q(·|x))]→0$ 时，下限变紧了。另外，当变分下界达到离散潜码的最大值 $L_I(G,Q)= H(c)$ 时，边界变紧并且达到最大互信息。</p><hr><h2><span id="16-实现">1.6. 实现</span></h2><p><strong>整体</strong></p><ul><li>将辅助分布 $Q$ 参数化为神经网络。 <ul><li>在大多数实验中， $Q$ 和 $D$ <strong>共享所有卷积层</strong></li><li>存在一个最终完全连接的层以输出条件分布 $Q(c|x)$ 的参数(softmax)</li></ul></li></ul><p>这意味着InfoGAN仅向GAN添加了<strong>可忽略的计算成本</strong><br>在实验中， $L_I(G,Q)$ 总是比正常的GAN目标更快收敛</p><p><strong>分类的潜在代码$c_i$​</strong></p><ul><li>使用非线性softmax来表示 $Q(c_i|x)$<ul><li>对于连续潜在代码 $c_j$​ ，根据真正的后验概率 $P(c_j|x)$ ，有更多的选项。可以简单地将 $Q(c_j|x)$ 作为因子化的高斯来处理就足够了。</li></ul></li><li><p><strong>c为离散变量</strong><br>$Q(c|x)$可以表示为一个神经网络$Q(X)$的输出</p><script type="math/tex; mode=display">\begin{aligned}&\because L_{I}(G, Q)=c \cdot \log Q(G(z, c))+H(c)\\&\therefore \max L_{I}(G, Q) \text{等价于} \max c \cdot \log Q(G(z, c))\end{aligned}</script><p>其中$\cdot$表示内积，c是一个选择计算哪个$\log$的参数，$H(c)$可以消去<br><strong>$L_I(G,Q)$本质上是$x$与$G(z,x)$之间的KL散度</strong></p><script type="math/tex; mode=display">\begin{aligned}&\because \begin{aligned}D_{K L}(c \| Q(G(z, c))) &=-c \cdot \log \frac{Q(G(z, c))}{c} \\&=-c \cdot \log Q(G(z, c))+c \cdot \log c \\&=-c \cdot \log Q(G(z, c))+H(c) \\&=-L_{I}(G, Q)+2 H(c)\end{aligned}\\&\therefore \max L_{I}(G, Q) \text{等价于} \min D_{K L}(c \| Q(G(z, c)))\end{aligned}</script><p>$\min D_{K L}(c | Q(G(z, c)))$意味着减少$c$与$Q(G(z, c)$</p></li><li><p><strong>c为连续变量</strong><br>设 $Q(x)$ 输出的参数潜码 $c$ 的均值 $\mu$，标准差 $\sigma$ 分别为 $Q(x)_{\mu}$ 和$Q(x)_{\sigma}$，那么对于参数潜码 c</p><script type="math/tex; mode=display">\begin{aligned}&L_{I}(G, Q)=\mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]+H(c) \\&\because p(x)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}(\text{c符合正态分布;均值 $\mu$,标准差 $\sigma$})\\&\therefore \log p(c) = -\frac{(c-\mu)^{2}}{2 \sigma^{2}}-\log (\sigma \sqrt{2 \pi})\\&\therefore L_{I}(G, Q)=-\frac{\left(c-Q(x)_{\mu}\right)^{2}}{2 Q(x)_{\sigma}^{2}}-\log \left(Q(x)_{\sigma} \sqrt{2 \pi}\right)+H(c)\\&\therefore \max L_{I}(G, Q) \text{等价于} \min \left(\frac{\left(c-Q(x)_{\mu}\right)^{2}}{2 Q(x)_{\sigma}^{2}}+\log \left(Q(x)_{\sigma} \sqrt{2 \pi}\right)\right)\end{aligned}</script><p>不考虑$Q(x)_{\sigma}$的影响则</p><script type="math/tex; mode=display">\max L_{I}(G, Q) \text{等价于} \min \left(c-Q(x)_{\mu}\right)^{2}</script><p>$\min \left(c-Q(x)_{\mu}\right)^{2}$意味这减小$c$与$Q(x)_{\mu}$的差</p></li><li><p><strong>总之$L_{I}$的优化过程，实质上是以G为编码器(Encoder)，Q为解码器(Decoder)，生成图像作为要编码的码(code)，训练一个自编码器(Autoencoder)</strong></p></li></ul><p><strong>超参数 $\lambda$</strong></p><ul><li>对于<em>离散</em>的潜在代码，它很容易调整，简单地设置为1就足够。</li><li>当潜在编码包含<em>连续</em>变量时，较小的 $\lambda$ 通常用于确保包含差分熵的 $L_I(G,Q)$ 的规模与GAN目标的规模相同。</li></ul><hr><h2><span id="17-实验">1.7. 实验</span></h2><p><strong>目标</strong></p><ul><li>调查是否可以有效地最大化互信息</li><li>评估InfoGAN是否可以通过利用生成器一次仅改变一个潜在因子来学习有区分度的可解释的表示，以评估改变这样的因素是否导致生成的图像中只有一种类型的语义变化。 </li></ul><h3><span id="171-互信息的最大化">1.7.1. 互信息的最大化</span></h3><p>为了评估潜在编码 $c$ 和生成的图像 $G(z,c)$ 之间的互信息是否可以通过提出的方法有效地最大化，作者在MNIST数据集上训练InfoGAN，对潜在编码 $c$ 进行统一的分类分布 $c\sim Cat(K=10,p=0.1)$ 。在 图1 中，下限 $L_I(G,Q)$ 被快速最大化为 $H(c)\approx 2.30$ ，这意味着下限 (4) 快速紧贴到到最大的互信息。</p><p>作为基准，当没有明确促使生成图像与潜在编码最大化的互信息时，作者还训练具有辅助分布 $Q$ 的常规GAN。由于作者使用神经网络对 $Q$ 进行参数化，假设 $Q$ 可以合理地近似真实的后验概率 $P(c|x)$ ，因此在常规GAN中潜在编码和生成图像之间几乎没有互信息。作者注意到，使用不同的神经网络架构，即使在实验中没有观察到这种情况，潜在代码和生成的图像之间可能存在更高的相互信息。这种比较是为了证明在常规GAN中，不能保证生成器能够利用潜在编码。</p><h3><span id="172-有区分度的表示">1.7.2. 有区分度的表示</span></h3><p><strong>离散的c捕捉离散变换，连续的c捕捉连续变换</strong><br><strong>MNIST</strong></p><ul><li>$c_1\sim Cat(K=10,p=0.1)$ 控制数字</li><li>$c_2 \sim Unif(-1,1)$​ 控制旋转数字</li><li>$c_3 \sim Unif(-1,1)$​ 控制宽度</li></ul><p>但$c_2,c_3$​还调整其他细节，如厚度或笔触样式<br>$c$处于$-2 \sim 2$之间仍有用，表明InfoGAN学习的潜在表示可泛化</p><p><strong>Faces</strong><br>$c_i\sim Unif(-1,1),1\leq i\leq 5$<br>表示为方位角（姿势），仰角和照明等潜在因素看做连续潜在变量。</p><p><strong>CelebA</strong><br>$c_1,c_2,c_3,c_4\sim (K=20,p=0.05)$和一个连续码 $c_5\sim Unif(-1,1)$<br>代表旋转的连续编码。使用单个连续代码连续插入不同宽度的类似椅子类型。</p><p><strong>SVHN</strong><br>利用四个10维分类变量和两个均匀连续变量作为潜在代码。</p><hr><h2><span id="18-结论">1.8. 结论</span></h2><ul><li>InfoGAN完全没有监督</li><li>在具有挑战性的数据集上学习可解释和有区分度的表示。</li><li>InfoGAN在GAN之上仅增加了可忽略不计的计算成本，并且易于训练。 </li><li>使用互信息表示的核心思想可以应用于其他方法，</li></ul><hr><h2><span id="19-附录解释为sleep-sleep算法">1.9. 附录——解释为“sleep-sleep”算法</span></h2><p>InfoGAN可以看作是Helmholtz机（wake-sleep算法）：</p><ul><li>$P_{G}(x | c)$是生成分布</li><li>$Q(c|x)$识别分布</li></ul><p>提出wake-sleep算法，通过执行wake阶段和sleep阶段更新Helmholtz机</p><ul><li>wake阶段：通过优化有关生成的变分下界$\log P_G(x)$来更新<script type="math/tex; mode=display">\max _{G} \mathbb{E}_{x \sim \operatorname{Data}, c \sim Q(c | x)}\left[\log P_{G}(x | c)\right]</script></li><li>sleep阶段：通过在当前生成分布中生成样本，而不是从实际数据分布中提取样本来更新辅助分布</li></ul><p>因此，当优化代理损失函数<sup><a href="#fn_2" id="reffn_2">2</a></sup>$L_I$（关于$Q$），更新步骤正是wake-sleep算法中的sleep过程。<br>InfoGAN与Wake-sleep不同之处在于优化$L_I$（关于$Q$）生成网络G在潜在代码$P(c)$整个先前分布中使用了潜在代码$c$。由于InfoGAN在sleep过程中更新了生成器，所以可以解释为sleep-sleep算法。</p><p>这种解释突出了InfoGAN与以前生成建模技术的区别：<br>明确鼓励生成器以潜在代码传达信息，并建议将相同原理应用于其他生成模型。</p><p><sup><a href="#fn_2" id="reffn_2">2</a></sup>:代理损失函数:当原本的loss function不便计算的时候，我们就会考虑使用surrogate loss function。</p><hr><h2><span id="110-参考资料">1.10. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1606.03657" target="_blank" rel="noopener">Paper—-InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a><br><a href="https://blog.csdn.net/hjimce/article/details/55657325" target="_blank" rel="noopener">CSDN—-深度学习（四十八）InfoGAN学习笔记</a><br><a href="https://zhuanlan.zhihu.com/p/58261928" target="_blank" rel="noopener">知乎—-InfoGAN解读</a><br><a href="https://www.inference.vc/infogan-variational-bound-on-mutual-information-twice/" target="_blank" rel="noopener">个人Blog—-InfoGAN: using the variational bound on mutual information (twice)</a><br><a href="https://www.jiqizhixin.com/articles/2018-10-29-21" target="_blank" rel="noopener">机器之心—-InfoGAN：一种无监督生成方法 | 经典论文复现</a><br><a href="http://www.pianshen.com/article/448358405/" target="_blank" rel="noopener">程序员大本营—-【GAN ZOO翻译系列】InfoGAN： Interpretable Representation Learning by Information Maximizing GAN</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets&quot;&gt;1. In
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>Maxout Networks阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/07/2013-Maxout-Networks%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/07/2013-Maxout-Networks阅读笔记/</id>
    <published>2020-02-07T03:14:42.000Z</published>
    <updated>2020-02-07T07:38:00.448Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-maxout-networks">1. Maxout Networks</a><ul><li><a href="#11-摘要">1.1. 摘要</a></li><li><a href="#12-介绍">1.2. 介绍</a></li><li><a href="#13-回顾droupt">1.3. 回顾droupt</a></li><li><a href="#14-模型maxout描述">1.4. 模型maxout描述</a></li><li><a href="#15-maxout是一个通用的近似器">1.5. Maxout是一个通用的近似器</a></li><li><a href="#16-maxout与relu">1.6. maxout与relu</a></li><li><a href="#17-模型平均">1.7. 模型平均</a></li><li><a href="#18-优化">1.8. 优化</a></li><li><a href="#19-参考资料">1.9. 参考资料</a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-maxout-networks">1. Maxout Networks</span></h1><blockquote><p>arXiv:1302.4389 [stat.ML]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-摘要">1.1. 摘要</span></h2><p>maxout：</p><ul><li>旨在通过dropout来加快优化过程，并提高准确度（与drop共同使用）；</li><li><strong>模型的输出是模型输入的最大值</strong></li></ul><hr><h2><span id="12-介绍">1.2. 介绍</span></h2><p>dropout</p><ul><li>可以训练集成模型</li><li>共享参数并近似的对这些模型的预测进行了平均</li><li><strong>一种不加区分的适用型工具，几乎可以应用于任何模型，都可以产生一定的性能改进。</strong></li></ul><p>dropout与SDG</p><ul><li><strong>dropout</strong><br>在更新时最有效的方式是<strong>使用更大的步长</strong>，因为这样可以在不同的训练子集上对不同的模型有明显的影响来使得目标函数有持续的波动性，理想情况下整个训练过程就类似于使用<a href="https://zh.wikipedia.org/wiki/Bagging%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">bagging</a>来训练集成的模型（带有参数共享的约束）。</li><li>SGD<br>更新时一般会使用更小的步长，来使得目标函数平滑的下降。</li></ul><p>对于深度网络模型，dropout只能作为模型平均的一种近似，显式的设计模型来最小化这种近似误差也可以提高dropout的性能。</p><hr><h2><span id="13-回顾droupt">1.3. 回顾droupt</span></h2><p>在给定输入向量$v$后，输出预测向量$y$，该构成包含了一系列的隐含层$h=\{h^{(1)},…,h^{(L)}\}$。<br>Dropout训练一组由包含$v$和$h$中变量的子集组成的所有模型组成的模型。使用同一组参数$\theta$来标识一组分组$p(y | v ; \theta, \mu)$，其中$\mu \in M$是一个二进制掩码，用来决定模型中哪些变量参与运算。<br>每次在训练集上进行训练时，我们都按照$\log p(y | v ; \theta, \mu)$的梯度对不同的$\mu$随机取样训练不同的子模型。<br>可以通过$v$和$h$和掩码的按元素相乘得到不同子模型$p(y | v ; \theta, \mu)$的实例</p><p>当集合需要将所有子模型的预测平均起来进行预测时，函数形式就变得非常重要。<br>多个指数模型的预测平均值可以简单的通过运行权重除以2的完整模型来得到。即当$p(y|v;\theta) = softmax(v^Tw+b)$时，通过重整$p(y|v;\theta,\mu)$的几何平均定义的预测分布，可以很简单的由$softmax(v^tw/2+b)$</p><p>dropout与bagging</p><ul><li>都是在不同子集上训练出不同模型</li><li>dropout只训练一次，且所有模型共享参数。像是在训练一个模型集合而不是训练单个模型，每次的更新都必须有重大的影响，这样才能使得该子模型能较好的拟合当前的输入$v$</li><li>bagging对子模型的输出进行算数平均，dropout是几何平均</li></ul><hr><h2><span id="14-模型maxout描述">1.4. 模型maxout描述</span></h2><ul><li>是一个简单的前馈框架模型</li><li>使用了一个新的激活函数：<strong>maxout unit</strong><br>给定一个输入$ x \in \mathbb{R}^d$ （$x$可能是输入$v$,也可能是隐含层的状态），maxout隐含层的采用下式实现：<script type="math/tex; mode=display">h_{i}(x)=\max _{j \in[1, k]} z_{i j}</script>其中$z_{i j}=x^{T} W_{\ldots i j}+b_{i j}$，$x \in \mathbb{R}^{d \times n}$，$W \in \mathbb{R}^{d \times m \times k}$, $b \in \mathbb{R}^{m \times k}$。$w$，$b$都是可训练参数。$k$表示每个隐藏节点对应k个“隐隐层”节点，这$k$个“隐隐层”节点都是线性输出。maxout的每个节点就从这k个“隐隐层”节点输出值中取最大的。所以使得maxout为一种非线性的变换</li></ul><p><strong>Notes</strong></p><ul><li>maxout因为有参数同时为非线性，所以既可以是网络也可以是激活器</li><li>单个maxout单元可以解释为对任意凸函数进行线性逼近。（任意的凸函数都可由分段线性函数来拟合）。它在每处都是局部线性的（k个“隐隐层”节点都是线性的，取其最大值则为局部线性，分段的个数与k值有关），而一般的激活函数都有明显的曲率。<br><img src="https://image.zkhweb.top/20200206171729.png" alt="20200206171729.png"></li><li>如同MLP一样，maxout网络也可以拟合任意连续函数。只要maxout单元含有任意多个“隐隐层”节点，那么只要两个隐层的maxout网络就可以实现任意连续函数的近似。</li><li>maxout网络不仅可以学习到隐层之间的关系，还可以学习到每个隐层单元的激活函数。</li><li>maxout放弃了传统激活函数的设计，它产生的表示不再是稀疏的，但是它的梯度是稀疏的，且dropout可以将它稀疏化。</li><li>maxout没有上下界，所以让它在某一端饱和是零概率事件。</li><li>如果训练时使用dropout，则dropout操作在矩阵相乘之前，而并不对max操作的输入执行dropout。</li><li>使用maxout会默认一个先验：样本集是凸集可分的。</li></ul><hr><h2><span id="15-maxout是一个通用的近似器">1.5. Maxout是一个通用的近似器</span></h2><p><img src="https://image.zkhweb.top/20200206165136.png" alt="20200206165136.png"></p><p><strong>命题1</strong>：对于任意的正整数$m$,$n$,都存在两组$n+1$维的实数参数向量$[W_{1j}, b_{1j}], j \in [1, k]$和$[W_{2j}, b_{2j}], j \in [1, k]$使得<script type="math/tex">g(v) = h_1(v) - h_(v)</script> 即任意的分段连续函数都可以使用两个凸分段线性函数的差来表示。</p><p><strong>命题2</strong>：根据Stone-Weierstrass近似定理，令$C$属于<a href="https://zh.wikipedia.org/wiki/%E7%B4%A7%E7%A9%BA%E9%97%B4" target="_blank" rel="noopener">紧空间(compact domain)</a>$C \subset \mathbb{R}^{n}$, 函数$f: C \rightarrow \mathbb{R}$是一个连续函数，一个正实数$\epsilon&gt;0$。存在分段线性函数(PWL function)$g$，使得$v \in C,|f(v)-g(v)|&lt;\epsilon$(取决于$\epsilon$)</p><p><strong>命题3</strong>：万能近似理论：任何连续函数$f$，在紧空间上都可以使用具有两个maxout单元的maxout网络近似。</p><p><strong>证明</strong>：</p><ul><li>命题2，一个分段线性函数可以尽可能近似（取决于$\epsilon$）一个连续函数；</li><li>命题1，一个分段线性函数的表示正好和一个maxout网络完全匹配，该maxout网络具有两个maxout单元$h_1(v)$和$h_2(v)$，且k足够大的，可以达到所需的近似程度$ \epsilon$。</li><li>综上所述，我们可以得出结论：一个具有两个maxout单元的maxout网络可以任意程度的逼近任何一个紧空间内的连续函数$f(v)$。通常情况下，近似程度越大（即$\epsilon \rightarrow 0$），k越大（即$ k \rightarrow \infty$）。</li></ul><hr><h2><span id="16-maxout与relu">1.6. maxout与relu</span></h2><p>relu表达式$h_{i}(x)=\operatorname{relu}\left(x^{T} W_{\cdots i}+b_{i}\right)=\max \left(x^{T} W_{\cdots i}+b_{i}, 0\right)$<br>maxout表达式$h_{i}(x)=\max _{j \in[1, k]}\left(x^{T} W \ldots i j+b_{i j}\right)$</p><p>唯一区别</p><ul><li>relu使用的max(x,0)是对隐层每一个单元执行的与0比较最大化操作</li><li>maxout是对$k$个“隐隐层”单元的值执行最大化操作(k为最大池化步长,max pooling stride。一般最大池化步长与k相等，如果步长小，则会有重叠最大池化)<br>（<strong>一种实现方式</strong>2-4-1，maxout是对5个“隐隐层”单元的值执行最大化操作。如果将“隐隐层”单元在隐层展开，那么隐层就有20个“隐隐层”单元，maxout做的就是在这20个中每5个取一个最大值作为最后的隐层单元，最后的隐层单元仍然为4个。实现的时候，可以将隐层单元数设置为20个，权重维度（2，20）偏置维度（1，20），然后在20个中每5个取一个最大值得到4个隐层单元。）</li></ul><hr><h2><span id="17-模型平均">1.7. 模型平均</span></h2><ul><li>单层softmax有对模型进行平均的能力，但是通过观察，多层模型中使用dropout也存在这样的模型平均，只是有拟合精度的问题。</li><li>训练中使用dropout使得maxout单元有了更大的输入附近的线性区域，因为每个子模型都要预测输出，每个maxout单元就要学习输出相同的预测而不管哪些输入被丢弃。改变dropout mask将经常明显移动有效输入，从而决定了输入被映射到分段线性函数的哪一段。使用dropout训练的maxout具有一种特性，即当dropout mask改变时每个maxout单元的最大化滤波器相对很少变化。</li><li><strong>maxout网络中的线性和最大化操作可以让dropout的拟合模型平均的精度很高</strong>。而一般的激活函数几乎处处都是弯曲的，因而dropout的拟合模型平均的精度不高。</li></ul><hr><h2><span id="18-优化">1.8. 优化</span></h2><ul><li>训练中使用dropout时，maxout的优化性能比relu+max pooling好</li><li>dropout使用更大的步长最有效，使得目标函数有持续的波动性。而一般的SGD会使用更小的步长，来使得目标函数平滑的下降。dropout快速的探索着许多不同的方向然后拒绝那些损害性能的方向，而SGD缓慢而平稳的朝向最可能的方向移动。</li><li>实验中SGD使得relu饱和在0值的时间少于5%，而dropout则超过60%。由于relu激活函数中的0值是一个常数，这就会阻止梯度在这些单元上传播（无论正向还是反向），这也就使得这些单元很难再次激活，这会导致很多单元由激活转变为非激活。而maxout就不会存在这样的问题，梯度在maxout单元上总是能够传播，即使maxout出现了0值，但是这些0值是参数的函数可以被改变，从而maxout单元总是激活的。单元中较高比例的且不易改变的0值会损害优化性能。</li><li>dropout要求梯度随着dropout mask的改变而明显改变，而一旦梯度几乎不随着dropout mask的改变而改变时，dropout就简化成为了SGD。relu网络的低层部分会有梯度衰减的问题（梯度的方差在高层较大而反向传播到低层后较小）。maxout更好的将变化的信息反向传播到低层并帮助dropout以类似bagging的方式训练低层参数。relu则由于饱和使得梯度损失，导致dropout在低层的训练类似于一般的SGD。</li></ul><hr><h2><span id="19-参考资料">1.9. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1302.4389" target="_blank" rel="noopener">Paper—-Maxout Networks</a><br><a href="https://blog.csdn.net/zhufenghao/article/details/52527047" target="_blank" rel="noopener">CSD—-Maxout Networks</a><br><a href="https://blog.csdn.net/maqian5/article/details/91880468" target="_blank" rel="noopener">CSDN—-论文笔记_Maxout Networks</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-maxout-networks&quot;&gt;1. Maxout Networks&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#11-摘要&quot;&gt;1.1. 摘要&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#12-介绍&quot;&gt;1.2
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>CGAN:Conditional Generative Adversarial Nets阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/07/2014-Conditional-Generative-Adversarial-Nets%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/07/2014-Conditional-Generative-Adversarial-Nets阅读笔记/</id>
    <published>2020-02-07T03:14:42.000Z</published>
    <updated>2020-02-12T15:20:50.050Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-conditional-generative-adversarial-nets">1. Conditional Generative Adversarial Nets</a><ul><li><a href="#11-摘要">1.1. 摘要</a></li><li><a href="#12-介绍">1.2. 介绍</a></li><li><a href="#13-条件对抗网络">1.3. 条件对抗网络</a><ul><li><a href="#131-符号定义">1.3.1. 符号定义</a></li><li><a href="#132-知识回顾生成对抗网络">1.3.2. 知识回顾——生成对抗网络</a></li><li><a href="#133-直观感受">1.3.3. 直观感受</a></li><li><a href="#134-目标函数">1.3.4. 目标函数</a></li><li><a href="#135-对抗">1.3.5. 对抗</a></li></ul></li><li><a href="#14-实验">1.4. 实验</a><ul><li><a href="#141-单模式mnist">1.4.1. 单模式——MNIST</a></li><li><a href="#142-多模式mir-flickr">1.4.2. 多模式——MIR Flickr</a></li></ul></li><li><a href="#15-参考资料">1.5. 参考资料</a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-conditional-generative-adversarial-nets">1. Conditional Generative Adversarial Nets</span></h1><blockquote><p>arXiv:1411.1784 [cs.LG]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-摘要">1.1. 摘要</span></h2><p>在GAN的基础上引入标签y，同时使用在生成器和判别器中.<br>可以应用于<a href="https://www.jiqizhixin.com/graph/technologies/4468592f-93e9-4575-be91-fd64c0c6afe0" target="_blank" rel="noopener">多模态模型</a>中。</p><hr><h2><span id="12-介绍">1.2. 介绍</span></h2><p>生成对抗网络</p><ul><li>规避了棘手的概率计算</li><li>不需要使用马尔科夫链，仅使用反向传播算法去获得梯度</li><li>训练时不需要推断，可以轻松的将各种因素和相互作用纳入模型</li></ul><p>但<strong>无条件生成模型无法控制生成的数据</strong>，给模型加入附加信息可以知道数据的生成</p><hr><h2><span id="13-条件对抗网络">1.3. 条件对抗网络</span></h2><h3><span id="131-符号定义">1.3.1. 符号定义</span></h3><p>$x$ $\rightarrow$ 真实数据<br>$y$ $\rightarrow$ 标签（辅助信息）<br>$z$ $\rightarrow$ 噪音（生成器的输入数据）<br>$p_x$ $\rightarrow$ 真实数据的分布<br>$p_{z}(z)$ $\rightarrow$ 原始噪音数据的分布<br>$p_g$ $\rightarrow$ 经过生成器后数据的分布<br>$G()$ $\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\theta_{g}$<br>$D()$ $\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\theta_{d}$<br>$G(z;\theta_{g})$ $\rightarrow$ 将噪音$z$映射到新的数据空间<br>$D(x ; \theta_{d})$ $\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）</p><h3><span id="132-知识回顾生成对抗网络">1.3.2. 知识回顾——生成对抗网络</span></h3><p>生成器G，判别器D，相互对抗使目标函数，达到最优。</p><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]</script><h3><span id="133-直观感受">1.3.3. 直观感受</span></h3><p><img src="https://image.zkhweb.top/20200205211839.png" alt="20200205211839.png"></p><h3><span id="134-目标函数">1.3.4. 目标函数</span></h3><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x|y)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z|y)))]</script><p>和原始GAN相近，只是G，D在y的条件下生成或判别</p><h3><span id="135-对抗">1.3.5. 对抗</span></h3><p>生成器G通过z，y联合生成图片<br>判别器D在y的条件下判别G(z)<br>主要是在y条件下的MinMax Game</p><hr><h2><span id="14-实验">1.4. 实验</span></h2><h3><span id="141-单模式mnist">1.4.1. 单模式——MNIST</span></h3><h3><span id="142-多模式mir-flickr">1.4.2. 多模式——MIR Flickr</span></h3><hr><h2><span id="15-参考资料">1.5. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1411.1784" target="_blank" rel="noopener">Paper—-Conditional Generative Adversarial Nets</a><br><a href="https://zhuanlan.zhihu.com/p/23648795" target="_blank" rel="noopener">知乎—-《Conditional Generative Adversarial Nets》阅读笔记</a><br><a href="https://blog.csdn.net/Chaolei3/article/details/78870858" target="_blank" rel="noopener">CSDN—-Conditional Generative Adversarial Nets论文翻译</a><br><a href="https://blog.csdn.net/wspba/article/details/54666907" target="_blank" rel="noopener">CSDN—-Conditional Generative Adversarial Nets论文笔记</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-conditional-generative-adversarial-nets&quot;&gt;1. Conditional Generative Adversarial Nets&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>GAN:Generative Adversarial Nets阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/</id>
    <published>2020-02-05T03:14:42.000Z</published>
    <updated>2020-02-12T15:20:54.936Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-generative-adversarial-nets">1. Generative Adversarial Nets</a><ul><li><a href="#11-摘要">1.1. 摘要</a></li><li><a href="#12-介绍">1.2. 介绍</a></li><li><a href="#13-对抗网络">1.3. 对抗网络</a><ul><li><a href="#131-符号定义">1.3.1. 符号定义</a></li><li><a href="#132-极大似然估计">1.3.2. 极大似然估计</a></li><li><a href="#133-目标函数">1.3.3. 目标函数</a></li><li><a href="#134-对抗">1.3.4. 对抗</a></li><li><a href="#135-loss-function">1.3.5. Loss Function</a></li><li><a href="#136-具体算法过程">1.3.6. 具体算法过程</a></li></ul></li><li><a href="#14-改进">1.4. 改进</a><ul><li><a href="#141-g替代版的loss-function">1.4.1. G替代版的Loss Function</a></li></ul></li><li><a href="#15-补充知识">1.5. 补充知识</a><ul><li><a href="#151-信息量">1.5.1. 信息量</a></li><li><a href="#152-信息熵">1.5.2. 信息熵</a></li><li><a href="#153-交叉熵">1.5.3. 交叉熵</a></li><li><a href="#154-kl散度kullbackleibler散度相对熵">1.5.4. KL散度(Kullback–Leibler散度，相对熵)</a></li><li><a href="#155-js散度jensen-shannon散度">1.5.5. JS散度(Jensen-Shannon散度)</a></li></ul></li><li><a href="#16-理论结果">1.6. 理论结果</a><ul><li><a href="#161-最优判别器ddx-fracp_text-dataxp_text-dataxp_gx">1.6.1. 最优判别器D：$D^{*}(x) =\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}$</a></li><li><a href="#162-最优生成器p_gp_text-data">1.6.2. 最优生成器：$p_{g}=p_{\text {data }}$</a></li><li><a href="#163-定理1全局最优">1.6.3. 定理1：全局最优</a></li><li><a href="#164-算法的收敛性">1.6.4. 算法的收敛性</a></li></ul></li><li><a href="#17-优势和劣势">1.7. 优势和劣势</a><ul><li><a href="#171-优势">1.7.1. 优势</a></li><li><a href="#172-劣势">1.7.2. 劣势</a></li></ul></li><li><a href="#18-结论和未来研究方向">1.8. 结论和未来研究方向</a></li><li><a href="#19-参考资料">1.9. 参考资料</a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-generative-adversarial-nets">1. Generative Adversarial Nets</span></h1><blockquote><p>arXiv:1406.2661 [stat.ML]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-摘要">1.1. 摘要</span></h2><p>通过对抗过程估计生成模型的框架，同时训练两个模型：<br><strong>生成模型G</strong>用来获取数据分布<br><strong>判别模型D</strong>估计样本来自训练数据而不是G的概率<br>G的训练目标是为了最大化D产生错误的概率<br>在任意函数G和D的空间中存在唯一的解，其中G恢复训练数据分布，并且D处处都等于$\frac{1}{2}$。</p><hr><h2><span id="12-介绍">1.2. 介绍</span></h2><p>最成功的的模型之一就是<strong>判别式模型</strong><br>通常它们将高维丰富的感知器输入映射到类标签上。<br>主要是<strong>基于反向传播和丢弃算法</strong>来实现的，特别是具有特别良好梯度的分段线性单元。</p><p>对抗网络</p><ol><li>生成模型通过将随机噪声传输到多层感知机来生成样本的特例</li><li>判别模型通过多层感知机去判别一个样本是来自模型分布还是数据分布</li><li>生成模型和判别模型互相对抗</li></ol><p>可以仅使用非常成熟的反向传播和丢弃算法训练两个模型，生成模型在生成样本时只使用前向传播算法。并且不需要近似推理和马尔可夫链作为前提。</p><hr><h2><span id="13-对抗网络">1.3. 对抗网络</span></h2><p>对抗模型框架是最直接的应用是多层感知机</p><h3><span id="131-符号定义">1.3.1. 符号定义</span></h3><p>$x$ $\rightarrow$ 真实数据<br>$z$ $\rightarrow$ 噪音（生成器的输入数据）<br>$p_x$ $\rightarrow$ 真实数据的分布<br>$p_{z}(z)$ $\rightarrow$ 原始噪音数据的分布<br>$p_g$ $\rightarrow$ 经过生成器后数据的分布<br>$G()$ $\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\theta_{g}$<br>$D()$ $\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\theta_{d}$<br>$G(z;\theta_{g})$ $\rightarrow$ 将噪音$z$映射到新的数据空间<br>$D(x ; \theta_{d})$ $\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）</p><h3><span id="132-极大似然估计">1.3.2. 极大似然估计</span></h3><p>对于真实数据$x$和生成数据$G(z)$，经过判别器判别后的，$D$认为$x$是真样本的概率为$D(x)$，$D$认为$G(z)$是假样本的概率为$1-D(G(z))$，那么对于$D$有$log$似然函数为：</p><script type="math/tex; mode=display">L=log[D(x)*(1-D(G(z)))] \tag{1}</script><h3><span id="133-目标函数">1.3.3. 目标函数</span></h3><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] \tag{2}</script><p>$D(x)$和$D(G(z))$分别表示$x$和$G(z)$经过判别器$D$的判别后，$D$认为输入样本是真样本的概率，则$1-D(G(z))$表示$D$将假样本判断为假的概率；那么，真实的概率分布与$D$判断出来的情况列表如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">$D$</th><th style="text-align:center">$D$将真样本$x$判断为真的概率:$D(x)$</th><th style="text-align:center">$D$将假样本$G(z)$判断为假的概率:$1-D(G(z))$</th></tr></thead><tbody><tr><td style="text-align:center">真实情况</td><td style="text-align:center">真样本$x$为真的概率:1</td><td style="text-align:center">假样本$G(z)$为假的概率:1</td></tr><tr><td style="text-align:center">用交叉熵作为目标函数</td><td style="text-align:center">$1*log[D(x)]对应第一项$</td><td style="text-align:center">$1*log[1-D(G(z))]$对应第二项</td></tr></tbody></table></div><p><strong>Note:$D$输出的是概率，那么$D$的输出层的激活函数必须是$sigmoid$</strong></p><h3><span id="134-对抗">1.3.4. 对抗</span></h3><p>判别器$D$的目标</p><ol><li>要尽可能把真的样本判断为真，对应最大化第一项：${ E }_{ x ～ { p }_  { data } (x) }[logD(x)]$</li><li>把假的样本判断为假，对应最大化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $</li></ol><ul><li>总之，也就是说<strong>判别器$D$要最大化目标函数</strong>；</li></ul><p>生成器$G$的目标</p><ol><li>要尽可能的让$D$将生成的假样本判断为真，对应最小化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $</li></ol><ul><li>总之，也就是说<strong>生成器$G$要最小化目标函数</strong>；</li></ul><p>总的来说，这是一个<strong>MinMax Game</strong>；<br><strong>Note:实际训练当中，训练$G$的时候$D$的参数是固定的，$G$并不干扰$D$对真实数据的判断，$G$需要$D$的正确引导，$G$只是不断提升自己生成数据的能力。</strong></p><h3><span id="135-loss-function">1.3.5. Loss Function</span></h3><p>$D$的损失函数（最小化）：</p><script type="math/tex; mode=display">Loss_D = -[1*logD(x) + 1*log(1-D(G(z)))] \tag{3}</script><p>$G$的损失函数（最小化）：</p><script type="math/tex; mode=display">Loss_G = 0*logD(x) + 1*log(1-D(G(z)))=log(1-D(G(z))) \tag{4}</script><h3><span id="136-具体算法过程">1.3.6. 具体算法过程</span></h3><p><img src="https://image.zkhweb.top/20190816181118.png" alt="20190816181118.png"></p><p>Note：</p><ol><li>生成对抗网络的minibatch随机梯度下降训练 </li><li>先更新$D$，再更新$G$，只有$D$有了正确的判断能力，$G$才能按照$D$的指示来更新;</li><li>可以设置一个超参数k来协调$D$、$G$两者之间更新的次数比例，在实验中k=1，使消耗最小;</li><li>在训练$G$的时候$D$的参数要固定，在训练$D$的时候$G$的参数要固定;</li></ol><hr><h2><span id="14-改进">1.4. 改进</span></h2><h3><span id="141-g替代版的loss-function">1.4.1. G替代版的Loss Function</span></h3><p>由于$G(z)$是从噪声中生成的样本，所以在最开始$G$生成的样本非常假，很容易被$D$抓出来，也就是说$D(G(z))$非常小,那么$Loss_G = log(1-D(G(z)))$就非常接近0，在反向传播的时候就不能够传播足够的梯度给$G$来更新参数，所以我们从Heuristic的角度来理解：我们本身是要最小化$D$抓出来假样本的概率，现在我们可以换成最大化$D$抓不出来的概率（$\log D(G(z))$），也就是将$G$的损失函数换成：</p><script type="math/tex; mode=display">Loss_G=-logD(G(z))</script><p>由于$D$是按照：</p><script type="math/tex; mode=display">Loss_G = log(1-D(G(z)))</script><p>训练的，那么如果损失函数更换，这两项不是等价的，所以$D$给出的值就能够提供足够的梯度。</p><p><strong>Note:<br>$Loss_G =log(1-D(G(z)))$对应的GAN叫做MMGAN<br>$Loss_G=-logD(G(z)) $对应的GAN叫做NSGAN<br>改进后的仍然存在些许问题，见与<a href="#1">定理1：全局最优的Note3</a></strong></p><p>从函数图像上，可以直观的看出，两种损失函数的梯度变化趋势：<br><img src="https://image.zkhweb.top/损失函数图像" alt="损失函数图像"></p><hr><h2><span id="15-补充知识">1.5. 补充知识</span></h2><h3><span id="151-信息量">1.5.1. 信息量</span></h3><p>$ I(x) = -\log {p(x)} = \log { \frac { 1}{ p (x) }  } $<br>一个事件发生的概率越大，这件事情发生所包含的信息量就越小，比如说一个高富帅追求一个白富美，追到手了没有什么稀奇的，因为这是一件概率很高的事情，但是如果一个矮穷矬追求一个白富美，追到手了，这种事情发生的概率很低，其中一定有其他的原因：比如这个矮穷矬救过白富美的命或者这个矮穷矬器大活好不黏人，所以概率低的事情发生所包含的信息量大；两个相互独立的事情同时发生的信息量是两者单独发生的信息量之和。</p><h3><span id="152-信息熵">1.5.2. 信息熵</span></h3><p>信息量的均值</p><script type="math/tex; mode=display">H(x) = - \sum _{ x } p(x)log p(x)</script><h3><span id="153-交叉熵">1.5.3. 交叉熵</span></h3><script type="math/tex; mode=display">H(P, Q) = - \sum _{ x } p(x)log q(x)</script><p>用估计编码$q(x)$近似真实编码$p(x)$需要的平均编码长度</p><h3><span id="154-kl散度kullbackleibler散度相对熵">1.5.4. KL散度(Kullback–Leibler散度，相对熵)</span></h3><p>统计中的一个概念，时衡量两种概率分布的相似程度，其越小，表示两种概率分布越接近。（当P(x)和Q(x)的相似度越高，KL散度越小）<br>对于离散的概率分布定义如下：</p><script type="math/tex; mode=display">D_{KL}(P||Q)=- \sum _{ x } p(x)log q(x) + \sum _{ x } p(x)log p(x) =H(P, Q)-H(P)</script><p>对于连续的概率分布定义如下：</p><script type="math/tex; mode=display">D_{K L}(P \| Q)=\int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} d x</script><p>想要将一个随机高斯噪声$z$通过一个生成网络G得到一个和</p><ul><li>性质：<ol><li>不对称性<br>尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即$D(P||Q) \not= D(Q||P)$。</li><li>非负性<br>相对熵的值是非负值，即$D(P||Q)&gt;0$。</li></ol></li></ul><h3><span id="155-js散度jensen-shannon散度">1.5.5. JS散度(Jensen-Shannon散度)</span></h3><script type="math/tex; mode=display">D_{JS}(P||Q)={\frac{1}{2}} KL(P||M) + {\frac{1}{2}} KL(Q||M) \quad \quad M = {\frac{1}{2}}(P+Q)</script><ul><li>不同于KL主要又两方面：<ol><li>值域范围<br>JS散度的值域范围是[0,1]，相同则是0，相反为1。相较于KL，对相似度的判别更确切了。</li><li>对称性<br>即 JS(P||Q)=JS(Q||P)，从数学表达式中就可以看出。</li></ol></li></ul><hr><h2><span id="16-理论结果">1.6. 理论结果</span></h2><h3><span id="161-最优判别器ddx-fracp_text-dataxp_text-dataxp_gx">1.6.1. 最优判别器D：$D^{*}(x) =\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}$</span></h3><p>对于给定生成器G，最大化$V(D,G)$而得出最优判别器D。原论文中价值函数可写为在$x$上的积分，即将数学期望展开为积分形式：</p><script type="math/tex; mode=display">\begin{aligned}\max _{ D } V(D,G)&={ E }_{ x ～ { p }_  { data } (x) }[logD(x)] + { E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]\\&=\int_{x} p_{d a t a}(x) \log D(x) \mathrm{d} x+\int_{z} p(z) \log (1-D(G(z))) \mathrm{d} z\\&=\int_{x} p_{d a t a}(x) \log D(x)+p_{G}(x) \log (1-D(x)) \mathrm{d} x\end{aligned}</script><p>取函数，求偏导数<br>（对于任意的$(a, b) \in \mathbb{R}^{2} \backslash\{0,0\}$,函数$y \rightarrow a \log (y)+b \log (1-y)$在$[0,1]$中的$\frac{a}{a+b}$处达到最大值）</p><script type="math/tex; mode=display">\begin{aligned}f(D) &=a \log (D)+b \log (1-D) \\\frac{d f(D)}{d D}&= a \times \frac{1}{D}+b \times \frac{1}{1-D} \times(-1)=0 \\a \times \frac{1}{D^{*}} &= b \times \frac{1}{1-D^{*}} \\\Leftrightarrow a \times & (1-D^{*}) =b \times D^{*} & \\\text{得到最优判别器}&{ D }^{ * }(x)：\\D^{*}(x) &=\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}\end{aligned}</script><h3><span id="162-最优生成器p_gp_text-data">1.6.2. 最优生成器：$p_{g}=p_{\text {data }}$</span></h3><p>我们知道对于$G$来说，最好的$G$是让：</p><script type="math/tex; mode=display">{ P }_{ r }(x) = { P }_{ g }(x)</script><p>此时，有：</p><script type="math/tex; mode=display">{ D }^{ * }(x)=1/2</script><p>也就是说最好的生成器使最好的判别器无法判别出来样本是生成样本还是真实样本。</p><h3><span id="163-定理1全局最优">1.6.3. 定理1：全局最优</span></h3><p><strong>定理1：当且仅当$p_{g}=p_{\text {data }}$时，$C(G)$达到全局最小。此时，$C(G)$的值为$−log4$。</strong><br>注意到，判别器$D$的训练目标可以看作为条件概率$P(Y=y | x)$的最大似然估计，当$y=1$时，x来自于$p_{\text {data }}$；当$y=0$时，$x$来自$p_{g}$。公式1中的极小化极大问题可以变形为： </p><script type="math/tex; mode=display">\begin{aligned} C(G) &=\max _{D} V(G, D) \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}}\left[\log \left(1-D_{G}^{*}(G(\boldsymbol{z}))\right)\right] \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right] \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log \frac{p_{\text {data }}(\boldsymbol{x})}{P_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \frac{p_{g}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right] \\ &=\int_{x} p_{\text {data}}(x) \log \left(\frac{p_{\text {data}}(x)}{p_{\text {data}}(x)+p_{g}(x)}\right)+p_{g}(x) \log \left(\frac{p_{g}(x)}{p_{\text {data}}(x)+p_{g}(x)}\right) d x\\&=\int_{x} p_{d a t a}(x) \log \left(\frac{p_{d a t a}(x)}{\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\right)+p_{g}(x) \log \left(\frac{p_{g}(x)}{\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\right) d x-\log (4)\\&=\underbrace{K L\left(p_{\text {data}}(x) \| \frac{p_{\text {data}}(x)+p_{g}(x)}{2}\right)}_{\geq 0}+\underbrace{K L\left(p_{g}(x) \| \frac{p_{\text {data}}(x)+p_{g}(x)}{2}\right)}_{\geq 0}-\log (4)\\&=2\underbrace{\cdot JSD(p_{data}\|p_{g})}_{\geq 0}-log(4)\\\min _{G} C(G)&=0+0-\log (4)=-\log (4)\end{aligned}</script><p>当且仅当$p_{\text {data}}(x)=\frac{p_{\text {data}}(x)+p_{g}(x)}{2}$即$p_{g}=p_{\text {data }}$时成立，此时$C(G)$达到全局最小，$C(G)$的值为$−log4$。<br><strong>Note1</strong><br>$KL$散度：$KL({ P }_{ 1 }||{ P }_{ 2 })={ P }_{ 1 }\log { \frac { { P }_{ 1 } }{ { P }_{ 2 } }  } $<br>$JS$散度：$ JS({ P }_{ 1 }||{ P }_{ 2 })=\frac { 1 }{ 2 } KL({ P }_{ 1 }||\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } )+\frac { 1 }{ 2 } KL({ P }_{ 2 }||\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } ) $<br><strong>Note2（MMGAN）</strong>$Loss_G =log(1-D(G(z)))$<br>当判别器$D$最优的时候，生成器$G$是在减小真实分布与生成分布之间的$JS$散度<br><strong><span id="1">Note3（NSGAN）</span></strong>$Loss_G=-logD(G(z)) $ </p><script type="math/tex; mode=display">\begin{aligned}KL({ P }_{ g }(x)||{ P }_{ r }(x))&={ P }_{ g }(x)*\log { \frac { { P }_{ g }(x) }{ { P }_{ r }(x) }  } \\ &={ P }_{ g }(x)*\log { \frac { { P }_{ g }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }{ { P }_{ r }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }  } \\ &={ P }_{ g }(x)*\log  \frac { 1-D^{ * }(x) }{ D^{ * }(x) } \\ &={ P }_{ g }(x)log[1-D^{ * }(x)]-{ P }_{ g }(x)logD^{ * }(x)\\-{P}_{g}(x)*logD^*(x)&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\Loss_{ G }&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\\because {P}_{r}(x)*log[D^*(x)] &+ {P}_{g}(x)*log[1-D^*(x)]=2JS({ P }_{ r }||{ P }_{ g })-2log2\\\therefore Loss_{ G }=KL({ P }_{ g }(&x)||{ P }_{ r }(x))-2JS({ P }_{ r }||{ P }_{ g })+{P}_{r}(x)*log[D^*(x)]+2log2[1-D^{ * }(x)]\end{aligned}</script><p><strong>从上面的式子可以看出KL散度和JS散度同时存在且方向相反，而JS散度和KL散度都是衡量两个分布距离的度量，且是单调性同步的函数，这样的话就会导致梯度的方向不稳定，一会儿上升一会儿下降，所以这个替代版的损失函数也不是一个好的选择。</strong></p><h3><span id="164-算法的收敛性">1.6.4. 算法的收敛性</span></h3><p>**命题：如果$G$和$D$有足够的性能，对于算法1中的每一步，给定$G$时，判别器能够达到它的最优，并且通过更新$p_g$来提高这个判别准则。 </p><script type="math/tex; mode=display">\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right]</script><p>则$p_g$收敛为$p_{data}$。**</p><!-- 证明.如上述准则，考虑$V(G, D)=U\left(p_{g}, D\right)$为关于$p_{g}$的函数。注意到$U\left(p_{g}, D\right)$为$p_g$的凸函数。该凸函数上确界的一次导数包括达到最大值处的该函数的导数。换句话说，如果$f(x)=\sup _{\alpha \in \mathcal{A}} f_{\alpha}(x)$且对于每一个$α$，$f_α(x)$ 是关于$x$的凸函数，那么如果$\beta=\operatorname{argsup}_{\alpha \in \mathcal{A}} f_{\alpha}(x)$，则$\partial f_{\beta}(x) \in \partial f$。这等价于给定对应的$G$和最优的$D$，计算$p_g$的梯度更新。如定理1所证明，$\sup _{D} U\left(p_{g}, D\right)$是关于$p_g$的凸函数且有唯一的全局最优解，因此，当$p_g$的更新足够小时，$p_g$收敛到$p_x$，证毕。 --><p><strong>Note</strong><br>优化$θ_g$而不是$p_g$本身</p><hr><h2><span id="17-优势和劣势">1.7. 优势和劣势</span></h2><h3><span id="171-优势">1.7.1. 优势</span></h3><ul><li>根据实际的结果，它们看上去可以比其它模型产生了更好的样本（图像更锐利、清晰）。</li><li>生成对抗式网络框架能训练任何一种生成器网络（理论上-实践中，用 REINFORCE 来训练带有离散输出的生成网络非常困难）。大部分其他的框架需要该生成器网络有一些特定的函数形式，比如输出层是高斯的。重要的是所有其他的框架需要生成器网络遍布非零质量（non-zero mass）。生成对抗式网络能学习可以仅在与数据接近的细流形（thin manifold）上生成点。</li><li>不需要设计遵循任何种类的因式分解的模型，任何生成器网络和任何鉴别器都会有用。</li><li>无需利用马尔科夫链反复采样，无需在学习过程中进行推断（Inference），回避了近似计算棘手的概率的难题。</li></ul><h3><span id="172-劣势">1.7.2. 劣势</span></h3><ul><li><p>解决不收敛（non-convergence）的问题。<br>目前面临的基本问题是：所有的理论都认为 GAN 应该在纳什均衡（Nash equilibrium）上有卓越的表现，但梯度下降只有在凸函数的情况下才能保证实现纳什均衡。当博弈双方都由神经网络表示时，在没有实际达到均衡的情况下，让它们永远保持对自己策略的调整是可能的【OpenAI Ian Goodfellow的Quora】。</p></li><li><p>难以训练：崩溃问题（collapse problem）<br>GAN模型被定义为极小极大问题，没有损失函数，在训练过程中很难区分是否正在取得进展。GAN的学习过程可能发生崩溃问题（collapse problem），生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。<a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">Improved Techniques for Training GANs</a></p></li><li><p>无需预先建模，模型过于自由不可控。<br>与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，即不需要formulate p(x)，而是使用一种分布直接进行采样sampling，从而真正达到理论上可以完全逼近真实数据，这也是GAN最大的优势。然而，这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了(超高维)。在GAN[Goodfellow Ian, Pouget-Abadie J] 中，每次学习参数的更新过程，被设为D更新k回，G才更新1回，也是出于类似的考虑。</p></li></ul><hr><h2><span id="18-结论和未来研究方向">1.8. 结论和未来研究方向</span></h2><p>该框架允许许多直接的扩展：</p><ul><li>条件生成模型$p(x | c)$可以通过将$c$作为$G$和$D$的输入来获得。</li><li>给定$x$，可以通过训练一个任意的模型来学习近似推理，以预测$z$。这和wake-sleep算法训练出的推理网络类似，但是它具有一个优势，就是在生成器训练完成后，这个推理网络可以针对固定的生成器进行训练。</li><li>能够用来近似模型所有的条件概率$p\left(\boldsymbol{x}_{S} | \boldsymbol{x}_{\beta}\right)$，其中$S$通过训练共享参数的条件模型簇的关于$x$索引的一个子集。本质上，可以使用生成对抗网络来随机拓展MP-DBM。</li><li>半监督学习：当标签数据有限时，判别网络或推理网络的特征不会提高分类器效果。</li><li>效率改善：为协调$G$和$D$设计更好的方法，或训练期间确定更好的分布来采样$z$，能够极大的加速训练。</li></ul><hr><h2><span id="19-参考资料">1.9. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener">Paper—-Generative Adversarial Nets</a><br><a href="https://zhuanlan.zhihu.com/p/28853704" target="_blank" rel="noopener">知乎—-GAN入门理解及公式推导</a><br><a href="https://blog.csdn.net/stalbo/article/details/79283399" target="_blank" rel="noopener">CSDN—-GAN论文阅读——原始GAN（基本概念及理论推导）</a><br><a href="https://blog.csdn.net/FrankieHello/article/details/80614422" target="_blank" rel="noopener">CSDN—-KL散度、JS散度以及交叉熵对比</a><br><a href="https://blog.csdn.net/wspba/article/details/54582391" target="_blank" rel="noopener">CSDN—-Generative Adversarial Nets论文笔记+代码解析</a><br><a href="https://blog.csdn.net/wspba/article/details/54577236" target="_blank" rel="noopener">CSDN—-Generative Adversarial Nets（译）</a><br><a href="https://github.com/andyhujinzhao/Generative_Adversarial_Nets" target="_blank" rel="noopener">Github—-andyhujinzhao/Generative_Adversarial_Nets</a></p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-generative-adversarial-nets&quot;&gt;1. Generative Adversarial Nets&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#11-摘要&quot;&gt;1.1. 摘要&lt;/a&gt;&lt;/li&gt;

      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>欢迎到我的博客= =（测试ing）</title>
    <link href="http://www.zkhweb.top/2019/06/02/%E6%AC%A2%E8%BF%8E%E5%88%B0%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2=%20=%EF%BC%88%E6%B5%8B%E8%AF%95ing%EF%BC%89/"/>
    <id>http://www.zkhweb.top/2019/06/02/欢迎到我的博客= =（测试ing）/</id>
    <published>2019-06-02T03:14:42.000Z</published>
    <updated>2019-06-05T05:02:16.045Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h2><span id="123">123</span></h2><h3><span id="352">352</span></h3><p>223s</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h2&gt;&lt;span id=&quot;123&quot;&gt;123&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span id=&quot;352&quot;&gt;352&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;223s&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="PS3" scheme="http://www.zkhweb.top/tags/PS3/"/>
    
      <category term="Games" scheme="http://www.zkhweb.top/tags/Games/"/>
    
  </entry>
  
</feed>
