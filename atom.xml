<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>幻华&#39;s Blog</title>
  
  <subtitle>无聊的人的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.zkhweb.top/"/>
  <updated>2020-05-01T13:20:22.864Z</updated>
  <id>http://www.zkhweb.top/</id>
  
  <author>
    <name>幻华(Zkher)</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>常用小书签(bookmarklet)</title>
    <link href="http://www.zkhweb.top/2020/05/01/bookmarklet/bookmarklet%20%E5%8F%91%E5%B8%83/"/>
    <id>http://www.zkhweb.top/2020/05/01/bookmarklet/bookmarklet 发布/</id>
    <published>2020-05-01T13:14:42.000Z</published>
    <updated>2020-05-01T13:20:22.864Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#常用小书签bookmarklet">常用小书签(bookmarklet)</a><ul><li><a href="#视频倍速播放">视频倍速播放</a></li></ul></li></ul><!-- tocstop --><hr><p>[toc]</p><h1><span id="常用小书签bookmarklet">常用小书签(bookmarklet)</span></h1><hr><h2><span id="视频倍速播放">视频倍速播放</span></h2><p><a href="javascript:(function(){var speed = 2;var videos = document.querySelectorAll('video');for (var video of videos) {var playspeed = video.playbackRate;if (playspeed != speed){video.playbackRate = speed;} else if (playspeed == speed){video.playbackRate = 1;}}})())" target="_blank" rel="noopener">2倍速</a><br><a href="javascript:alert('hi');" target="_blank" rel="noopener">1.5倍速</a></p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">javascript:(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">var</span> speed = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">var</span> videos = <span class="built_in">document</span>.querySelectorAll(<span class="string">'video'</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> video <span class="keyword">of</span> videos) &#123;</span><br><span class="line">        <span class="keyword">var</span> playspeed = video.playbackRate;</span><br><span class="line">        <span class="keyword">if</span> (playspeed != speed)&#123;</span><br><span class="line">            video.playbackRate = speed;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (playspeed == speed)&#123;</span><br><span class="line">            video.playbackRate = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)();</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#常用小书签bookmarklet&quot;&gt;常用小书签(bookmarklet)&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#视频倍速播放&quot;&gt;视频倍速播放&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- to
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>WGAN:Wasserstein GAN</title>
    <link href="http://www.zkhweb.top/2020/02/24/2017-Wasserstein-GAN/"/>
    <id>http://www.zkhweb.top/2020/02/24/2017-Wasserstein-GAN/</id>
    <published>2020-02-24T12:43:09.000Z</published>
    <updated>2020-03-01T13:59:41.964Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-wasserstein-gan">1. Wasserstein GAN</a><ul><li><a href="#11-总结">1.1. 总结</a></li><li><a href="#12-引言">1.2. 引言</a></li><li><a href="#13-不同的距离定义">1.3. 不同的距离定义</a></li><li><a href="#14-wasserstein-gan">1.4. Wasserstein GAN</a></li><li><a href="#15-实验结果">1.5. 实验结果</a></li></ul></li><li><a href="#2-总结">2. 总结</a></li><li><a href="#3-参考资料">3. 参考资料</a></li></ul><!-- tocstop --><hr><h1><span id="1-wasserstein-gan">1. Wasserstein GAN</span></h1><blockquote><p>arXiv:1701.07875 [cs, stat]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-总结">1.1. 总结</span></h2><p>一句话解释：W距离就是在最优路径规划下把生成拉向真实的最小消耗。</p><ul><li><p>要解决什么问题</p><ul><li>判别器越好，生成器梯度消失越严重</li><li>判别器越好的情况下，生成的模型多样性不够</li><li><p>训练困难，生成器和判别器的loss无法指示训练进程。</p><p>原始GAN的最小化loss等价于最小化生成器和判别器的JS散度和KL散度，当生成器数据和判别器数据无重叠时或者重叠可忽略时，无论相距多远,JS散度都是常数log2，经公式计算最终导致梯度为0，即梯度消失，Wasserstein距离优越性在于即便两个部分没有重叠，W距离仍能够反映远近。</p></li></ul></li><li><p>用什么方法解决<br>  <img src="https://image.zkhweb.top/20200213234842.png" alt="20200213234842.png"></p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c，即Lipschitz限制</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul></li><li><p>优势</p><ul><li>将GAN的训练过程，也就是loss指示了训练进程</li><li>解决了生成样本的多样性的问题</li><li>使用DCGAN的网络结构，不需要重新设计新的网络结构</li></ul></li><li>还存在什么问题<br>clipx项</li></ul><hr><h2><span id="12-引言">1.2. 引言</span></h2><p>$\mathbb{P}_r$ ==&gt; 概率分布<br>$P_r$ ==&gt; 概率密度</p><p>非监督式学习</p><p>学习一个概率分布，通常我们是学习这个分布的概率密度函数，假设概率密度函数存在，且由多个参数组成即$\left(P_{\theta}\right)_{\theta \in \mathbb{R}^{d}}$，已知该分布下点集为$\left\{x^{(i)}\right\}_{i=1}^{m}$,那么认为这些点既然出现了，就是概率最大的（相当于极大似然的思想）。问题就变成了求解使得</p><script type="math/tex; mode=display">\max _{\theta \in \mathbb{R}^{d}} \frac{1}{m} \sum_{i=1}^{m} \log P_{\theta}\left(x^{(i)}\right)</script><p>如果实际的资料分布$\mathbb{P}_r$提供机率密度，而$\mathbb{P}_\theta$是参数化的机率密度$P_\theta$，然后，两个资料分布渐近，这相当于最小化Kullback-Leibler divergence(KL-Divergence) $KL(\mathbb{P}_r||\mathbb{P}_\theta)$</p><p>但是在现实生活中，处理的分布的支撑集都是低位流形的。两个分布的重叠部分测度为0，那么KL散度就没办法衡量了</p><p>典型的纠正办法（不可取），就是给模型的分布加一个有很大宽度的高斯分布，使得模型的分布覆盖所有样本，但是这也造成了生成图像时产生了非常大噪声。</p><p>相比估计$\mathbb{P}_r$的概率密度，且这个密度函数还不一定存在，使用另一种方法$g_{\theta}: \mathcal{Z} \rightarrow \mathcal{X}$, $Z$为随机变量，概率密度为$p(z)$,通过改变$\theta$使得分布$\mathbb{P}_\theta$接近于真实分布$\mathbb{P}_r$</p><ul><li>与密度不同，可以表示局限于低维流形的分布</li><li>容易生成样本的能力通常比知道密度的数值有用（例如，在考虑给定输入图像的情况下，当考虑输出图像的条件分布时，在图像超分辨率或语义分割中）。 </li></ul><p>通常，很难在给定任意高维密度的情况下生成样本</p><p>本文，致力于测量两种分布之间距离的不同方法，或等效的定义距离或散度<br><strong>这种距离最重要的不同时对概率分布收敛的影响程度</strong></p><p><strong>分布收敛定义</strong>：距离或散度$\rho\left(\mathbb{P}_{\theta}, \mathbb{P}_{r}\right)$，分布序列$\left(\mathbb{P}_{t}\right)_{t \in \mathbb{N}}$收敛当且仅当存在一分布$\mathbb{P}_\infty$使得$\rho\left(\mathbb{P}_{t}, \mathbb{P}_{\infty}\right)$取域0.取决于距离的精确度</p><p><strong>连续的定义</strong>：如果参数$\theta_t$收敛为$\theta$时，那么分布$\mathbb{P}_{\theta_d}$就收敛到$\mathbb{P}_{\theta}$</p><p>分布$\mathbb{P}_{\theta_d}$是否收敛<strong>依赖于选择计算距离的方法</strong>，之所以给出连续的定义，是想说如果损失函数$\theta \mapsto \rho\left(\mathbb{P}_{\theta}, \mathbb{P}_{r}\right)$连续等同于$\theta \mapsto \rho\left(\mathbb{P}_{\theta}\right)$连续</p><ul><li>Section 2 各种距离的比较</li><li>Section 3 应用EM定义WGAN</li><li>Section 4 WGAN实战</li></ul><hr><h2><span id="13-不同的距离定义">1.3. 不同的距离定义</span></h2><p>$\mathcal{X}$ ==&gt; compact metric set(像的空间[0,1]$^d$)<br>$\sum$ ==&gt; $\mathcal{X}$上所以的Borel子集的集合<br>$Porb{\mathcal{X}}$ ==&gt; $\mathcal{X}$上的概率密度空间<br>$\mathbb{P}_r,\mathbb{P}_g \in Prob{\mathcal{X}}$</p><ul><li>Total Variation(TV) distance<script type="math/tex; mode=display">  \delta\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)=\sup _{A \in \Sigma}\left|\mathbb{P}_{r}(A)-\mathbb{P}_{g}(A)\right|</script></li><li>Kullback-Leibler(KL) divergence<script type="math/tex; mode=display">  K L\left(\mathbb{P}_{r} \| \mathbb{P}_{g}\right)=\int \log \left(\frac{P_{r}(x)}{P_{g}(x)}\right) P_{r}(x) d \mu(x)</script>  $\mathbb{P}_r,\mathbb{P}_g$假设是绝对连续的，且概率密度函数存在，服从统一测度。$P_{g}(x)=0$和$P_{r}(x)&gt;0$时，KL散度时非对称的并且可能为无限值</li><li>Jensen-Shannon(JS) divergence<script type="math/tex; mode=display">  J S\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)=K L\left(\mathbb{P}_{r} \| \mathbb{P}_{m}\right)+K L\left(\mathbb{P}_{g} \| \mathbb{P}_{m}\right)</script>  其中$\mathbb{P}_m = (\mathbb{P}_r + \mathbb{P}_g)/2$,JS散度时对称的，并且可被定义($\mu = \mathbb{P}_m$)</li><li>Earth-Mover(EM) distance(Wasserstein-1)<script type="math/tex; mode=display">  W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)=\inf _{\gamma \in \Pi\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)} \mathbb{E}_{(x, y) \sim \gamma}[\|x-y\|]</script>  $\Pi\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)$ ==&gt; 边界分别为$\mathbb{P}_r$和$\mathbb{P}_g$的联合分布$\gamma(x,y)$<br>  <strong>直观理解</strong>：$\gamma(x,y)$表示必须从$x$到$y$运输多少质量，才能将分布$\mathbb{P}_r$转换为$\mathbb{P}_g$。EM距离就是最佳传输计划的“成本”。从生成样本和真实样本中随机取出一对样本，计算他们之间的差的均值，最小的那个均值即所求。</li></ul><p><strong>简单明了的例子(学习平行线)</strong>——概率分布的序列，在EM下收敛，其他下不收敛<br>令 $Z \sim U[0,1]$,$\mathbb{P}_{0}$ be the distribution of $(0, Z) \in \mathbb{R}^{2}$, $g_{\theta}(z)=(\theta, z)$ with $\theta$ a single real parameter</p><script type="math/tex; mode=display">\begin{aligned}&W\left(\mathbb{P}_{0}, \mathbb{P}_{\theta}\right)=|\theta|\\&J S\left(\mathbb{P}_{0}, \mathbb{P}_{\theta}\right)=\left\{\begin{array}{ll}{\log 2} & {\text { if } \theta \neq 0} \\{0} & {\text { if } \theta=0}\end{array}\right.\\&K L\left(\mathbb{P}_{\theta} \| \mathbb{P}_{0}\right)=K L\left(\mathbb{P}_{0} \| \mathbb{P}_{\theta}\right)=\left\{\begin{array}{ll}{+\infty} & {\text { if } \theta \neq 0} \\{0} & {\text { if } \theta=0}\end{array}\right.\\&\text { and } \delta\left(\mathbb{P}_{0}, \mathbb{P}_{\theta}\right)=\left\{\begin{array}{ll}{1} & {\text { if } \theta \neq 0} \\{0} & {\text { if } \theta=0}\end{array}\right.\end{aligned}</script><p>当$\theta_t \rightarrow 0$,只有EM距离下序列$(\mathbb{P}_{\theta_t})_{t \in M}$收敛到$\mathbb{P}_0$</p><ul><li><p><strong>定理1</strong>：已知$\mathbb{P}_r$是空间$\mathcal{X}$上的固定分布，令$Z$为$\mathcal{Z}$空间上的随机变量(e.g. Gaussion)。令$g: \mathcal{Z} \times \mathbb{R}^{d} \rightarrow \mathcal{X}$是一个由$\theta$和$z$确定的函数$g_\theta (z)$,$\mathbb{P}_\theta$代表其分布，那么</p><ul><li>如果$g$在$\theta$上连续，$W(\mathbb{P}_r,\mathbb{P}_\theta$也连续</li><li>如果满足<strong>假设1</strong>，且$g$为Lipschitz函数，那么$W(\mathbb{P}_r,\mathbb{P}_\theta$处处连续且可谓</li><li><p>$JS(\mathbb{P}_r,\mathbb{P}_\theta)$和 all the KLs不满足上述性质</p><p><strong>证明</strong>：</p></li></ul></li><li><p><strong>假设1</strong>：$g: \mathcal{Z} \times \mathbb{R}^{d} \rightarrow \mathcal{X}$是有限维空间中的局部Lipschitz函数，$g_\theta (z)$表示对于坐标$(z,\theta)$的求值。如果存在局部Lipschitz常数$L(\theta, z)$,使得$g$对于$\mathcal{Z}$上的某个概率分布$p$满足</p><script type="math/tex; mode=display">\mathbb{E}_{z \sim p}[L(\theta, z)]<+\infty</script></li><li><p><strong>推论1</strong>：令$g_\theta$是关于参数$\theta$的任意的前向传播NN(feedforward neural network)，$p(z)$是当z满足$\mathbb{E}_{z \sim p(z)}[|z|]&lt;\infty$的先验概率。然后满足<strong>假设1</strong>，因此$W(\mathbb{P}_r,\mathbb{P}_\theta)$处处连续且可微<br><strong>证明</strong>：</p></li></ul><p>下面定理描述着由这些距离与离散所引起的相对强度，KL最强，接着是JS与TV，EM最弱。</p><ul><li><p><strong>定理2</strong>：令$\mathbb{P}$是一个在紧空间$\mathcal{X}$上的分布，$(\mathbb{P}_n)_{n \in N}$是空间$\mathcal{X}$上的一个序列。然后考虑$n \rightarrow \infty$时</p><ol><li>以下陈述为等价陈述<ul><li>$\delta(\mathbb{P}_n, \mathbb{P}) \rightarrow 0$ 其中$\delta$为the total variation distance.</li><li>$JS(\mathbb{P}_n, \mathbb{P}) \rightarrow 0$ 其中$JS$为 the Jensen-Shannon divergence.</li></ul></li><li>以下陈述为等价陈述<ul><li>$W(\mathbb{P}_n, \mathbb{P}) \rightarrow 0$</li><li>$\mathbb{P}_n \stackrel{\mathcal{D}}{\longrightarrow}$其中$\stackrel{\mathcal{D}}{\longrightarrow}\mathbb{P}$表示随机变量的分布收敛性</li></ul></li><li>$K L\left(\mathbb{P}_{n} | \mathbb{P}\right) \rightarrow 0$ 和 $K L\left(\mathbb{P} | \mathbb{P}_{n}\right) \rightarrow 0$满足上述陈述1</li><li><p>陈述(1)暗示着陈述(2)</p><p><strong>证明</strong>：</p></li></ol></li></ul><p><strong>定理2</strong>说明了即优化后的$W(\mathbb{P}_n, \mathbb{P})$可能比$JS(\mathbb{P}_n, \mathbb{P})$具有更好的特性<br><strong>结论</strong>：<br>在学习由低维流形支持的分布时，KL，JS和TV距离不是明智的成本函数。 但是，在该设置中，EM距离是明智的。</p><h2><span id="14-wasserstein-gan">1.4. Wasserstein GAN</span></h2><p>$W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)=\inf _{\gamma \in \Pi\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)} \mathbb{E}_{(x, y) \sim \gamma}[|x-y|]$下确界不易计算。改用</p><script type="math/tex; mode=display">W\left(\mathbb{P}_{r}, \mathbb{P}_{\theta}\right)=\sup _{\|  L_{L} \|\leq 1} \mathbb{E}_{x \sim \mathbb{P}_{r}}[f(x)]-\mathbb{E}_{x \sim \mathbb{P}_{\theta}}[f(x)]</script><p>其中上确界覆盖所有的1-Lipschitz functions $f: \mathcal{X} \rightarrow \mathbb{R}$<br>如果使用$|f|_{L} \leq K$替换为$|f|_{L} \leq 1$那么最终得到的为$K \cdot W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)$((考虑K-Lipschitz为某一个常数K))<br>如果我们有一个参数化的函数族$\left\{f_{w}\right\}_w \in \mathcal{W}$(某些K的K-Lipschitz),那么将问题转化为解决</p><script type="math/tex; mode=display">\max _{w \in \mathcal{W}} \mathbb{E}_{x \sim \mathbb{P}_{r}}\left[f_{w}(x)\right]-\mathbb{E}_{z \sim p(z)}\left[f_{w}\left(g_{\theta}(z)\right]\right.</script><p>如果在上上式中达到上确界$w \in \mathcal{W}$(一个很强的假设，类似于证明估计量的一致性时所假设的假设),则此过程将产生$W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)$的计算，直到乘法 不变。 此外，我们可以考虑通过估计$\mathbb{E}_{z \sim p(z)}\left[\nabla_{\theta} f_{w}\left(g_{\theta}(z)\right)\right]$通过上式反向传播来对$W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)$进行微分（再次，直到一个常数）] 尽管这都是直觉，但我们现在证明该过程是在最佳假设下进行的。</p><ul><li><strong>定理</strong>：令$\mathbb{P}_r$是任意分布，$\mathbb{P}_\theta$是$g_\theta(Z)$的分布，$Z$为带有密度$p$的随机变量，$g_\theta$是满足$W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)=\inf _{\gamma \in \Pi\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)} \mathbb{E}_{(x, y) \sim \gamma}[|x-y|]$的函数。那么，有一个解决这问题的方法<script type="math/tex; mode=display">\max _{\|f\|_{L} \leq 1} \mathbb{E}_{x \sim \mathbb{P}_{r}}[f(x)]-\mathbb{E}_{x \sim \mathbb{P}_{\theta}}[f(x)]</script>当两个函数都有明确定义时<script type="math/tex; mode=display">\nabla_{\theta} W\left(\mathbb{P}_{r}, \mathbb{P}_{\theta}\right)=-\mathbb{E}_{z \sim p(z)}\left[\nabla_{\theta} f\left(g_{\theta}(z)\right)\right]</script><strong>证明</strong>：</li></ul><p>问题就变成了找到一个满足利普西兹函数条件的函数$f$，使得达到最大值。可以用带参数的$w$神经网络确定函数，为使函数满足利普西兹条件，可以简单地将其参数截断到一个范围（比较简单）。$f_w$被称为critic，生成模型的梯度传播为$\mathbb{E}_{z \sim p(z)}\left[\nabla_{\theta} f_{w}\left(g_{\theta}(z)\right)\right]$</p><p>用权重剪裁(clipping)来强制Lipschitz约束是一种明显糟糕的方法。如果剪裁(clipping)参数过大，那们每一个权重都需要花费很长的时间才能到达它们的极值，从而造成训练critic最佳化非常困难。如果剪裁(clipping)参数过小，那在神经网路很深或没有使用batch normalization(像是RNNs)的情况下，它会很轻易的导致梯度消失(vanishing gradients)。我们尝试简单的变体(像是将权重(weights)投射到球面(sphere) )，差异很小，并且由于它的简单性和良好的效能，我们坚持使用权重剪裁(weight clipping)。然而，我们确实将强制Lipschitz约束的主题保留在神经网路设置中供进一步研究，我们积极鼓励感兴趣的研究人员来改进这个方法。</p><p><img src="https://image.zkhweb.top/20200213234842.png" alt="20200213234842.png"></p><p>EM距离是连续且可微。意味着我们可以（并且应该）训练critic一直到最佳性。<br>训练critic愈多，将得到的Wasserstein梯度就愈可靠<br>因为Wasserstein几乎处处可微。</p><p>对于JS-divergence，即使discriminator得到更好的梯度，也更可靠，但是险际上它的梯度是0，因为JS是局部饱合的(locally saturated)，我们得到消失的梯度</p><p>也许更重要的是，当我们这样做的时候，事实上我们可以训练critic一直到最佳性，这确保训练过程不会坏掉。坏掉的一个原因事实在于，固定discriminator的最佳generator是分配最高值的点上的增量总和。</p><h2><span id="15-实验结果">1.5. 实验结果</span></h2><ul><li>说明这是一个有效的损失度量，和生成模型的收敛以及样本质量有关。</li><li>提高了优化过程的稳定性。</li></ul><h1><span id="2-总结">2. 总结</span></h1><p>引入一种算法，我们认为WGAN可以替代传统GAN的训练。在这个新的模型中，我们说明我们可以提高学习稳定性，摆掉脱一些问题，像是mode collapse，并提供有意义的学习曲线来帮助除错与超参数的寻找。此外，我们说明相关优化问题是合理的，并提供广泛的理论工作来强调分布之间其它距离的深度连结。</p><hr><h1><span id="3-参考资料">3. 参考资料</span></h1><p><a href="http://arxiv.org/abs/1701.07875" target="_blank" rel="noopener">Paper—-Wasserstein GAN</a><br><a href="https://blog.csdn.net/xiaohouzi1992/article/details/80854086" target="_blank" rel="noopener">CSDN—-Wasserstein GANs 三部曲（二）:Wasserstein GAN论文的理解</a><br><a href="https://blog.csdn.net/shanlepu6038/article/details/86539216" target="_blank" rel="noopener">CSDN—-WGAN-GP精彩分析（附源代码）</a><br><a href="https://blog.csdn.net/duanmuji/article/details/87937505" target="_blank" rel="noopener">CSDN—-WGAN, WGAN-GP, BE-GAN论文笔记</a><br><a href="https://blog.csdn.net/qq_31239495/article/details/83145651" target="_blank" rel="noopener">CSDN—-WGAN(wasserstein GAN)</a><br><a href="https://blog.csdn.net/zh20166666/article/details/83444089" target="_blank" rel="noopener">CSDN—-论文阅读——《Wasserstein GAN》《Improved Training of Wasserstein GANs》</a><br><a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank" rel="noopener">知乎—-令人拍案叫绝的Wasserstein GAN</a><br><a href="https://hackmd.io/@shaoeChen/SyjI6W2zB/https%3A%2F%2Fhackmd.io%2F%40shaoeChen%2FryT0HZtXr" target="_blank" rel="noopener">个人Blog—-WGAN_Paper(翻譯)</a><br><a href="http://www.twistedwg.com/2018/01/31/WGAN.html" target="_blank" rel="noopener">个人Blog—-WGAN介绍</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-wasserstein-gan&quot;&gt;1. Wasserstein GAN&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#11-总结&quot;&gt;1.1. 总结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#12-引言&quot;&gt;1.2
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>Towards Principled Methods for Training Generative Adversarial Networks论文阅读</title>
    <link href="http://www.zkhweb.top/2020/02/17/2017-Towards-Principled-Methods-for-Training-Generative-Adversarial-Networks%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <id>http://www.zkhweb.top/2020/02/17/2017-Towards-Principled-Methods-for-Training-Generative-Adversarial-Networks论文阅读/</id>
    <published>2020-02-17T12:39:13.000Z</published>
    <updated>2020-02-20T11:03:55.870Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-towards-principled-methods-for-training-generative-adversarial-networks">1. Towards Principled Methods for Training Generative Adversarial Networks</a></li><li><a href="#2-总结">2. 总结</a></li><li><a href="#摘要">摘要</a></li><li><a href="#引言">引言</a></li><li><a href="#不稳定的来源">不稳定的来源</a><ul><li><a href="#判别器越好生成器梯度消失越严重">判别器越好，生成器梯度消失越严重</a></li><li><a href="#完美的判别理论">完美的判别理论</a></li><li><a href="#每个cost函数的结果和问题">每个cost函数的结果和问题</a><ul><li><a href="#原始的cost函数">原始的cost函数</a></li><li><a href="#生成器的代替函数-log-dthe-log-d-alternative">生成器的代替函数-log D（the -log D alternative）</a></li></ul></li></ul></li><li><a href="#更柔和的指标和分布">更柔和的指标和分布</a></li><li><a href="#附录">附录</a><ul><li><a href="#span-idappendix_1附录1两者分布不重合js散度为log2span"><span id="Appendix_1">附录1——两者分布不重合JS散度为log2</span></a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-towards-principled-methods-for-training-generative-adversarial-networks">1. Towards Principled Methods for Training Generative Adversarial Networks</span></h1><blockquote><p>arXiv:1701.04862 [cs, stat]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h1><span id="2-总结">2. 总结</span></h1><ul><li><p>要解决什么问题</p><ul><li>彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度<ul><li>第一种生成器loss面临梯度消失问题</li><li>第二种生成器loss面临优化目标荒谬、梯度不稳定、对多样性与准确性惩罚不平衡导致mode collapse这几个问题。</li></ul></li><li>基本解决了collapse mode的问题，确保了生成样本的多样性</li><li>训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高</li><li>以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到</li></ul></li><li><p>用什么方法解决</p></li><li><p>还存在什么问题</p></li><li><p>算法流程(相对于原始GAN)</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行<br><img src="https://image.zkhweb.top/20200213234842.png" alt="20200213234842.png"></li></ul></li></ul><hr><h1><span id="摘要">摘要</span></h1><p>为全面理解生成式对抗网络的训练动力学做出理论上的一步</p><ul><li>介绍了眼前的问题</li><li>专门研究和严格证明训练生成对抗网络时出现的不稳定和饱和问题</li><li>探讨了解决这些问题的实用且理论基础的方向</li></ul><hr><h1><span id="引言">引言</span></h1><ul><li>GAN难以训练，解决问题还依赖于对修改极其敏感的启发式方法</li><li>没有理论分析GAN训练的不稳定原因</li></ul><p>GAN所用的生成器和其他方法(VAE)并没有明显差别</p><ul><li><p>都是从一个简单先验进行采样$z\sim p(z)$，然后输出最后的采样$g_{\theta}(z)$，有时候会在最后加上噪音.总之，$g_{\theta}$是一个受到参数$\theta$控制的神经网络，主要的差别就是$g_{\theta}$是如何训练的。</p></li><li><p>生成模型依赖最大似然</p></li><li>等效于最小化未知的真实数据分布$\mathbb{P}_r$和生成器分布$\mathbb{P}_g$（依赖于$\theta$）之间的KL散度。如果假设这两个分布都是连续密度$P_r$和$P_g$，那么这些方法就是最小化：<script type="math/tex; mode=display">K L\left(\mathbb{P}_{r} \| \mathbb{P}_{g}\right)=\int_{\mathcal{X}} P_{r}(x) \log \frac{P_{r}(x)}{P_{g}(x)} \mathrm{d} x</script>这个损失函数有很好的特性，其有唯一最小值，当且仅当$\mathbb{P}_r = \mathbb{P}_g$，而且优化时，不需要事先知道$P_r(x)$的相关信息，只需要采样。<br>但是<strong>当$\mathbb{P}_r$和$\mathbb{P}_g$之间不是对称的时候就有趣了</strong>：<ul><li>如果$P_r(x)&gt;P_g(x)$，那么$x$是一个数据点，其来自真实数据的概率要远大于生成的。该现象的本质通常被描述为“mode dropping”<sup><a href="#fn_modedropping" id="reffn_modedropping">modedropping</a></sup>：当很大区域是$P_r$的高值，而$P_g$是很小或者零值。当$P_r(x)&gt;0$但是$P_g(x)\rightarrow 0$时，KL内部的被积函数迅速增长到无穷大，这意味着这个损失函数赋予生成器的分布（那些没有覆盖到数据的部分）极大的cost值。</li><li>如果$P_r(x)<p_g(x)$，那么$x$表示来自生成的概率远大于真实数据的。这种情况下我们可以看到生成器的输出基本看上去很假。当$p_r(x) \rightarrow 0$且$p_g(x)>0$时，发现KL中的值接近为0，意味着损失函数会将极低的值给生成器（此时生成的数据看上去很假）。</p_g(x)$，那么$x$表示来自生成的概率远大于真实数据的。这种情况下我们可以看到生成器的输出基本看上去很假。当$p_r(x)></li></ul></li></ul><p><strong>最小化$KL(\mathbb{P}_g||\mathbb{P}_r)$</strong><br>损失函数的权重就会反过来，即损失函数会在生成很假样本的时候给予很高的cost值。</p><p>GAN是优化（最原始形态）Jensen-Shannon散度(Jensen-shannon divergence, JSD)，这两个cost的转换形式为：</p><script type="math/tex; mode=display">J S D\left(\mathbb{P}_{r} \| \mathbb{P}_{g}\right)=\frac{1}{2} K L\left(\mathbb{P}_{r} \| \mathbb{P}_{A}\right)+\frac{1}{2} K L\left(\mathbb{P}_{g} \| \mathbb{P}_{A}\right)</script><p>这里$\mathbb{P}_A$是平均分布，密度为$\frac{P_r+P_g}{2}$。<br><strong>GAN成功生成看似真实图像的原因</strong>：是由于传统的最大似然方法的转换</p><p>GAN形式化成2个步骤，首先训练一个判别器D去最大化：</p><script type="math/tex; mode=display">L(D,g_{\theta})=\mathbb{E}_{x\sim \mathbb{P}_r}\left[ \log D(x)\right]+\mathbb{E}_{x\sim \mathbb{P}_g}\left[ \log(1-D(x))\right]</script><p>可以发现最优判别器形如：</p><script type="math/tex; mode=display">D^*(x)=\frac{P_r(x)}{P_r(x)+P_g(x)}</script><script type="math/tex; mode=display">L(D^*,g_{\theta})=2JSD(\mathbb{P}_r||\mathbb{P}_g)-2\log2</script><p>当鉴别器是最优的时，最小化等式$J S D\left(\mathbb{P}_{r} | \mathbb{P}_{g}\right)=\frac{1}{2} K L\left(\mathbb{P}_{r} | \mathbb{P}_{A}\right)+\frac{1}{2} K L\left(\mathbb{P}_{g} | \mathbb{P}_{A}\right)$看成最小化Jensen-Shannon散度的$\theta$的函数。</p><p>理论上，我们期望首先尽可能最优的训练判别器（所以$\theta$时候的cost函数近似JSD），然后在$\theta$上进行梯度迭代，然后交替这2个事情。然而，这并不work。判别器目标函数越小，则实际上就是$P_r$和$P_g$之间的JS散度越小，通过优化JS散度就能将$P_g$“拉向”$P_r$，最终以假乱真。<br>实际上，判别器越好，对生成器的更新就会越糟糕，原始GAN论文认为这个问题主要来自饱和，换成另一个相似cost函数就不会有这个问题了。然而即使使用新的cost函数，更新还是会变得更糟，优化也会变得更不稳定。</p><p><strong>就有下面几个问题</strong>：</p><ul><li>为什么判别器变得越来越好，而更新却越来越差？在原始cost函数和新的cost函数都是这样；</li><li>为什么GAN训练这么不稳定；</li><li>是否新的cost函数和JSD是一样的相似散度？如果是，他的特性是什么？；</li><li>有方法避免这些问题么？</li></ul><hr><h1><span id="不稳定的来源">不稳定的来源</span></h1><blockquote><p><strong>概念术语</strong></p><ul><li>支撑集（support）其实就是函数的非零部分子集，比如ReLU函数的支撑集就是(0, +$\infty$)，一个概率分布的支撑集就是所有概率密度非零部分的集合。</li><li>流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。</li><li>测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”</li></ul></blockquote><h2><span id="判别器越好生成器梯度消失越严重">判别器越好，生成器梯度消失越严重</span></h2><p>理论上训练的判别器的cost基本就是$2\log2-2JSD(\mathbb{P}_r||\mathbb{P}_g)$。<br>实际上，如果只训练D直到收敛，它的误差接近0。可以得知判别器已经完全胜出了(D训练得更较精确，G的更新会变得越差)，并不是均衡。<br>这种情况发生的时候是</p><ul><li>分布是非连续的（附录B1）</li><li>支撑集（supports）不相交。</li></ul><blockquote><p>1通过连续，我们实际上将引用一个绝对连续的随机变量（即具有密度的变量），如通常所做的那样。 有关进一步的说明，请参见附录B。常见的分布一般都有密度函数</p></blockquote><p><strong>分布非连续的原因</strong>(没有密度函数)</p><ul><li>他们的支撑集（supports）位于低维度流形(流形维度低于全空间)上。文献中证明$\mathbb{P}_r$确实非常集中在低维流形上</li></ul><p>在GAN中，$\mathbb{P}_g$的定义是从一个简单先验$z\sim p(z)$进行采样，然后应用一个函数$g:\mathcal{Z}\rightarrow \mathcal{X}$，所以$\mathbb{P}_g$的支撑集被包含在$g(\mathcal{Z})$里面。如果$\mathcal{Z}$的维度小于$\mathcal{X}$的维度（通常都是这样，采样128维，然后生成28x28的图片），那么是不可能让$\mathbb{P}_g$变成连续的 。这是因为在大多数情况下$g(\mathcal{Z})$会被包含在一个低维度流形的联合体上，因此在$\mathcal{X}$中有测度0存在。而直观上，这是高度非平凡的，因为一个$n$维的参数绝对不会意味着图片会处于$n$维流形上。事实上，有许多简单的反例，如Peano曲线，lemniscates等等。</p><blockquote><p><strong>$\downarrow$对应白话文$\downarrow$</strong></p><ul><li>如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），它们的<strong>JS散度是$\log 2$</strong>(见<a href="#Appendix_1">附录</a>)<ul><li><strong>总之</strong>：无论$P_r$跟$P_g$是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$\log 2$，<strong>而这对于梯度下降方法意味着——梯度为0</strong>此时对于最优判别器来说，生成器肯定是得不到任何梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。</li></ul></li></ul></blockquote><ul><li>$P_r$与$P_g$不重叠或重叠部分可忽略的可能性有多大？<ul><li>不严谨的答案是：非常大。</li><li>比较严谨的答案是：当$P_r$与$P_g$的支撑集是高维空间中的低维流形时，$P_r$与$P_g$重叠部分测度为0的概率为1。</li></ul></li><li>解释“<strong>当$P_r$与$P_g$的支撑集是高维空间中的低维流形</strong>”<br>  GAN中的生成器一般是从某个低维(比如100维)的随机分布中采样出一个编码向量，==&gt;再经过一个神经网络生成出一个高维样本(比如64x64的图片就有4096维)。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。</li><li>“撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积（测度）是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以$P_g$几乎不可能与$P_r$有什么关联,它们的支撑集之间的重叠部分<ul><li><strong>要么不存在</strong></li><li><strong>要么就比$P_r$和$P_g$的最小维度还要低至少一个维度，故而测度为0</strong>。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。</li></ul></li><li><strong>关于生成器梯度消失的第一个论证</strong>：在（近似）最优判别器下，最小化生成器的loss等价于最小化$P_r$与$P_g$之间的JS散度，而由于$P_r$与$P_g$几乎不可能有不可忽略的重叠，所以无论它们相距多远JS散度都是常数$\log 2$，最终导致生成器的梯度（近似）为0，梯度消失。<blockquote><p><strong>$\uparrow$对应白话文$\uparrow$</strong></p></blockquote></li></ul><p><strong>假设$g$是一个NN</strong>。下面给出引理：</p><ul><li><strong>引理1</strong>：令$g:\mathcal(Z)\rightarrow \mathcal{X}$是一个函数，其由仿射映射(线性变换+平移)，逐点非线性（可以是ReLU，LReLU，或者就是严格平滑增加的函数如sigmoid，tanh，softplus等等）。然后$g(\mathcal{Z})$是包含在一个维度接近$\mathcal{Z}$的可数流形并集上（这里就有点测度论的”可数无穷个不相交的集合的测度之和等于其集合并集的测度“意思了。）。因此，如果$\mathcal{Z}$的维度小于$\mathcal{X}$，那么$g(\mathcal{Z})$会让$\mathcal{X}$中有许多测度为0的存在。<br><strong>证明</strong>：附录A<ul><li><strong>Relu或Leak Relu</strong>： $\sigma(x)=\mathbb{1}[x&lt;0] c_{1} x+\mathbb{1}[x \geq 0] c_{2} x$其中$c_1, c_2 \in \mathbb{R}$<br>$g(z)=\mathbf{D}_{n} \mathbf{W}_{n} \ldots \mathbf{D}_{1} \mathbf{W}_{1} z,$ 其中$\mathbf{W}_{i}$仿射变换, $\mathbf{D}_{i}$为取决于$z$对角矩阵，具有对角项$c_1, c_2$。如果我们认为$\mathcal{D}$是所有(有限)集合拥有$c_1, c_2$的对角矩阵，那么$g(\mathcal{Z}) \subseteq \bigcup_{D_{i} \in \mathcal{D}} \mathbf{D}_{n} \mathbf{W}_{n} \ldots \mathbf{D}_{1} \mathbf{W}_{1} \mathcal{Z}$是线性整流的有限集合</li><li><strong>严格平滑增加的函数</strong>：$\sigma$是逐点平滑严格单调增加的欸线性时，然后将其矢量化应用到他的图像上是一个微分同胚。因此，它将d维可数集合(countable union)的流形映射到另一个d维可数集合的流形。如果可以证明仿射变换具有相同的意义，那么将证毕。由于$g(\mathcal{Z}) $只是将其应用于$\mathcal{Z}$维的流形。当然，这足以证明放射变化将不增加维度的使流形映射到可数集合的流形，因为可数个可数集的并是可数集。此外，只需要对线性变换展现这一点，因为应用偏置项使微分同构</li><li>设$\mathbf{W} \in \mathbb{R}^{n \times m}$，通过奇异值分解$\mathbf{W}=\mathbf{U} \boldsymbol{\Sigma} \mathbf{V}$，其中$\sum$为具有对角正项的平方对角矩阵，$U,V$是由基础变化、包含（意味着在新坐标上加0）和投影到坐标子集的组成。与基数相乘并乘以是微分同构，并且将0加到新坐标上是流形嵌入，因此我们只需要证明对投影到该坐标子集上的陈述即可。$\pi: \mathbb{R}^{n+k} \rightarrow \mathbb{R}^{n}$， 其中$\pi\left(x_{1}, \ldots, x_{n+k}\right)=\left(x_{1}, \ldots, x_{n}\right)$是投影。$\mathcal{M} \subseteq \mathbb{R}^{n+k}$为$d$维流形。<ul><li>如果$n \leq d$得证，因为映射$\pi$包含在所有的$\mathbb{R}^n$,其中流形最大为d维</li><li>如果$n &gt; d$,$\pi_{i}(x)=x_{i}$为第$i$个坐标上的投影，如果$x$为$\pi$的临界点，由于$\pi$的最表是独立的，所以$x$是$\pi_i$的临界点。由于Morse引理，$\pi_i$的临界点被隔离了，因此$\pi$中的任意一个也被隔离，意味着它们的数量最多的可数数字。因此$\pi$将非临界点映射到了d维流形(因为它扮演者嵌入)，并且将可数的边界点，映射到可计数的点数(或0维流形)</li></ul></li></ul></li></ul><p><strong>如果$\mathbb{P}_r$和$\mathbb{P}_g$的支撑集是不相交或者位于低维流形上，那么总是存在一个完美的判别器</strong></p><h2><span id="完美的判别理论">完美的判别理论</span></h2><blockquote><p><strong>$\downarrow$脉络白话文$\downarrow$</strong></p><ul><li>首先，$\mathbb{P}_r$和$\mathbb{P}_g$之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。</li><li>由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。</li><li>最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数（1和0），导致生成器的loss梯度为0，梯度消失。<br><strong>$\uparrow$脉络白话文$\uparrow$</strong></li><li>解释下什么时候$\mathbb{P}_r$和$\mathbb{P}_g$会存在不相交支撑集<br>我们说一个判别器$D:\mathcal{X}\rightarrow [0,1]$的准确值为1时，即此时判别器在包含$\mathbb{P}_r$的支撑集上判定其为1，而在包含$\mathbb{P}_g$的支撑集上判定其为0.即$\mathbb{P}_r[D(x)=1]=1$和$\mathbb{P}_g[D(x)=0]=1$。</li></ul></blockquote><ul><li><strong>定理2.1</strong>：如果两个分布$\mathbb{P}_r$和$\mathbb{P}_g$的支撑集分别包含在两个不相交且紧凑的集合$\mathcal{M}$和$\mathcal{P}$，那么存在一个平滑最优的判别器$D^<em>:\mathcal{X}\rightarrow [0,1]$，其准确值为1（即此时一定存在一个判别器能够完全划分这两个集合），且此时对于所有的$x\in\mathcal{M}\cup\mathcal{P}$有$\bigtriangledown_x D^</em>(x)=0$<br><strong>证明</strong>：判别器是训练并且最大化<script type="math/tex; mode=display">\mathbb{E}_{x\sim\mathbb{P}_r}[\log D(x)]+\mathbb{E}_{x\sim\mathbb{P}_g}[\log(1-D(x))]</script>因为$\mathcal{M}$和$\mathcal{P}$都是紧凑且不相关的，那么$z$这两个集合之间的距离存在$0&lt;\delta =d(\mathcal{P},\mathcal{M})$。现在定义：<script type="math/tex; mode=display">\begin{aligned}\hat{\mathcal{M}} = \{ x:d(x,M) \leq \frac{\delta}{3} \} \\ \hat{\mathcal{P}}= \{x:d(x,P)\leq \frac{\delta}{3}\} \end{aligned}</script>通过$\delta$的定义，$\hat{\mathcal{M}}$和$\hat{\mathcal{P}}$清晰的是两个不相关紧凑集合。因此，通过Urysohn的平滑理论，会存在一个平滑函数$D^<em>:\mathcal{X}\rightarrow [0,1]$,使得$D^</em>|_{\hat{\mathcal{M}}}\equiv 1$和$D^<em>|_{\hat{\mathcal{P}}}\equiv 0$。因为对于所有的位于$\mathcal{P}_r$的支撑集中的变量$x$，都有$\log D^</em>(x)=0$，而对于所有位于$\mathcal{P}_g$的支撑集中的变量$x$，都有$\log (1-D^<em>(x))=1$，判别器是完全最优且准确值为1。令$x$位于$\mathcal{M}\cup \mathcal{P}$。假设$x\in\mathcal{M}$，存在一个开区间球$B=B(x,\frac{\delta}{3})$，且$D^</em>|_{B}$是一个常量。此时$\triangledown_xD^*(x) \equiv 0$，即梯度就是为0，如果$x\in\mathcal{P}$那么结果也是一样。得证。</li></ul><p>在下一个理论中，先放弃不相交的假设，将其推广到更一般的情况，<br>假设是2个不同的流形。如果这两个流形在很大部分空间上都是完美匹配的，那么意味着没有判别器可以将它们进行区分。直观上，具有这种情况的两个低维度流形还是很少存在的：对于在特定段中空间匹配的两条曲线，它们不能以遭受任何任意的小方式扰动下还能满足该属性。（即在低维流形中进行稍微扰动下，就分开了）。为此，将<strong>定义</strong>两个流形完美对齐的概念，并表明在任意的小扰动下，该属性永远不会以概率1保持。（即一扰动，该属性就会被破坏）.</p><ul><li><p><strong>定义2.1</strong>：我们首先需要回顾一下横向性(transversality)的定义。令$\mathcal{M}$和$\mathcal{P}$是两个关于$\mathcal{F}$的无边界常规子流形，这里简单认为$\mathcal{F}=\mathbb[R]^d$。$x\in \mathcal{M}\cap\mathcal{P}$是这两个流形的交叉点。如果有$\mathcal{T}_x\mathcal{M}+\mathcal{T}_x\mathcal{P}=\mathcal{T}_x\mathcal{F}$，我们就说$\mathcal{M}$和$\mathcal{P}$在$x$上横向交叉，这里$\mathcal{T}_x\mathcal{M}$表示$\mathcal{M}$上围绕$x$的切线空间。</p></li><li><p><strong>定义2.2</strong>我们说两个没有边界的流形$\mathcal{M}$和$\mathcal{P}$是完美对齐是，如果有$x\in \mathcal{M}\cap\mathcal{P}$，那么$\mathcal{M}$和$\mathcal{P}$不在$x$上横向交叉。</p></li></ul><p>这里将流形$M$的边界表示为$\partial M$，内部表示为$Int M$。我们说两个流形$\mathcal{M}$和$\mathcal{P}$（不管是否有边界）完美对齐是基于下面四组中（$Int \mathcal{M}$, $Int \mathcal{P}$）,（$Int \mathcal{M}$,$\partial \mathcal{P}$），（$\partial \mathcal{M}$, $Int \mathcal{P}$），（$\partial \mathcal{M}$,$\partial \mathcal{P}$）任意一组无边界流形对完全对齐成立前提下。<sup><a href="#fn_yinli2" id="reffn_yinli2">yinli2</a></sup></p><p>如引理3所述，如果两个流形不完美对齐，那么他们的交集$\mathcal{L}=\mathcal{M}\cap\mathcal{P}$是一个有限流形的并集，其中维度严格小于$\mathcal{M}$和$\mathcal{P}$。</p><ul><li><p><strong>引理2</strong>：令$\mathcal{M}$和$\mathcal{P}$是$\mathbb{R}^d$的两个常规子流形，且没有所有的维度。同时令$\eta$,$\eta^{‘}$是任意独立的连续随机变量。因此定义扰动的流形为$\tilde{\mathcal{M}}=\mathcal{M}+\eta$和$\tilde{\mathcal{P}}=\mathcal{P}+\eta^{‘}$，那么：</p><script type="math/tex; mode=display">\mathbb{P}_{\eta,\eta^{'}}(\tilde{\mathcal{M}}\text{与}\tilde{\mathcal{P}}\text{不是完美对齐})=1</script><p><strong>证明</strong>见附录A</p></li><li><p><strong>引理3</strong>：令$\mathcal{M}$和$\mathcal{P}$是$\mathbb{R}^d$的两个常规子流形，他们不是完美对齐且没有所有维度。令$\mathcal{L}=\mathcal{M}\cap\mathcal{P}$。如果$\mathcal{M}$和$\mathcal{P}$没有边界，那么$\mathcal{L}$同样也是一个流形，并且维度严格低于$\mathcal{M}$和$\mathcal{P}$。如果他们有边界，那么$\mathcal{L}$是一个最多4个（可数的）严格更低维度流形的并集。在这两种情况中，$\mathcal{L}$在$\mathcal{M}$和$\mathcal{P}$上的测度为0.<br><strong>证明</strong>见附录A</p></li></ul><p>现在叙述下在这种情况下，基于两个流形上最优判别器结果。</p><ul><li><strong>定理2.2</strong>：令$\mathbb{P}_r$和$\mathbb{P}_g$是两个分布，其支撑集包含在两个封闭的流形$\mathcal{M}$和$\mathcal{P}$上，这两个流形没有完美对齐，且没有所有维度。并假设$\mathbb{P}_r$和$\mathbb{P}_g$在他们各自流形内是连续的，意味着如果有一个集合$A$，其在$\mathcal{M}$上的测度为0，那么$\mathbb{P}_r(A)=0$（对于$\mathbb{P}_g$也是一样）。然后，存在一个最优判别器$D^<em>:\mathcal{X}\rightarrow [0,1]$的准确度为1，且对于几乎任意$\mathcal{M}$和$\mathcal{P}$中的变量$x$，$D^</em>$在$x$周边是平滑的，且$\bigtriangledown_x D^<em>(x)=0$。<br><strong>证明</strong>：通过<em>*引理3</em></em>我们知道$\mathcal{L}=\mathcal{M} \cap \mathcal{P}$是比$\mathcal{M}$和$\mathcal{P}$严格更低维度,并在两个位置上都测得0。通过连续性，得知$\mathbb{P}_{r}(\mathcal{L})=0$和$\mathbb{P}_{g}(\mathcal{L})=0$。注意这暗示着$\mathbb{P}_{r}$ 暗含在 $\mathcal{M} \backslash \mathcal{L}$中，同时也是$\mathbb{P}_{q}$ 暗含在 $\mathcal{P} \backslash \mathcal{L}$的支持。<br>令$x \in \mathcal{M} \backslash \mathcal{L} $因此$ x \in \mathcal{P}^{c} \left( \mathcal{P}\text {的补码}\right) $ 是一个开放集(open set), 因此存在一个半径为 $\epsilon_{x}$的球，使得$B\left(x, \epsilon_{x}\right) \cap \mathcal{P}=\emptyset$通过这种方式，我们定义了<script type="math/tex; mode=display">\hat{\mathcal{M}}=\bigcup_{x \in \mathcal{M} \backslash \mathcal{L}} B\left(x, \epsilon_{x} / 3\right)</script>类似的定义$\hat{P}$. 注意，通过构造，这些都是在$\mathbb{R}^{d}$上的开放集 因此$\mathcal{M} \backslash \mathcal{L} \subseteq$<br>$\hat{\mathcal{M}},$ and $\mathcal{P} \backslash \mathcal{L} \subseteq \hat{\mathcal{P}},$ the support of $\mathbb{P}_{r}$ and $\mathbb{P}_{g}$ is contained in $\mathcal{M}$ and $\hat{\mathcal{P}}$ respectively. As well by construction, $\mathcal{M} \cap \hat{\mathcal{P}}=\emptyset$<br>Let us define $D^{<em>}(x)=1$ for all $x \in \hat{\mathcal{M}},$ and 0 elsewhere (clearly including $\hat{\mathcal{P}} .$ since $\log D^{</em>}(x)=0$ for all $x$ in the support of $\mathbb{P}_{r}$ and $\log \left(1-D^{<em>}(x)\right)=0$ for all $x$ in the support of $\mathbb{P}_{g},$ the discriminator is completely optimal and has accuracy 1. Furthermore, let $x \in \hat{\mathcal{M}}$. since $\mathcal{M}$ is an open set and $D^{</em>}$ is constant on $\mathcal{M},$ then $\left.\nabla_{x} D^{<em>}\right|_{\hat{\mathcal{M}}} \equiv 0 .$ Analogously, $\nabla_{x} D^{</em>} | \hat{p} \equiv 0 .$ Therefore, the set of points where $D^{*}$ is non-smooth or has non-zero gradient inside $\mathcal{M} \cup \mathcal{P}$ is contained in $\mathcal{L},$ which has null-measure in both manifolds, therefore concluding the theorem.</li></ul><p>这两个定理告诉我们<strong>存在一个最优判别器，其在$\mathbb{P}_r$和$\mathbb{P}_g$几乎任何地方都是平滑而且是常量</strong>。所以事实就是该判别器在流形点上是常量，所以没法通过BP学到任何信息，同时在下面介绍的也是常量。下面的定理2.3是将整个理论进行总结得出的</p><ul><li><strong>定理2.3</strong>：令$\mathbb{P}_r$和$\mathbb{P}_g$是两个分布，其支撑集包含在两个封闭的流形$\mathcal{M}$和$\mathcal{P}$上，这两个流形没有完美对齐，且没有所有维度。并假设$\mathbb{P}_r$和$\mathbb{P}_g$在他们各自流形内是连续的，那么：<script type="math/tex; mode=display">\begin{aligned}JSD(\mathbb{P}_r||\mathbb{P}_g) =\log2 \\ KL(\mathbb{P}_r||\mathbb{P}_g) = +\infty \\ KL(\mathbb{P}_g||\mathbb{P}_r) = +\infty \end{aligned}</script></li></ul><p>注意到即使两个流形彼此靠得很近，这些散度也会maxed out。而就算生成器生成的样本看上去很好，可是此时两个KL散度可能很大。因此，定理2.3指出使用那些通常用来测试两个分布之间相似性的方法并不是一个好主意。更不用说，如果这些散度总是maxed out并试图通过梯度下降进行最小化也是不可能的。我们期望有一个softer的测度，可以包含流形中点之间距离的概念。我们将在第3节中稍后再讨论该主题，在该部分中我们将解释一个替代指标并提供我们可以分析和优化的范围。</p><blockquote><p><strong>$\downarrow$结论白话文$\downarrow$</strong><br>有了这些理论分析，原始GAN不稳定的原因就彻底清楚了：</p><ul><li><strong>判别器训练得太好，生成器梯度消失，生成器loss降不下去</strong></li><li><strong>判别器训练得不好，生成器梯度不准，四处乱跑</strong></li><li><strong>只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样</strong><br>所以GAN才那么难训练。<br><strong>$\uparrow$结论白话文$\uparrow$</strong></li></ul></blockquote><h2><span id="每个cost函数的结果和问题">每个cost函数的结果和问题</span></h2><p><strong>上述均为原始cost</strong><br>定理2.1和定理2.2得出一个很重要的事实。如果我们关心的两个分布的支撑集是不相关或者位于低维流形上的，最优判别器可能是完美的，而且梯度几乎在任何地方都是0.</p><h3><span id="原始的cost函数">原始的cost函数</span></h3><p><strong>一句话概括：判别器越好，生成器梯度消失越严重</strong><br>接下来将介绍下当通过一个判别器将梯度传递给生成器时会发生什么。与目前为止的典型分析一个关键区别是，作者将开发一套理论来近似最优判别器，而不是使用（未知）真正的判别器。并证明随着近似越来越好，所观察到的梯度消失或者大规模不稳定的行为主要依赖使用的cost函数。<br>将$||D||$表示范数：</p><script type="math/tex; mode=display">||D||=\underset{x\in\mathcal{X}}{sup}|D(x)|+||\bigtriangledown_x D(x)||_2</script><p>该范数的使用可以让证明变得更简单，但是可以在另一个Sobolev范数中完成$||\cdot||_{1,p}$,对于普遍逼近定理所涵盖的$p&lt;\infty$，此时可以保证在这个范数中的神经网络近似[5]。</p><ul><li><p><strong>定理2.4</strong>（在生成器上的梯度消失）:$g_{\theta}:\mathcal{Z}\rightarrow \mathcal{X}$是一个微分函数，表示分布一个分布$\mathbb{P}_g$。令$\mathbb{P}_r$表示真实数据分布，D表示一个可微分的判别器。如果定理2.1和2.2都满足，$||D-D^*||&lt;\epsilon$且$\mathbb{E}_{z\sim p(z)}\left[ ||J_{\theta}g_{\theta}(z)||_2^2\right]\leq M^2$（因为M依赖于$\theta$,对于均匀分布先验和NN，该条件可以简单验证。而对于高斯先验需要更多的工作，因为我们需要限制$z$的增长，但是对当前结构同样适用。），那么：</p><script type="math/tex; mode=display">||\bigtriangledown_{\theta}\mathbb{E}_{z\sim p(z)}\left[\log(1-D(g_{\theta}(z))\,\,) \right]||_2<M\frac{\epsilon}{1-\epsilon}</script><p><strong>证明</strong>：在定理2.1和定理2.2的证明中，$D^*$在$\mathbb{P}_g$的支撑集上局部为0.那么在该支撑集上使用Jensen不等式和链式法则，得：</p><script type="math/tex; mode=display">\begin{aligned}\left\|\nabla_{\theta} \mathbb{E}_{z \sim p(z)}\left[\log \left(1-D\left(g_{\theta}(z)\right)\right)\right)\right\|_{2}^{2} & \leq \mathbb{E}_{z \sim p(z)}\left[\frac{\left\|\nabla_{\theta} D\left(g_{\theta}(z)\right)\right\|_{2}^{2}}{\left|1-D\left(g_{\theta}(z)\right)\right|^{2}}\right] \\& \leq \mathbb{E}_{z \sim p(z)}\left[\frac{\left\|\nabla_{x} D\left(g_{\theta}(z)\right)\right\|_{2}^{2}\left\|J_{\theta} g_{\theta}(z)\right\|_{2}^{2}}{\left|1-D\left(g_{\theta}(z)\right)\right|^{2}}\right] \\&<\mathbb{E}_{z \sim p(z)}\left[\frac{\left(\left\|\nabla_{x} D^{*}\left(g_{\theta}(z)\right)\right\|_{2}+\epsilon\right)^{2}\left\|J_{\theta} g_{\theta}(z)\right\|_{2}^{2}}{\left.\left(| 1-D^{*}(z)\right) |-\epsilon\right)^{2}}\right] \\&=\mathbb{E}_{z \sim p(z)}\left[\frac{\epsilon^{2}\left\|J_{\theta} g_{\theta}(z)\right\|_{2}^{2}}{(1-\epsilon)^{2}}\right] \\& \leq M^{2} \frac{\epsilon^{2}}{(1-\epsilon)^{2}}\end{aligned}</script><p>将其开方得：</p><script type="math/tex; mode=display">||\bigtriangledown_{\theta}\mathbb{E}_{z\sim p(z)}\left[\log(1-D(g_{\theta}(z))\,\,)\right]||_2<M\frac{\epsilon}{1-\epsilon}</script><p>得证。</p></li><li><p><strong>推理2.1</strong>：基于与定理2.4一样的假设：</p><script type="math/tex; mode=display">\underset{||D-D^*||\rightarrow 0}{\lim} \bigtriangledown_{\theta}\mathbb{E}_{z\sim p(z)}\left[\log(1-D(g_{\theta}(z))\,\,)\right]=0</script></li></ul><p>可以发现判别器训练的越好，则生成器梯度就会消失，生成器的cost函数接近Jensen-Shannon散度取决于近似的质量好坏。这点告诉我们一个基础理论：要么判别器的更新是不准确的或者直接梯度会消失。这使得训练这个cost变得很困难或者需要用户来决定准确的判别器训练过程，从而让GAN训练变得很困难。</p><h3><span id="生成器的代替函数-log-dthe-log-d-alternative">生成器的代替函数-log D（the -log D alternative）</span></h3><p><strong>一句话概括：最小化第二种生成器loss函数，会等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。</strong><br>为了避免判别器很好时候梯度消失的问题，人们选择使用一个不同的cost函数：</p><script type="math/tex; mode=display">\Delta \theta=\bigtriangledown_{\theta}\mathbb{E}_{z\sim p(z)}[-\log D(g_{\theta}(z))]</script><p>现在先叙述并证明该梯度优化的cost函数，随后，证明虽然该梯度不一定会受到消失梯度的影响，但它确实会在最优判别器的噪音近似下导致大量不稳定的更新（在实验中已经广泛证实）。</p><ul><li><strong>定理2.5</strong>:令$\mathbb{P}_r$和$\mathbb{P}_{g \theta}$表示2个连续分布，对应密度为$P_r$和$P_{g \theta}$。令$D^*=\frac{P_r}{P_{g\theta_0}+P_r}$是最优判别器，此时$\theta_0$是固定的（迭代生成器的时候，判别器是固定的）。那么：<script type="math/tex; mode=display">\mathbb{E}_{z\sim p(z)}\left[ -\bigtriangledown_{\theta}\log D^*(g_{\theta}(z))|_{\theta=\theta_0}\right]=\bigtriangledown_{\theta}\left[ KL(\mathbb{P}_{g\theta}||\mathbb{P}_r)-2JSD(\mathbb{P}_{g\theta}||\mathbb{P}_r)\right] |_{\theta=\theta_0}</script>或：<script type="math/tex; mode=display">Loss_{ G }=KL({ P }_{ g }(x)||{ P }_{ r }(x))-2JS({ P }_{ r }||{ P }_{ g })+{P}_{r}(x)*log[D^*(x)]+2log2[1-D^{ * }(x)]$$(证明见GAN论文)**证明**：原始生成器的loss为改成$$\mathbb{E}_{x\sim P_g}[-\log D(x)]</script>且在得到最优判别器下<script type="math/tex; mode=display">\mathbb{E}_{x\sim P_r}[\log D^*(x)]+\mathbb{E}_{x\sim P_g}[\log(1- D^*(x))]=2JSD(P_r||P_g)-2\log 2</script>将KL散度变换成最优判别器：<script type="math/tex; mode=display">\begin{aligned}K L\left(\mathbb{P}_{g_{\theta}} \| \mathbb{P}_{r}\right) &=\mathbb{E}_{x \sim \mathbb{P}_{g_{\theta}}}\left[\log \frac{P_{g_{\theta}}(x)}{P_{r}(x)}\right] \\&=\mathbb{E}_{x \sim \mathbb{P}_{g_{\theta}}}\left[\log \frac{P_{g_{0}(x)}(x)}{P_{r}(x)}\right]-\mathbb{E}_{x \sim \mathbb{P}_{g_{\theta}}}\left[\log \frac{P_{g_{\theta}}(x)}{P_{g_{0}}(x)}\right] \\&=-\mathbb{E}_{x \sim \mathbb{P}_{g_{\theta}}}\left[\log \frac{D^{*}(x)}{1-D^{*}(x)}\right]-K L\left(\mathbb{P}_{g_{\theta}} \| \mathbb{P}_{g_{\theta_{0}}}\right) \\&=-\mathbb{E}_{z \sim p(z)}\left[\log \frac{D^{*}\left(g_{\theta}(z)\right)}{1-D^{*}\left(g_{\theta}(z)\right)}\right]-K L\left(\mathbb{P}_{g_{\theta}} \| \mathbb{P}_{g_{\theta_{0}}}\right)\end{aligned}</script>Taking derivatives in $\theta$ at $\theta_0$ we get<script type="math/tex; mode=display">\begin{aligned}\left.\nabla_{\theta} K L\left(\mathbb{P}_{g s} \| \mathbb{P}_{r}\right)\right|_{\theta=\theta_{0}} &=-\left.\nabla_{\theta} \mathbb{E}_{z \sim p(z)}\left[\log \frac{D^{*}\left(g_{\theta}(z)\right)}{1-D^{*}\left(g_{\theta}(z)\right)}\right]\right|_{\theta=\theta_{0}}-\left.\nabla_{\theta} K L\left(\mathbb{P}_{g_{\theta}} \| \mathbb{P}_{g e_{0}}\right)\right|_{\theta=\theta_{0}} \\&=\left.\mathbb{E}_{z \sim p(z)}\left[-\nabla_{\theta} \log \frac{D^{*}\left(g_{\theta}(z)\right)}{1-D^{*}\left(g_{\theta}(z)\right)}\right]\right|_{\theta=\theta_{0}}\end{aligned}</script>将最后一个方程式与JSD的结果相减，我们便获得了所需的结果<br>得证。</li></ul><blockquote><p><strong>$\downarrow$问题分析$\downarrow$</strong></p><ul><li>第一：JS散度项<br>  一个拉近，一个推远。在数值上则会导致梯度不稳定<ul><li>最小化生成分布与真实分布的KL散度</li><li>却又要最大化两者的JSD散度</li></ul></li><li>第二，$KL(\mathbb{P}_{g\theta}||\mathbb{P}_r)$<br>  KL散度不是一个对称的衡量<br>  $KL(\mathbb{P}_{g\theta}||\mathbb{P}_r)$与$KL(\mathbb{P}_r||\mathbb{P}_g)$是不同的，以前者为例<ul><li>$KL(\mathbb{P}_{g\theta}||\mathbb{P}_r)$<br>  这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。<ul><li>当 $P_g(x)\rightarrow 0$而$P_r(x)\rightarrow 0$时，$P_g(x)\log\frac{P_g(x)}{P_r(x)}\rightarrow 0$,对$KL(\mathbb{P}_{g\theta}||\mathbb{P}_r)$贡献趋近于0；<strong>“生成器没能生成真实的样本”，惩罚微小</strong>；<strong>缺乏多样性</strong></li><li>当 $P_g(x)\rightarrow 1$而$P_r(x)\rightarrow 0$时，$P_g(x)\log\frac{P_g(x)}{P_r(x)}\rightarrow +\infty$,对$KL(\mathbb{P}_{g\theta}||\mathbb{P}_r)$贡献趋近于正无穷；<strong>“生成器生成了不真实的样本” ，惩罚巨大</strong> <strong>缺乏准确性</strong></li></ul></li><li>$KL(\mathbb{P}_r||\mathbb{P}_g)$<br><strong>$\uparrow$问题分析$\uparrow$</strong></li></ul></li></ul></blockquote><ul><li><strong>定理2.6</strong>(生成器梯度更新的不稳定):令$g_{\theta}: \mathcal{Z} \rightarrow \mathcal{X}$是可生成$\mathbb{P}_g$的可微函数。令$\mathbb{P}_r$是真实数据分布，同时满足定理2.1和定理2.2的条件。令$D$是一个判别器，使得$D^<em>-D=\epsilon$是一个由x索引为中心的高斯过程，并且对于每一个x(通常称为白噪声)为独立。并且$\nabla_{x} D^{</em>}-\nabla_{x} D=r$是另一个由x索引为中心的独立高斯过程，且对于每一个x为独立。然后，每个坐标<script type="math/tex; mode=display">\mathbb{E}_{z \sim p(z)}\left[-\nabla_{\theta} \log D\left(g_{\theta}(z)\right)\right]</script>是具有无限期望和方差的中心柯西分布(<strong>Note</strong>定理成立，与r和$\epsilon$的方差无关。 随着逼近度的提高，由于有限的精度，该误差越来越像是中心随机噪声。)<br><strong>证明</strong>: 在这种情况下，$\mathbb{P}_g$的支撑集上$D$的局部常数等于0.使用$r\left(g_{\theta}(z)\right), \epsilon\left(g_{\theta}(z)\right)$ 表示随机变量$r(z), \epsilon(z)$。使用链式规则和$r,\epsilon$的定义，得到<script type="math/tex; mode=display">\begin{aligned}\mathbb{E}_{z \sim p(z)}\left[-\nabla_{\theta} \log D\left(g_{\theta}(z)\right)\right] &=\mathbb{E}_{z \sim p(z)}\left[-\frac{J_{\theta g_{\theta}(z)} \nabla_{x} D\left(g_{\theta}(z)\right)}{D\left(g_{\theta}(z)\right)}\right] \\&=\mathbb{E}_{z \sim p(z)}\left[-\frac{J_{\theta} g_{\theta}(z) r(z)}{\epsilon(z)}\right]\end{aligned}</script>由于$r(z)$是中心高斯分布，因此它乘一个矩阵不会改变。此外，当除以$\epsilon$(独立于分子的中心高斯),在每个坐标上得到一个中心柯西随机变量.z上取平均值，不同的独立柯西随机变量再次产生中心柯西分布<br>证毕。</li></ul><p><strong>Note</strong>即使我们忽略了更新会有无限的变化（即方差很大），仍然认为更新的分布是可以中心化的，这意味着如果我们限定更新，更新的期望将为0，即不向梯度提供任何反馈。<br>因为关于$D$和$\nabla D$的噪音是去相关的假设太严格了，如图3.在训练稳定良好的DCGAN的任何阶段，除非已经收敛，否则当我们训练鉴别器接近最优时，梯度的范数会急剧增长。在所有情况下，使用此更新会导致样本质量不断下降。曲线中的噪音显示梯度的方差也在不断增长，而这会减缓收敛并且在优化阶段会有更多不稳定的行为</p><h1><span id="更柔和的指标和分布">更柔和的指标和分布</span></h1><p>一个很重要的问题是如何修复不稳定和梯度消失的问题。我们打破这些定理假设的一个方法就是<strong>给判别器输入增加连续噪音</strong>，因而平滑概率质量的分布。</p><ul><li><p><strong>定理3.1</strong>：如果$X$分布为$\mathbb{P}_X$，其支撑集为$\mathcal{M}$,$\epsilon$是一个完全连续的随机变量，其密度为$P_{\epsilon}$，那么$\mathbb{P}_{X+\epsilon}$是完全连续的，其密度为：</p><script type="math/tex; mode=display">\begin{aligned}P_{X+\epsilon}(x) &= \mathbb{E}_{y\sim \mathbb{P}_X}[P_{\epsilon}(x-y)] \\ &= \int_{\mathcal{M}}P_{\epsilon}(x-y)d\mathbb{P}_X(y) \end{aligned}</script><p><strong>证明</strong>:</p><ul><li>首先证明$\mathbb{P}_{X+\epsilon}$是绝对连续的，令$A$是Lebesgue测度为0的Borel集。那么，根据$\epsilon$和$X$是独立的事实，通过Fubini可以得到<script type="math/tex; mode=display">\begin{aligned}\mathbb{P}_{X+\epsilon}(A) &=\int_{\mathbb{R}^{d}} \mathbb{P}_{\epsilon}(A-x) \mathrm{d} \mathbb{P}_{X}(x) \\&=\int_{\mathbb{R}^{d}} 0 \mathrm{d} \mathbb{P}_{X}(x)=0\end{aligned}</script>其中，如果$A$的Lebesgue的测度为0，那么$A-x$的测度也为0.并且由于$\mathbb{P}_{\epsilon}$是绝对连续的，所以$\mathbb{P}_{\epsilon}(A-x)=0$</li><li>接着计算$\mathbb{P}_{X+\epsilon}$的密度。继续使用$X$和$\epsilon$独立性，对于任何Borel集B，有<script type="math/tex; mode=display">\begin{aligned}\mathbb{P}_{X+\epsilon}(B) &=\int_{\mathbb{R}^{d}} \mathbb{P}_{\epsilon}(B-y) \mathrm{d} \mathbb{P}_{X}(y) \\&=\mathbb{E}_{y \sim \mathbb{P}} x\left[\mathbb{P}_{\epsilon}(B-y)\right] \\&=\mathbb{E}_{y \sim \mathbb{P}_{x}}\left[\int_{B-y} P_{\epsilon}(x) d x\right] \\&=\left.\mathbb{E}_{y}\right|_{\Gamma_{x}}\left[\int_{B} P_{\epsilon}(x-y) d x\right] \\&=\int_{B} \mathbb{E}_{y \sim \mathbb{P}_{x}}\left[P_{\epsilon}(x-y)\right] d x\end{aligned}</script>因此$\mathbb{P}_{X+\epsilon}(B)=\int_{B} P_{X+\epsilon}(x) d x$我们的目标是$P_{X+\epsilon}$和所有的Borel集$B$，通过Radon-Nikodym定理的唯一性，这意味着，所提出的$P_{x+\epsilon}$是$\mathbb{P}_{X+\epsilon}$的密度。根据期望定义以及$\mathbb{P}_X$在$\mathcal{M}$的支撑集$\mathbb{P}_X$, 改变$\int_{\mathcal{M}} \mathbb{P}_{X}$期望的公式的等价性是微不足道的。<br>证毕。</li></ul></li><li><p><strong>推论3.1</strong></p><ul><li>如果$\epsilon\sim \mathcal{N}(0,\sigma^2I)$，那么：<script type="math/tex; mode=display">P_{X+\epsilon}(x)=\frac{1}{Z}\int_{\mathcal{M}}e^{-\frac{||y-x||^2}{2\sigma^2}}d\mathbb{P}_{X}(y)</script></li><li>如果$\epsilon \sim \mathcal{N}(0, \Sigma)$，那么：<script type="math/tex; mode=display">P_{X+\epsilon}(x)=\frac{1}{Z} \mathbb{E}_{y \sim \mathbb{P}_{X}}\left[e^{-\frac{1}{2}\|y-x\|_{\Sigma-1}^{2}}\right]</script></li><li>如果$P_{\epsilon}(x) \propto \frac{1}{|x|^{d+1}}$，那么：<script type="math/tex; mode=display">P_{X+\epsilon}(x)=\frac{1}{Z} \mathbb{E}_{y \sim \mathbb{P}_{X}}\left[\frac{1}{\|x-y\|^{d+1}}\right]</script></li></ul></li></ul><p>从定理得知密度$P_{X+\epsilon}(X)$与到支撑集$\mathbb{P}_X$的平均距离成反比，由临界点的概率加权。在支撑集$\mathbb{P}_X$是流形的情况下。我们将得到到沿着流形的点的距离的加权平均值。我们如何选择噪声的分布将影响我们所选择的距离的概念。例如，在我们的corolary中，我们可以看到通过改变指数内的范数来改变协方差矩阵的效果。因此，可以使用具有不同衰变类型的不同噪声。</p><p>因此，<strong>最佳判别器处于$\mathbb{P}_{g+\epsilon}$和$\mathbb{P}_{r + \epsilon}$之间</strong></p><script type="math/tex; mode=display">D^{*}(x)=\frac{P_{r+\epsilon}(x)}{P_{r+\epsilon}(x)+P_{g+\epsilon}(x)}</script><ul><li><strong>定理3.2</strong>:令$\mathbb{P}_{g}$和$\mathbb{P}_{r}$为支撑集在$\mathcal{M}$和$\mathcal{P}$上的分布，其中$\epsilon \sim \mathcal{N}\left(0, \sigma^{2} I\right)$。那么，传递给生成器的梯度具有以下形式<script type="math/tex; mode=display">\begin{aligned}&\mathbb{E}_{z \sim p(z)}\left[\nabla_{\theta} \log \left(1-D^{*}\left(g_{\theta}(z)\right)\right)\right]\\&=\mathbb{E}_{z \sim p(z)}\left[a(z) \int_{\mathcal{M}} P_{\epsilon}\left(g_{\theta}(z)-y\right) \nabla_{\theta}\left\|g_{\theta}(z)-y\right\|^{2} \mathrm{d} \mathbb{P}_{r}(y)\right.\\&-b(z) \int_{\mathcal{P}} P_{\epsilon}\left(g_{\theta}(z)-y\right) \nabla_{\theta}\left\|g_{\theta}(z)-y\right\|^{2} \mathrm{d} \mathbb{P}_{g}(y)]\end{aligned}</script>其中$a(z)$和$b(z)$是正函数。此外当且仅当$P_{r+\epsilon}&gt;P_{g+\epsilon}$时$b&gt;a$；当且仅当$P_{r+\epsilon} &lt; P_{g+\epsilon}$时$b &lt; a$；<br><strong>证明</strong>：由于鉴别器在反向生成到发生器时假定是固定的，因此唯一依赖的是每个z的$g_\theta(z)$ 通过对我们的成本函数取导数<script type="math/tex; mode=display">\begin{array}{l}{\mathbb{E}_{z \sim p(z)}\left[\nabla_{\theta} \log \left(1-D^{*}\left(g_{\theta}(z)\right)\right)\right]} \\{=\mathbb{E}_{z \sim p(z)}\left[\nabla_{\theta} \log \frac{P_{g+\epsilon}\left(g_{\theta}(z)\right)}{P_{r+\epsilon}\left(g_{\theta}(z)\right)+P_{g+\epsilon}\left(g_{\theta}(z)\right)}\right]} \\{=\mathbb{E}_{z \sim p(z)}\left[\nabla_{\theta} \log P_{g+\epsilon}\left(g_{\theta}(z)\right)-\nabla_{\theta+\epsilon}\left(g_{\theta}(z)\right)\right]} \\{=\mathbb{E}_{z \sim p(z)}\left[\frac{\nabla_{\theta} P_{g+\epsilon}\left(g_{\theta}(z)\right)}{P_{g+\epsilon}\left(g_{\theta}(z)\right)}-\frac{\nabla_{\theta} P_{g+\epsilon}\left(g_{\theta}(z)\right)+\nabla_{\theta} P_{r+\epsilon}\left(g_{\theta}(z)\right)}{P_{g+\epsilon}\left(g_{\theta}(z)\right)+P_{r+\epsilon}\left(g_{\theta}(z)\right)}\right]} \\{=\mathbb{E}_{z \sim p(z)}\left[\frac{1}{P_{g+\epsilon}\left(g_{\theta}(z)\right)+P_{r+\epsilon}\left(g_{\theta}(z)\right)} \nabla_{\theta}\left[-P_{r+\epsilon}\left(g_{\theta}(z)\right)\right]-\right.} \\{\left.\frac{1}{P_{g+\epsilon}\left(g_{\theta}(z)\right)+P_{r+\epsilon}\left(g_{\theta}(z)\right)} \frac{P_{r+\epsilon}\left(g_{\theta}(z)\right)}{P_{g+\epsilon}\left(g_{\theta}(z)\right)} \nabla_{\theta}\left[-P_{g+\epsilon}\left(g_{\theta}(z)\right)\right]\right]}\end{array}</script>令$\epsilon$的密度为$\frac{1}{Z} e^{-\frac{|x|^{2}}{2 \sigma^{2}}}$。定义<script type="math/tex; mode=display">\begin{aligned}&a(z)=\frac{1}{2 \sigma^{2}} \frac{1}{P_{g+\epsilon}\left(g_{\theta}(z)\right)+P_{r+\epsilon}\left(g_{\theta}(z)\right)}\\&b(z)=\frac{1}{2 \sigma^{2}} \frac{1}{P_{g+\epsilon}\left(g_{\theta}(z)\right)+P_{r+\epsilon}\left(g_{\theta}(z)\right)} \frac{P_{r+\epsilon}\left(g_{\theta}(z)\right)}{P_{g+\epsilon}\left(g_{\theta}(z)\right)}\end{aligned}</script>同时$a,b$为正函数，由于$b=a \frac{P_{r+\epsilon}}{P_{g+\epsilon}}$，可以得知当且仅当$P_{r+\epsilon}&gt;P_{g+\epsilon}$时$b&gt;a$；当且仅当$P_{r+\epsilon} &lt; P_{g+\epsilon}$时$b &lt; a$；同时得出<br><script type="math/tex">\begin{aligned}&\mathbb{E}_{z \sim p(z)}\left[\nabla_{\theta} \log \left(1-D^{*}\left(g_{\theta}(z)\right)\right)\right]\\&\begin{array}{l}{=\mathbb{E}_{z \sim p(z)}\left[2 \sigma^{2} a(z) \nabla_{\theta}\left[-P_{r+\epsilon}\left(g_{\theta}(z)\right)\right]-2 \sigma^{2} b(z)\right] \nabla_{\theta}\left[-P_{g+\epsilon}\left(g_{\theta}(z)\right)\right]} \\{=\mathbb{E}_{z \sim p(z)}\left[2 \sigma^{2} a(z) \int_{\mathcal{M}}-\nabla_{\theta} \frac{1}{Z} e^{\frac{-\| g_{\theta}(z)-y | l_{2}}{2 \sigma^{2}}} \mathrm{d} \mathbb{P}_{r}(y)-2 \sigma^{2} b(z) \int_{\mathcal{P}}-\nabla_{\theta} \frac{1}{Z} e^{\frac{-\| g_{\theta}(z)-y | l_{2}^{2}}{2 \sigma^{2}}} \mathrm{d} \mathbb{P}_{g}(y)\right]} \\{=\mathbb{E}_{z \sim p(z)}\left[a(z) \int_{\mathcal{M}} \frac{1}{Z} e^{\frac{-\| g_{\theta}(z)-y | 2}{2 \sigma^{2}}} \nabla_{\theta}\left\|g_{\theta}(z)-y\right\|^{2} \mathrm{d} \mathbb{P}_{r}(y)\right.}\end{array}\\&\begin{array}{l}{\left.-b(z) \int_{\mathcal{P}} \frac{1}{Z} e^{\frac{-\left\|g_{\theta}(z)-y\right\|_{2}^{2}}{2 \sigma^{2}}} \nabla_{\theta}\left\|g_{\theta}(z)-y\right\|^{2} \mathrm{d} \mathbb{P}_{g}(y)\right]} \\{=\mathbb{E}_{z \sim p(z)}\left[a(z) \int_{\mathcal{M}} P_{\epsilon}\left(g_{\theta}(z)-y\right) \nabla_{\theta}\left\|g_{\theta}(z)-y\right\|^{2} \mathrm{d} \mathbb{P}_{r}(y)\right.} \\{\left.-b(z) \int_{\mathcal{P}} P_{\epsilon}\left(g_{\theta}(z)-y\right) \nabla_{\theta}\left\|g_{\theta}(z)-y\right\|^{2} \mathrm{d} \mathbb{P}_{g}(y)\right]}\end{array}\end{aligned}</script>得证</li></ul><p>该定理证明，我们将样本$g_{\theta}$沿着数据流形朝着临界点移动，并对其概率和与样本之间的距离进行加权。 此外，第二项使我们的点远离高概率样本，再次由样本流形和到这些样本的距离加权。 这在本质上与对比散度相似，在对比散度中，我们降低了样本的自由能并增加了数据点的自由能。 当我们拥有比$\mathbb{P}_r$高的可能性时，从$\mathbb{P}_g$得出的样本更清楚地看到了该术语的重要性。 在这种情况下，我们将使b&gt; a，并且第二项将具有降低这种太可能样本的概率的强度。 最后，如果x周围有一个区域与$\mathbb{P}_g$相比具有与$\mathbb{P}_r$相同的概率，则两个项之间的梯度贡献将抵消，因此当$\mathbb{P}_r$与$\mathbb{P}_g$相似时，可以稳定梯度。</p><p>完全采用上式的梯度步骤存在一个重要问题，那就是在这种情况下，$D$将忽略恰好位于$g_\mathcal(Z)$中的误差，因为这是一组度量0。但是，g将仅在该空间上优化其成本。这将使鉴别器极易受到对抗性例子的影响，并且将使生成器的成本降低而鉴别器的成本却不高，并且糟糕的样本将变得毫无意义。当我们意识到上式的期望内的项将为正标量乘以$\nabla_{x} \log \left(1-D^{*}(x)\right) \nabla_{\theta} g_{\theta}(z)$时，这是很容易看出的，这是朝向精确值的方向导数Goodfellow等人的对抗词。 （2014b）。因此，在发生器中的噪声样本中反向传播也很重要。这将产生关键的好处：生成器的反向支持期限将通过歧视者会关注的一组积极措施上的样本进行。正式化这个概念，通过发生器的实际梯度现在将与$\nabla_{\theta} J S D\left(\mathbb{P}_{r+\epsilon} | \mathbb{P}_{q+\epsilon}\right)$成比例，这将使两个噪声分布匹配。当我们对噪声进行退火时，这也会使Pr和Pg匹配。为了完整起见，我们显示了在这种情况下获得的平滑渐变。证明与定理3.2的证明相同，因此我们留给读者。</p><ul><li><strong>推理3.2</strong>:令$\epsilon, \epsilon^{\prime} \sim \mathcal{N}\left(0, \sigma^{2} I\right)$ 和 $\tilde{g}_{\theta}(z)=g_{\theta}(z)+\epsilon^{\prime}$那么<script type="math/tex; mode=display">\begin{array}{l}{\mathbb{E}_{z \sim p(z), \epsilon^{\prime}}\left[\nabla_{\theta} \log \left(1-D^{*}\left(\tilde{g}_{\theta}(z)\right)\right)\right]} \\{\quad=\mathbb{E}_{z \sim p(z), \epsilon^{\prime}}\left[a(z) \int_{\mathcal{M}} P_{\epsilon}\left(\tilde{g}_{\theta}(z)-y\right) \nabla_{\theta}\left\|\tilde{g}_{\theta}(z)-y\right\|^{2} \mathrm{d} \mathbb{P}_{r}(y)\right.} \\{\left.\quad-b(z) \int_{\mathcal{P}} P_{\epsilon}\left(\tilde{g}_{\theta}(z)-y\right) \nabla_{\theta}\left\|\tilde{g}_{\theta}(z)-y\right\|^{2} \mathrm{d} \mathbb{P}_{g}(y)\right]} \\{\quad=2 \nabla_{\theta} J S D\left(\mathbb{P}_{r+\epsilon} \| \mathbb{P}_{g+\epsilon}\right)}\end{array}</script></li></ul><p>与定理3.2相同，a和b将具有相同的属性。 主要区别在于，我们会将所有嘈杂的样本移向数据流形，可以将其视为将一小部分样本移向数据流形。 这将保护区分器免受措施0的对抗示例</p><p>一个有趣的观察是，如果我们有两个分布在$\mathbb{P}_{r}$和$\mathbb{P}_{g}$的支撑集在流形上是封闭的，则噪声项将使嘈杂的分布$\mathbb{P}_{r+\epsilon}$和$\mathbb{P}_{g+\epsilon}$几乎重叠，并且它们之间的JSD将很小。 这与无噪声变型$\mathbb{P}_{r}$和$\mathbb{P}_{g}$形成了鲜明的对比，在无噪声变型中，所有歧管都最大化，而与歧管的紧密程度无关。 我们可以争辩说，使用带噪声的变体的JSD来度量原始分布之间的相似性，但这将取决于噪声量，而不是$\mathbb{P}_{r}$和$\mathbb{P}_{g}$的固有度量。 幸运的是，还有其他选择。</p><ul><li><strong>定义3.1</strong>:$\mathcal{X}$上$P$和$Q$的两个分布的Wasserstein度量$W(P;Q)$的定义。<script type="math/tex; mode=display">W(P, Q)=\inf _{\gamma \in \Gamma} \int_{\mathcal{X} \times \mathcal{X}}\|x-y\|_{2} d \gamma(x, y)</script>其中$\gamma $是$\mathcal{X} \times \mathcal{X}$上具有边际$P$ 和 $Q$的和</li></ul><p>当我们减小噪声方差时，它平稳地变为0。</p><ul><li><strong>引理4</strong>:如果$\epsilon$为一均值为$0$的随机向量，那么<script type="math/tex; mode=display">W\left(\mathbb{P}_{X}, \mathbb{P}_{X+\epsilon}\right) \leq V^{\frac{1}{2}}</script>其中 $V=\mathbb{E}\left[|\epsilon|_{2}^{2}\right]$ 是 $\epsilon$的方差<br><strong>证明</strong>:令$x \sim \mathbb{P}_{X}$和$y=x+\epsilon$ 其中 $\epsilon$和$x$无关。 $\gamma$ 为$(x, y)$的节点，具有边际$\mathbb{P}_{X}$ 和 $\mathbb{P}_{X+\epsilon}$ 因此<script type="math/tex; mode=display">\begin{aligned}W\left(\mathbb{P}_{X}, \mathbb{P}_{X+\epsilon}\right) & \leq \int\|x-y\|_{2} d \gamma(x, y) \\&=\mathbb{E}_{x \sim \mathbb{P}_{X}} \mathbb{E}_{y \sim x+\epsilon}\left[\|x-y\|_{2}\right] \\&=\mathbb{E}_{x \sim \mathbb{P}_{X}} \mathbb{E}_{y \sim x+\epsilon}\left[\|\epsilon\|_{2}\right] \\&=\mathbb{E}_{x \sim \mathbb{P}_{X}} \mathbb{E}_{\epsilon}\left[\|\epsilon\|_{2}\right] \\&=\mathbb{E}_{\epsilon}\left[\|\epsilon\|_{2}\right] \\& \leq \mathbb{E}_{\epsilon}\left[\|\epsilon\|_{2}^{2}\right]^{\frac{1}{2}}=V^{\frac{1}{2}}\end{aligned}</script>其中最后由于Jensen导致不平等</li></ul><p>现在我们来谈谈我们的主要结果之一。 我们感兴趣的是研究Pr和Pg之间的距离而没有任何噪声，即使它们的支撑位于不同的歧管上，因为（例如）这些歧管越近，样本数据歧管上的实际点也越近。 此外，我们最终想要一种评估生成模型的方法，而不论它们是连续的（如在VAE中）还是不连续的（如在GAN中），这是一个目前尚未完全解决的问题。 下一个定理将Pr和Pg的Wasserstein距离（无任何噪声或修改）与Pr +和Pg +的发散度以及噪声的方差相关。 由于Pr +和Pg +是连续分布，因此这种偏差是一个明智的估计，甚至可以尝试将其最小化，因为根据这些分布训练的鉴别器将近似它们之间的JSD，并根据Corolary 3.2提供平滑的梯度。</p><ul><li><strong>定理3.3</strong>:令 $\mathbb{P}_{r}$ and $\mathbb{P}_{g}$ be any two distributions, and $\epsilon$ a random vector with mean 0 and variance $V .$ If $\mathbb{P}_{r+\epsilon}$ and $\mathbb{P}_{g+\epsilon}$ have support contained on a ball of diameter $C,$ then <script type="math/tex; mode=display">W\left(\mathbb{P}_{r} | \mathbb{P}_{g}\right) \leq 2 V^{\frac{1}{2}}+2 C \sqrt{J S D\left(\mathbb{P}_{r+\epsilon} \| \mathbb{P}_{g+\epsilon}\right)}</script><strong>证明</strong>:<script type="math/tex; mode=display">\begin{aligned}W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right) & \leq W\left(\mathbb{P}_{r}, \mathbb{P}_{r+\epsilon}\right)+W\left(\mathbb{P}_{r+\epsilon}, \mathbb{P}_{g+\epsilon}\right)+W\left(\mathbb{P}_{g+\epsilon}, \mathbb{P}_{g}\right) \\& \leq 2 V^{\frac{1}{2}}+W\left(\mathbb{P}_{r+\epsilon}, \mathbb{P}_{g+\epsilon}\right) \\& \leq 2 V^{\frac{1}{2}}+C \delta\left(\mathbb{P}_{r+\epsilon}, \mathbb{P}_{g+\epsilon}\right) \\& \leq 2 V^{\frac{1}{2}}+C\left(\delta\left(\mathbb{P}_{r+\epsilon}, \mathbb{P}_{m}\right)+\delta\left(\mathbb{P}_{g+\epsilon}, \mathbb{P}_{m}\right)\right) \\& \leq 2 V^{\frac{1}{2}}+C(\sqrt{\frac{1}{2} K L\left(\mathbb{P}_{r+\epsilon} \| \mathbb{P}_{m}\right)}+\sqrt{\frac{1}{2} K L\left(\mathbb{P}_{g+\epsilon} \| \mathbb{P}_{m}\right)}) \\& \leq 2 V^{\frac{1}{2}}+2 C \sqrt{J S D\left(\mathbb{P}_{r+\epsilon} \| \mathbb{P}_{g+\epsilon}\right)}\end{aligned}</script></li></ul><p>定理3.3告诉我们一个有趣的idea。即上述式子中的两项是可以控制的。第一项可以通过噪音退火的方式来减少，第二项可以通过一个GAN（基于噪音输入来训练判别器）来最小化，因为他会近似于两个连续分布的JSD。该方法的一个优点是我们不再需要担心训练的选择方案。因为噪音，我们可以训练判别器直到最优而且没任何问题，并通过推理3.2得到平滑的可解释梯度。所有这一切仍然是在最小化$\mathbb{P}_r$和$\mathbb{P}_g$之间的距离，这两个分布也是我们最终关心的两个无噪声分布。</p><blockquote><p><strong>$\downarrow$结论白话文$\downarrow$</strong></p></blockquote><p><strong>原始GAN问题的问题根源</strong></p><ul><li>等价优化的距离衡量（KL散度、JS散度）不合理</li><li>生成器随机初始化后的生成分布很难与真实分布有不可忽略的重叠。</li></ul><p>本文其实已经针对第二点提出了一个解决方案，就是<strong>对生成样本和真实样本加噪声</strong></p><ul><li>直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。</li></ul><p>在训练过程中，我们可以对所加的噪声进行退火（annealing），慢慢减小其方差，到后面两个低维流形“本体”都已经有重叠时，就算把噪声完全拿掉，JS散度也能照样发挥作用，继续产生有意义的梯度把两个低维流形拉近，直到它们接近完全重合。以上是对原文的直观解释。<br>在这个解决方案下我们可以放心地把判别器训练到接近最优，不必担心梯度消失的问题。而当判别器最优时，对公式26取反可得判别器的最小loss为</p><script type="math/tex; mode=display">\begin{aligned} \min L_D(P_{r+\epsilon}, P_{g+\epsilon}) &= - \mathbb{E}_{x\sim P_{r+\epsilon}}\,\,[\log D^*(x)] - \mathbb{E}_{x\sim P_{g+\epsilon}}\,\,[\log(1-D^*(x))] \\ &= 2\log 2 - 2JS(P_{r+\epsilon} || P_{g+\epsilon}) \end{aligned}</script><p>其中$P_{r+\epsilon}$和$P_{g+\epsilon}$分别是加噪后的真实分布与生成分布。反过来说，从最优判别器的loss可以反推出当前两个加噪分布的JS散度。两个加噪分布的JS散度可以在某种程度上代表两个原本分布的距离，也就是说可以通过最优判别器的loss反映训练进程！……真的有这样的好事吗？<br>并没有，因为加噪JS散度的具体数值受到噪声的方差影响，随着噪声的退火，前后的数值就没法比较了，所以它不能成为$P_r$和$P_g$距离的本质性衡量。<br>加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是仍然没能够提供一个衡量训练进程的数值指标。但是WGAN从第一点根源出发，用Wasserstein距离代替JS散度，同时完成了稳定训练和进程指标的问题！</p><blockquote><p><strong>$\uparrow$结论白话文$\uparrow$</strong></p></blockquote><p>WGAN前作分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。<br>WGAN前作针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。</p><hr><h1><span id="附录">附录</span></h1><h2><span id="附录1两者分布不重合js散度为log2"><span id="Appendix_1">附录1——两者分布不重合JS散度为log2</span></span></h2><p><strong>题目</strong>：对于真实数据分布$P_r$和生成数据分布$P_g$，如果满足上述无法全维度重合的情况的话，则$J S D\left(P_{r} | P_{g}\right)=\log 2$<br><strong>证明</strong>：<br>KL散度定义：$D_{K L}(P | Q)=\int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} d x$<br>JS散度定义：$D_{JS}(P||Q)={\frac{1}{2}} KL(P||M) + {\frac{1}{2}} KL(Q||M) \quad \quad M = {\frac{1}{2}}(P+Q)$</p><script type="math/tex; mode=display">\begin{aligned}&\therefore     \begin{aligned}     J S D(P \| Q)&=\frac{1}{2} \int_{-\infty}^{\infty} p(x) \log \left(\frac{p(x)}{\frac{p(x)+q(x)}{2}}\right)+\frac{1}{2} \int_{-\infty}^{\infty} q(x) \log \left(\frac{q(x)}{\frac{p(x)+q(x)}{2}}\right)\\    &=\frac{1}{2} \int_{-\infty}^{\infty} p(x) \log \left(\frac{2 p(x)}{p(x)+q(x)}\right)+\frac{1}{2} \int_{-\infty}^{\infty} q(x) \log \left(\frac{2 q(x)}{p(x)+q(x)}\right)    \end{aligned}\\&\because \int_{-\infty}^{\infty} p(x)=\int_{-\infty}^{\infty} q(x)=1\\&\therefore J S D(P \| Q)=\frac{1}{2} \sum p(x) \log \left(\frac{p(x)}{p(x)+q(x)}\right)+\frac{1}{2} \sum q(x) \log \left(\frac{q(x)}{p(x)+q(x)}\right)+\log 2\end{aligned}</script><p>因为对于任意一个$x$只有四种可能：</p><ul><li>$P_1(x) = 0$且$P_2(x) = 0$对计算JS散度无贡献</li><li>$P_1(x) \neq 0$且$P_2(x) \neq 0$由于重叠部分可忽略所以贡献也为0</li><li>$P_1(x) = 0$且$P_2(x) \neq 0$第一项因为$0 \times y=0$,第二项因为$\log (1)=0$</li><li>$P_1(x) \neq 0$且$P_2(x) = 0$与上述情况类似<script type="math/tex; mode=display">\therefore \forall x \in R, \text { 都有 } J S D(P \| Q)=\log 2</script></li></ul><hr><p><a href="http://arxiv.org/abs/1701.04862" target="_blank" rel="noopener">Paper—-Towards Principled Methods for Training Generative Adversarial Networks</a><br><a href="https://www.cnblogs.com/shouhuxianjian/p/10268624.html" target="_blank" rel="noopener">博客园—-Generative Adversarial Nets[Pre-WGAN]</a><br><a href="https://blog.csdn.net/xiaohouzi1992/article/details/80839921" target="_blank" rel="noopener">CSDN—-Wasserstein GANs 三部曲（一）：Towards Principled Methods for Training Generative Adversarial Networks的理解</a><br><a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank" rel="noopener">知乎—-令人拍案叫绝的Wasserstein GAN</a></p><p><a href="https://zhuanlan.zhihu.com/p/31394374" target="_blank" rel="noopener">知乎—-WGAN和GAN直观区别和优劣</a><br><a href="https://blog.csdn.net/Jasminexjf/article/details/82621223" target="_blank" rel="noopener">CSDN—-GAN（Generative Adversarial Network）的学习历程</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-towards-principled-methods-for-training-generative-adversarial-networks&quot;&gt;1. Towards Principled Methods for
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>DCGAN:Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/12/2016-Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/12/2016-Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks阅读笔记/</id>
    <published>2020-02-12T15:17:28.000Z</published>
    <updated>2020-02-12T15:22:06.797Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-unsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks">1. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></li><li><a href="#2-总结">2. 总结</a></li><li><a href="#3-引言">3. 引言</a></li><li><a href="#4-相关工作">4. 相关工作</a></li><li><a href="#5-dcgan构建方法cnn">5. DCGAN构建方法(CNN)</a></li><li><a href="#6-对抗式训练的细节">6. 对抗式训练的细节</a></li><li><a href="#7-参考资料">7. 参考资料</a></li></ul><!-- tocstop --><hr><h1><span id="1-unsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks">1. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</span></h1><blockquote><p>arXiv:1511.06434 [cs]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h1><span id="2-总结">2. 总结</span></h1><ul><li>要解决什么问题<ul><li>结合CNN和GAN，提出了具体的实现细节和技巧</li><li>对CNN结果进行可视化，帮助理解CNN过程</li></ul></li><li>用什么方法解决<ul><li>通过CNN构建GAN中的生成器和判别器</li><li>在CNN具体实现中，提出了一些改进方案，提高稳定性</li></ul></li><li>还存在什么问题<ul><li>稳定性差——GAN通病</li></ul></li></ul><hr><h1><span id="3-引言">3. 引言</span></h1><ul><li>提出并评估了一系列卷积GAN体系结构拓扑上的约束条件，这些约束条件使得它们在大多数情况下可以稳定地训练。我们将这种架构称为Deep Convolutional GANs（DCGAN）</li><li>使用图像分类任务上训练出来的判别器和其他的非监督算法做了比较</li><li>对GAN学习到的特征做出了可视化，并经验性的证明了特殊的特征表征了特殊的对象</li><li>针对生成器，我们提出了一个很有趣的算法向量，这个向量能很简单的在语义层面上操作生成样例的质量</li></ul><hr><h1><span id="4-相关工作">4. 相关工作</span></h1><ul><li><p>无监督的表征学习</p><ul><li>一个经典的非监督表征学习手段是做出数据聚类，之后利用聚类结果来改善分类结果。</li><li>训练自编码器（卷积式的自编码器）都能将图像作成紧编码，并且尽可能的通过解码器还原图像<ul><li>分离编码中向量的意义和位置</li><li>分析编码的梯度结构</li></ul></li></ul></li><li><p>生成自然图像</p><ul><li>参数化领域<br>  是在图像数据库下做匹配，经常对成批的图像做匹配，它在纹理合成，超分辨率重建和in-paiting中用的较多。</li><li>非参数化领域</li></ul></li><li><p>CNN内部的可视化<br>使用反卷积，过滤最大激活，可以逼近网络中每一个卷积滤波器的结果</p></li></ul><hr><h1><span id="5-dcgan构建方法cnn">5. DCGAN构建方法(CNN)</span></h1><ul><li>全卷积网络<br>  使用<strong>逐步卷积替代确定性的空间池化函数</strong>,允许网络学习自身上采样(upsampling)或下采样(downsampling)方式（生成器G/判别器D）。在网络中，所有的pooling层使用步幅卷积(判别网络)和微步幅度卷积(生成网络)进行替换。</li><li>在卷积特征之上消除全连接层<br>  例如全局平均池化，全局平均pooling增强了模型稳定性，但减缓了收敛速度</li><li><p>批量归一化(Batch Normalization)<br>  将每个单元的输入都标准化为0均值与单位方差</p><ul><li>改进了训练问题</li><li><p>缓解了深层网络中的梯度溢出问题</p><p>但实际上，这种方法在深层的生成器中被证明是不适用的，它会<strong>导致生成器反复震荡生成单点数据</strong>。但是，将所有层都进行BN，会导致样本震荡和模型不稳定，所以，<strong>不要在生成器的输出层和判别器的输入层上使用BN</strong>。</p></li></ul></li><li>激活函数<br>  生成器：除了最终输出层使用<code>Tanh</code>，其他都使用<code>Relu</code><br>  判别器：都是用<code>leaky relu</code>(leaky rectified activation)</li></ul><p><strong>稳定DCGAN的架构指导：</strong></p><ul><li>判别器中，使用带步长的卷基层来替换所有pooling层，生成器中使用小步长卷积来代替pooling层。 </li><li>在生成器和判别器中使用BN。 </li><li>去除深度架构中的全连接隐藏层。</li><li>生成器中，除去最后一层使用Tanh之外，每一层都使用ReLU来激活。 </li><li>判别器中，每一层都使用LeakReLU来激活。</li></ul><hr><h1><span id="6-对抗式训练的细节">6. 对抗式训练的细节</span></h1><ul><li>基本对原始数据都不进行数据增强，只是将像素值变换到[-1,1]之间（与生成器最终输出层的tanh对应）</li><li>使用Adam作为优化器，初始学习率0.0002，beta_1=0.5</li><li>leaky relu=0.2</li></ul><p>判别器的网络构造<br><img src="https://image.zkhweb.top/20200212214025.png" alt="20200212214025.png"><br><strong>常用验证unsupervised representation learning algorithms</strong> 的方法是：<br>选择某个监督学习数据集，使用训练好的模型输入数据提取特征，使用线性模型用于监督数据集任务，查看性能。</p><hr><h1><span id="7-参考资料">7. 参考资料</span></h1><p><a href="http://arxiv.org/abs/1511.06434" target="_blank" rel="noopener">Paper—-Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a><br><a href="https://blog.csdn.net/xiening0618/article/details/79417734" target="_blank" rel="noopener">CSDN—-论文翻译——无监督DCGAN做表征学习</a><br><a href="https://blog.csdn.net/qq_40667584/article/details/79690043" target="_blank" rel="noopener">CSDN—-DCGAN论文译本</a><br><a href="https://blog.csdn.net/wspba/article/details/54730871" target="_blank" rel="noopener">CSDN—-DCGAN论文笔记+源码解析</a><br><a href="https://blog.csdn.net/stalbo/article/details/79359095" target="_blank" rel="noopener">CSDN—-GAN论文阅读——DCGAN</a><br><a href="https://zhuanlan.zhihu.com/p/40126869" target="_blank" rel="noopener">知乎—-精读深度学习论文(26) DCGAN</a><br><a href="https://buptldy.github.io/2016/10/29/2016-10-29-deconv/" target="_blank" rel="noopener">个人Blog—-Transposed Convolution, Fractionally Strided Convolution or Deconvolution</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-unsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks&quot;&gt;1. Unsupervi
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>InfoGAN:Interpretable Representation Learning by Information MaximizingGenerative Adversarial Nets阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/09/2016-InfoGAN-Interpretable-Representation-Learning-by-Information-Maximizing-Generative-Adversarial-Nets%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/09/2016-InfoGAN-Interpretable-Representation-Learning-by-Information-Maximizing-Generative-Adversarial-Nets阅读笔记/</id>
    <published>2020-02-09T15:54:52.000Z</published>
    <updated>2020-02-12T15:21:53.901Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets">1. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a><ul><li><a href="#11-摘要">1.1. 摘要</a></li><li><a href="#12-引言">1.2. 引言</a></li><li><a href="#13-相关工作">1.3. 相关工作</a></li><li><a href="#14-补充知识">1.4. 补充知识</a><ul><li><a href="#141-信息量">1.4.1. 信息量</a></li><li><a href="#142-信息熵">1.4.2. 信息熵</a></li><li><a href="#143-互信息">1.4.3. 互信息</a></li></ul></li><li><a href="#15-infogan">1.5. InfoGAN</a><ul><li><a href="#151-知识回顾生成对抗网络">1.5.1. 知识回顾——生成对抗网络</a></li><li><a href="#152-符号定义">1.5.2. 符号定义</a></li><li><a href="#153-直观感受">1.5.3. 直观感受</a></li><li><a href="#154-目标函数">1.5.4. 目标函数</a></li><li><a href="#155-对抗">1.5.5. 对抗</a></li><li><a href="#156-目标函数由来">1.5.6. 目标函数由来</a></li><li><a href="#157-变分互信息最大化">1.5.7. 变分互信息最大化</a></li></ul></li><li><a href="#16-实现">1.6. 实现</a></li><li><a href="#17-实验">1.7. 实验</a><ul><li><a href="#171-互信息的最大化">1.7.1. 互信息的最大化</a></li><li><a href="#172-有区分度的表示">1.7.2. 有区分度的表示</a></li></ul></li><li><a href="#18-结论">1.8. 结论</a></li><li><a href="#19-附录解释为sleep-sleep算法">1.9. 附录——解释为“sleep-sleep”算法</a></li><li><a href="#110-参考资料">1.10. 参考资料</a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets">1. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</span></h1><blockquote><p>arXiv:1606.03657 [cs.LG]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-摘要">1.1. 摘要</span></h2><p><strong>InfoGAN</strong></p><ul><li>对生成对抗网络的信息理论扩展</li><li>完全无监督的方式学习特征分离表示</li><li>能最大化潜在变量的一小部分与观察(生成)结果之间的互信息</li></ul><p><strong>本文</strong></p><ul><li>有效优化的互信息目标的下界</li><li>InfoGAN可以学习与现有监督方法学习得到了具有竞争力的可解释性表征。</li></ul><hr><h2><span id="12-引言">1.2. 引言</span></h2><p><strong>无监督学习</strong></p><ul><li>一般可以被描述为从大量存在的未标记数据中提取数值的问题。</li><li>流行框架是<strong>表征学习</strong><ul><li>目标是使用未标记的数据来学习一种表示，以从重要语义特征中找到易于解释的要素。</li></ul></li><li>特征分离的表示对于需要知道数据的显著属性的自然任务可能是有用的</li><li>无监督学习算法必须对下游分类任务有正确的效果（在不直接接触下游任务的情况下）。</li><li>很大一部分是由生成模型驱动的。<ul><li>动力源于对生成模型能力的相信，或为观察数据“创造”某种形式的理解，并希望良好的生成模型能自动学习一个有区分度的表示，即便通过随便一个不好的表示也容易构造完美的生成模型。最突出的生成模型是变分自动编码器（VAE）和生成对抗网络（GAN）。</li></ul></li></ul><p><strong>本文</strong></p><ul><li>生成对抗网络目标进行了简单的修改，鼓励其学习可解释和有意义的表示。</li><li>通过最大化GAN噪声变量的固定小子集与观测值之间的互信息来实现，这一点相对比较直观。</li><li>增加互信息成本的生成模型是学习特征表示的有效途径。</li></ul><hr><h2><span id="13-相关工作">1.3. 相关工作</span></h2><p>现在存在大量关于无监督表示学习的工作。</p><ul><li>早期的方法是基于堆叠的（通常是去噪）自动编码器或受限玻尔兹曼机</li><li>阶梯网络，它在MNIST数据集的半监督变学习上取得了惊人的成果。</li></ul><p>此外，先前的研究试图使用监督数据来学习分离的特征表示。</p><ul><li>使用监督学习训练表示的一部分来匹配所提供的标签</li><li>弱监督方法来消除对明确标记变量的需要</li></ul><hr><h2><span id="14-补充知识">1.4. 补充知识</span></h2><h3><span id="141-信息量">1.4.1. 信息量</span></h3><p>$ I(x) = -\log {p(x)} = \log { \frac { 1}{ p (x) }  } $<br>一个事件发生的概率越大，这件事情发生所包含的信息量就越小，比如说一个高富帅追求一个白富美，追到手了没有什么稀奇的，因为这是一件概率很高的事情，但是如果一个矮穷矬追求一个白富美，追到手了，这种事情发生的概率很低，其中一定有其他的原因：比如这个矮穷矬救过白富美的命或者这个矮穷矬器大活好不黏人，所以概率低的事情发生所包含的信息量大；两个相互独立的事情同时发生的信息量是两者单独发生的信息量之和。</p><h3><span id="142-信息熵">1.4.2. 信息熵</span></h3><p>信息量的均值</p><script type="math/tex; mode=display">H(x) = - \sum _{ x } p(x)log p(x)</script><h3><span id="143-互信息">1.4.3. 互信息</span></h3><p>在信息论中，X和Y之间的互信息 $I(X;Y)$测量从随机变量Y的知识中学习的关于另一个随机变量X的“信息量”。</p><ul><li>互信息可以表示为两个熵项的差值：<script type="math/tex; mode=display">I(X;Y)=H(X)-H(X|Y)=H(Y)-H(Y|X)</script>这个定义有一个直观的解释： $I(X,Y)$是观察到 $Y$ 时， $X$的不确定性的减少量。如果 $X$ 和 $Y$ 是独立的，那么 $I(X;Y)=0$ ，因为一个变量与另一个变量毫无关系；相反，如果$X$和$Y$通过确定性可逆函数相关，则获得最大互信息。<br><img src="https://image.zkhweb.top/20200209214308.png" alt="20200209214308.png"></li></ul><hr><h2><span id="15-infogan">1.5. InfoGAN</span></h2><h3><span id="151-知识回顾生成对抗网络">1.5.1. 知识回顾——生成对抗网络</span></h3><p>生成器G，判别器D，相互对抗使目标函数，达到最优。</p><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]</script><p>但是<strong>无约束、不可控、噪声信号z很难解释等问题。</strong></p><h3><span id="152-符号定义">1.5.2. 符号定义</span></h3><p>$x$ $\rightarrow$ 真实数据<br>$y$ $\rightarrow$ 标签（辅助信息）<br>$z$ $\rightarrow$ 噪音（生成器的输入数据）<br>$c$ $\rightarrow$ 潜在代码(latent code)<br>$p_c$ $\rightarrow$ 潜在代码的分布，可以为连续分布，也可以为离散分布<br>$p_x$ $\rightarrow$ 真实数据的分布<br>$p_{z}(z)$ $\rightarrow$ 原始噪音数据的分布<br>$p_g$ $\rightarrow$ 经过生成器后数据的分布<br>$G()$ $\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\theta_{g}$<br>$D()$ $\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\theta_{d}$<br>$Q(c|x)$ $\rightarrow$ 辅助分布用于逼近后验概率$P(c|x)$<br>$G(z,c;\theta_{g})$ $\rightarrow$ 将噪音$z$和潜在代码映射到新的数据空间<br>$D(x ; \theta_{d})$ $\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）</p><h3><span id="153-直观感受">1.5.3. 直观感受</span></h3><p><img src="https://image.zkhweb.top/20200209213237.png" alt="20200209213237.png"><br>当Q与D共享参数<br><img src="https://image.zkhweb.top/20200209213913.png" alt="20200209213913.png"></p><h3><span id="154-目标函数">1.5.4. 目标函数</span></h3><script type="math/tex; mode=display">\begin{aligned}\min _{G} \max _{D} V_{I}(D, G)&=V(D, G)-\lambda I(c ; G(z, c)) \\&= { \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]-\lambda I(c ; G(z, c))\end{aligned}</script><p>和原始GAN相近，只是G中加入了潜码$c$（和$G(z,c)$有关），可以调节$c$来改变生成样式(加入了互信息的惩罚)</p><p>当用分布$Q(c|x)$逼近后验概率$P(c|x)$时，目标函数变为</p><script type="math/tex; mode=display">\min_{G,Q}\max_D V_{InfoGAN}(D,G,Q)=V(D,G)-\lambda L_I(G,Q)</script><p><strong>Note</strong>:此处的$V(D, G)$不局限于原始GAN的代价函数，可以使用其他的代价函数，以获得更好的训练</p><h3><span id="155-对抗">1.5.5. 对抗</span></h3><p>判别器$D$的目标</p><ol><li>要尽可能把真的样本判断为真，对应最大化第一项：${ E }_{ x ～ { p }_  { data } (x) }[logD(x)]$</li><li>把假的样本判断为假，对应最大化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z,c)))] $</li></ol><ul><li>总之，也就是说<strong>判别器$D$要最大化目标函数</strong>；</li></ul><p>生成器$G$的目标</p><ol><li>要尽可能的让$D$将生成的假样本判断为真，对应最小化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $</li><li>同时加入潜码$c$是为了使生成$G(z,c)$和$c$有很强的关联：$I(c ; G(z, c))$最大化，即$-\lambda I(c ; G(z, c))$($\lambda$为整数)最小</li></ol><ul><li>总之，也就是说<strong>生成器$G$要最小化目标函数</strong>；</li></ul><p>总的来说，这是一个<strong>信息正则化的MinMax Game</strong>；<br>当用分布$Q(c|x)$逼近后验概率$P(c|x)$时，InfoGAN<strong>具有互信息和超参数λ的变分正则化的MinMax Game</strong></p><h3><span id="156-目标函数由来">1.5.6. 目标函数由来</span></h3><p>为了让让网络学习到了可解释的特征表示<br>将提出将<strong>输入噪声向量分成为两部分</strong>：</p><ul><li>$z$:被视为不可压缩的噪声源；</li><li>$c$<sup><a href="#fn_1" id="reffn_1">1</a></sup>:将其称为潜在代码(latent code)，其目的在于数据分布的显著结构化的语义特征。</li></ul><p><sup><a href="#fn_1" id="reffn_1">1</a></sup>:在数学上，$c_1,c_2,…,c_L$​ 表示结构化潜在变量的集合。在其最简单的形式中，可以假设一个因式分布，由 $P\left(c_{1}, c_{2}, \ldots, c_{L}\right)=\prod_{i=1}^{L} P\left(c_{i}\right)$ 给出。为了便于表示，使用潜在代码 $c$ 来表示所有潜在变量 $c_i$​ 的联合。</p><p>但是在标准GAN中，通过找到满足 $P_G(x|c)= P_G(x)$ 的解，生成器可以自由地忽略附加潜在代码$c$ 。</p><p>提出了一种<strong>基于信息论的正则化方法</strong>：潜在码 $c$ 和生成分布 $G(z,c)$ 之间应该有很高的互信息。因此 $I(c;G(z,c))$ 应该很高。</p><p>给定任何 $x \sim P_{G}(x)$ ，希望 $P_G(c|x)$ 具有小的熵。换句话说，<strong>潜在码 $c$ 中的信息不应该在生成过程中丢失</strong>。在聚类的背景下，之前已经有过类似的互信息启发目标函数。因此，本文建议通过以下信息正则化的minimax游戏来解决问题：</p><script type="math/tex; mode=display">\min _{G} \max _{D} V_{I}(D, G)=V(D, G)-\lambda I(c ; G(z, c))</script><h3><span id="157-变分互信息最大化">1.5.7. 变分互信息最大化</span></h3><p><strong>引理1</strong>对于随机变量$X$，$Y$和函数$f(x,y)$在适当的正则条件下$\mathbb{E}_{x \sim X, y \sim Y | x}[f(x, y)]=\mathbb{E}_{x \sim X, y \sim Y\left|x, x^{\prime} \sim X\right| y\left[f\left(x^{\prime}, y\right)\right]}$</p><p><strong>证明</strong>：</p><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}_{x \sim X, y \sim Y | x}[f(x, y)] &=\int_{x} P(x) \int_{y} P(y | x) f(x, y) d y d x \\&=\int_{x} \int_{y} P(x, y) f(x, y) d y d x \\&=\int_{x} \int_{y} P(x, y) f(x, y) \int_{x^{\prime}} P\left(x^{\prime} | y\right) d x^{\prime} d y d x \\&=\int_{x} P(x) \int_{y} P(y | x) \int_{x^{\prime}} P\left(x^{\prime} | y\right) f\left(x^{\prime}, y\right) d x^{\prime} d y d x \\&=\mathbb{E}_{x \sim X, y \sim Y\left|x, x^{\prime} \sim X\right| y}\left[f\left(x^{\prime}, y\right)\right]\end{aligned}</script><p><strong>变分信息最大化</strong><br>互信息项 $I(c;G(z,c))$ 难以直接最大化，因为它先得到后验概率 $P(c|x)$ 。<br><strong>通过定义辅助分布 $Q(c|x)$ 来逼近 $P(c|x)$</strong> ，可以得到它的下界：</p><script type="math/tex; mode=display">\begin{aligned}I(c ; G(z, c)) &=H(c)-H(c | G(z, c)) \\&=\mathbb{E}_{c \sim P(c),x \sim G(z, c)}[\log P(c |x)]+H(c)\\根据引理1&=\mathbb{E}_{x \sim G(z, c)} \left[\mathbb{E}_{c^{\prime} \sim P(c | x)} \left[\log P(c^{\prime}|x) \right] \right]+H(c)\\&=\mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log P\left(c^{\prime} | x\right)\right]\right]+H(c) \\&=\mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c | x)} \left[ \frac{P(c^{\prime} | x) Q(c^{\prime} | x)}{Q(c^{\prime} | x)} \right] \right] \\&=\mathbb{E}_{x \sim G(z, c)}\left[  \mathbb{E}_{c^{\prime} \sim P(c | x)} \left[ \log \frac{P(c^{\prime} | x)}{Q(c^{\prime} | x)}\right]+ \mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]+H(c)\\&=\mathbb{E}_{x \sim G(z, c)}\left[\underbrace{D_{K L}(P(\cdot | x) \| Q(\cdot | x))}_{\geq 0}+\mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]+H(c) \\& \geq \mathbb{E}_{x \sim G(z, c)}[{\left.D_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]}+H(c)\end{aligned}</script><p>潜在编码 $H(c)$ 的熵也可以优化，因为对于常见分布，它具有简单的分析形式。然而，在本文中，通过修复潜在编码分布来选择简化的表示，并<strong>将 $H(c)$ 视为常量</strong>。</p><p><strong>引理2</strong> 对随机变量 $X$,$Y$ 和函数 $f(x,y)$ ，在合适的规则条件下： $\mathbb{E}_{x \sim X, y \sim Y | x}[f(x, y)]=\mathbb{E}_{x \sim X, y \sim Y|x, x^{\prime} \sim X| y}[f\left(x^{\prime}, y\right)]$</p><p><strong>证明</strong>：<br>通过使用引理1可以定义互信息 $I(c;G(z,c))$ 变分的下界 $L_I(G,Q)$:</p><script type="math/tex; mode=display">\begin{aligned}L_{I}(G, Q) &=E_{c \sim P(c), x \sim G(z, c)}[\log Q(c | x)]+H(c) \\&=E_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]+H(c) \\& \leq I(c ; G(z, c))\end{aligned}</script><p>注意到 $L_I(G,Q)$ 很容易用<strong>蒙特卡罗模拟近似</strong>。 特别是，可以对于 w.r.t.$Q$ 和 w.r.t.$G$ 使用重参数化技巧将 $L_I$​ 最大化。 因此， $L_I(G,Q)$ 可以添加到GAN的目标而不改变GAN的训练过程，称之为<strong>信息最大化生成对抗网络(InfoGAN)</strong>。</p><p>变分互信息最大化表明，当辅助分布 $Q$ 接近真实的后验分布 $\mathbb E_x[D_{KL}P(·|x)||Q(·|x))]→0$ 时，下限变紧了。另外，当变分下界达到离散潜码的最大值 $L_I(G,Q)= H(c)$ 时，边界变紧并且达到最大互信息。</p><hr><h2><span id="16-实现">1.6. 实现</span></h2><p><strong>整体</strong></p><ul><li>将辅助分布 $Q$ 参数化为神经网络。 <ul><li>在大多数实验中， $Q$ 和 $D$ <strong>共享所有卷积层</strong></li><li>存在一个最终完全连接的层以输出条件分布 $Q(c|x)$ 的参数(softmax)</li></ul></li></ul><p>这意味着InfoGAN仅向GAN添加了<strong>可忽略的计算成本</strong><br>在实验中， $L_I(G,Q)$ 总是比正常的GAN目标更快收敛</p><p><strong>分类的潜在代码$c_i$​</strong></p><ul><li>使用非线性softmax来表示 $Q(c_i|x)$<ul><li>对于连续潜在代码 $c_j$​ ，根据真正的后验概率 $P(c_j|x)$ ，有更多的选项。可以简单地将 $Q(c_j|x)$ 作为因子化的高斯来处理就足够了。</li></ul></li><li><p><strong>c为离散变量</strong><br>$Q(c|x)$可以表示为一个神经网络$Q(X)$的输出</p><script type="math/tex; mode=display">\begin{aligned}&\because L_{I}(G, Q)=c \cdot \log Q(G(z, c))+H(c)\\&\therefore \max L_{I}(G, Q) \text{等价于} \max c \cdot \log Q(G(z, c))\end{aligned}</script><p>其中$\cdot$表示内积，c是一个选择计算哪个$\log$的参数，$H(c)$可以消去<br><strong>$L_I(G,Q)$本质上是$x$与$G(z,x)$之间的KL散度</strong></p><script type="math/tex; mode=display">\begin{aligned}&\because \begin{aligned}D_{K L}(c \| Q(G(z, c))) &=-c \cdot \log \frac{Q(G(z, c))}{c} \\&=-c \cdot \log Q(G(z, c))+c \cdot \log c \\&=-c \cdot \log Q(G(z, c))+H(c) \\&=-L_{I}(G, Q)+2 H(c)\end{aligned}\\&\therefore \max L_{I}(G, Q) \text{等价于} \min D_{K L}(c \| Q(G(z, c)))\end{aligned}</script><p>$\min D_{K L}(c | Q(G(z, c)))$意味着减少$c$与$Q(G(z, c)$</p></li><li><p><strong>c为连续变量</strong><br>设 $Q(x)$ 输出的参数潜码 $c$ 的均值 $\mu$，标准差 $\sigma$ 分别为 $Q(x)_{\mu}$ 和$Q(x)_{\sigma}$，那么对于参数潜码 c</p><script type="math/tex; mode=display">\begin{aligned}&L_{I}(G, Q)=\mathbb{E}_{x \sim G(z, c)}\left[\mathbb{E}_{c^{\prime} \sim P(c | x)}\left[\log Q\left(c^{\prime} | x\right)\right]\right]+H(c) \\&\because p(x)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}(\text{c符合正态分布;均值 $\mu$,标准差 $\sigma$})\\&\therefore \log p(c) = -\frac{(c-\mu)^{2}}{2 \sigma^{2}}-\log (\sigma \sqrt{2 \pi})\\&\therefore L_{I}(G, Q)=-\frac{\left(c-Q(x)_{\mu}\right)^{2}}{2 Q(x)_{\sigma}^{2}}-\log \left(Q(x)_{\sigma} \sqrt{2 \pi}\right)+H(c)\\&\therefore \max L_{I}(G, Q) \text{等价于} \min \left(\frac{\left(c-Q(x)_{\mu}\right)^{2}}{2 Q(x)_{\sigma}^{2}}+\log \left(Q(x)_{\sigma} \sqrt{2 \pi}\right)\right)\end{aligned}</script><p>不考虑$Q(x)_{\sigma}$的影响则</p><script type="math/tex; mode=display">\max L_{I}(G, Q) \text{等价于} \min \left(c-Q(x)_{\mu}\right)^{2}</script><p>$\min \left(c-Q(x)_{\mu}\right)^{2}$意味这减小$c$与$Q(x)_{\mu}$的差</p></li><li><p><strong>总之$L_{I}$的优化过程，实质上是以G为编码器(Encoder)，Q为解码器(Decoder)，生成图像作为要编码的码(code)，训练一个自编码器(Autoencoder)</strong></p></li></ul><p><strong>超参数 $\lambda$</strong></p><ul><li>对于<em>离散</em>的潜在代码，它很容易调整，简单地设置为1就足够。</li><li>当潜在编码包含<em>连续</em>变量时，较小的 $\lambda$ 通常用于确保包含差分熵的 $L_I(G,Q)$ 的规模与GAN目标的规模相同。</li></ul><hr><h2><span id="17-实验">1.7. 实验</span></h2><p><strong>目标</strong></p><ul><li>调查是否可以有效地最大化互信息</li><li>评估InfoGAN是否可以通过利用生成器一次仅改变一个潜在因子来学习有区分度的可解释的表示，以评估改变这样的因素是否导致生成的图像中只有一种类型的语义变化。 </li></ul><h3><span id="171-互信息的最大化">1.7.1. 互信息的最大化</span></h3><p>为了评估潜在编码 $c$ 和生成的图像 $G(z,c)$ 之间的互信息是否可以通过提出的方法有效地最大化，作者在MNIST数据集上训练InfoGAN，对潜在编码 $c$ 进行统一的分类分布 $c\sim Cat(K=10,p=0.1)$ 。在 图1 中，下限 $L_I(G,Q)$ 被快速最大化为 $H(c)\approx 2.30$ ，这意味着下限 (4) 快速紧贴到到最大的互信息。</p><p>作为基准，当没有明确促使生成图像与潜在编码最大化的互信息时，作者还训练具有辅助分布 $Q$ 的常规GAN。由于作者使用神经网络对 $Q$ 进行参数化，假设 $Q$ 可以合理地近似真实的后验概率 $P(c|x)$ ，因此在常规GAN中潜在编码和生成图像之间几乎没有互信息。作者注意到，使用不同的神经网络架构，即使在实验中没有观察到这种情况，潜在代码和生成的图像之间可能存在更高的相互信息。这种比较是为了证明在常规GAN中，不能保证生成器能够利用潜在编码。</p><h3><span id="172-有区分度的表示">1.7.2. 有区分度的表示</span></h3><p><strong>离散的c捕捉离散变换，连续的c捕捉连续变换</strong><br><strong>MNIST</strong></p><ul><li>$c_1\sim Cat(K=10,p=0.1)$ 控制数字</li><li>$c_2 \sim Unif(-1,1)$​ 控制旋转数字</li><li>$c_3 \sim Unif(-1,1)$​ 控制宽度</li></ul><p>但$c_2,c_3$​还调整其他细节，如厚度或笔触样式<br>$c$处于$-2 \sim 2$之间仍有用，表明InfoGAN学习的潜在表示可泛化</p><p><strong>Faces</strong><br>$c_i\sim Unif(-1,1),1\leq i\leq 5$<br>表示为方位角（姿势），仰角和照明等潜在因素看做连续潜在变量。</p><p><strong>CelebA</strong><br>$c_1,c_2,c_3,c_4\sim (K=20,p=0.05)$和一个连续码 $c_5\sim Unif(-1,1)$<br>代表旋转的连续编码。使用单个连续代码连续插入不同宽度的类似椅子类型。</p><p><strong>SVHN</strong><br>利用四个10维分类变量和两个均匀连续变量作为潜在代码。</p><hr><h2><span id="18-结论">1.8. 结论</span></h2><ul><li>InfoGAN完全没有监督</li><li>在具有挑战性的数据集上学习可解释和有区分度的表示。</li><li>InfoGAN在GAN之上仅增加了可忽略不计的计算成本，并且易于训练。 </li><li>使用互信息表示的核心思想可以应用于其他方法，</li></ul><hr><h2><span id="19-附录解释为sleep-sleep算法">1.9. 附录——解释为“sleep-sleep”算法</span></h2><p>InfoGAN可以看作是Helmholtz机（wake-sleep算法）：</p><ul><li>$P_{G}(x | c)$是生成分布</li><li>$Q(c|x)$识别分布</li></ul><p>提出wake-sleep算法，通过执行wake阶段和sleep阶段更新Helmholtz机</p><ul><li>wake阶段：通过优化有关生成的变分下界$\log P_G(x)$来更新<script type="math/tex; mode=display">\max _{G} \mathbb{E}_{x \sim \operatorname{Data}, c \sim Q(c | x)}\left[\log P_{G}(x | c)\right]</script></li><li>sleep阶段：通过在当前生成分布中生成样本，而不是从实际数据分布中提取样本来更新辅助分布</li></ul><p>因此，当优化代理损失函数<sup><a href="#fn_2" id="reffn_2">2</a></sup>$L_I$（关于$Q$），更新步骤正是wake-sleep算法中的sleep过程。<br>InfoGAN与Wake-sleep不同之处在于优化$L_I$（关于$Q$）生成网络G在潜在代码$P(c)$整个先前分布中使用了潜在代码$c$。由于InfoGAN在sleep过程中更新了生成器，所以可以解释为sleep-sleep算法。</p><p>这种解释突出了InfoGAN与以前生成建模技术的区别：<br>明确鼓励生成器以潜在代码传达信息，并建议将相同原理应用于其他生成模型。</p><p><sup><a href="#fn_2" id="reffn_2">2</a></sup>:代理损失函数:当原本的loss function不便计算的时候，我们就会考虑使用surrogate loss function。</p><hr><h2><span id="110-参考资料">1.10. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1606.03657" target="_blank" rel="noopener">Paper—-InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a><br><a href="https://blog.csdn.net/hjimce/article/details/55657325" target="_blank" rel="noopener">CSDN—-深度学习（四十八）InfoGAN学习笔记</a><br><a href="https://zhuanlan.zhihu.com/p/58261928" target="_blank" rel="noopener">知乎—-InfoGAN解读</a><br><a href="https://www.inference.vc/infogan-variational-bound-on-mutual-information-twice/" target="_blank" rel="noopener">个人Blog—-InfoGAN: using the variational bound on mutual information (twice)</a><br><a href="https://www.jiqizhixin.com/articles/2018-10-29-21" target="_blank" rel="noopener">机器之心—-InfoGAN：一种无监督生成方法 | 经典论文复现</a><br><a href="http://www.pianshen.com/article/448358405/" target="_blank" rel="noopener">程序员大本营—-【GAN ZOO翻译系列】InfoGAN： Interpretable Representation Learning by Information Maximizing GAN</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets&quot;&gt;1. In
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>Maxout Networks阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/07/2013-Maxout-Networks%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/07/2013-Maxout-Networks阅读笔记/</id>
    <published>2020-02-07T03:14:42.000Z</published>
    <updated>2020-02-07T07:38:00.448Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-maxout-networks">1. Maxout Networks</a><ul><li><a href="#11-摘要">1.1. 摘要</a></li><li><a href="#12-介绍">1.2. 介绍</a></li><li><a href="#13-回顾droupt">1.3. 回顾droupt</a></li><li><a href="#14-模型maxout描述">1.4. 模型maxout描述</a></li><li><a href="#15-maxout是一个通用的近似器">1.5. Maxout是一个通用的近似器</a></li><li><a href="#16-maxout与relu">1.6. maxout与relu</a></li><li><a href="#17-模型平均">1.7. 模型平均</a></li><li><a href="#18-优化">1.8. 优化</a></li><li><a href="#19-参考资料">1.9. 参考资料</a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-maxout-networks">1. Maxout Networks</span></h1><blockquote><p>arXiv:1302.4389 [stat.ML]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-摘要">1.1. 摘要</span></h2><p>maxout：</p><ul><li>旨在通过dropout来加快优化过程，并提高准确度（与drop共同使用）；</li><li><strong>模型的输出是模型输入的最大值</strong></li></ul><hr><h2><span id="12-介绍">1.2. 介绍</span></h2><p>dropout</p><ul><li>可以训练集成模型</li><li>共享参数并近似的对这些模型的预测进行了平均</li><li><strong>一种不加区分的适用型工具，几乎可以应用于任何模型，都可以产生一定的性能改进。</strong></li></ul><p>dropout与SDG</p><ul><li><strong>dropout</strong><br>在更新时最有效的方式是<strong>使用更大的步长</strong>，因为这样可以在不同的训练子集上对不同的模型有明显的影响来使得目标函数有持续的波动性，理想情况下整个训练过程就类似于使用<a href="https://zh.wikipedia.org/wiki/Bagging%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">bagging</a>来训练集成的模型（带有参数共享的约束）。</li><li>SGD<br>更新时一般会使用更小的步长，来使得目标函数平滑的下降。</li></ul><p>对于深度网络模型，dropout只能作为模型平均的一种近似，显式的设计模型来最小化这种近似误差也可以提高dropout的性能。</p><hr><h2><span id="13-回顾droupt">1.3. 回顾droupt</span></h2><p>在给定输入向量$v$后，输出预测向量$y$，该构成包含了一系列的隐含层$h=\{h^{(1)},…,h^{(L)}\}$。<br>Dropout训练一组由包含$v$和$h$中变量的子集组成的所有模型组成的模型。使用同一组参数$\theta$来标识一组分组$p(y | v ; \theta, \mu)$，其中$\mu \in M$是一个二进制掩码，用来决定模型中哪些变量参与运算。<br>每次在训练集上进行训练时，我们都按照$\log p(y | v ; \theta, \mu)$的梯度对不同的$\mu$随机取样训练不同的子模型。<br>可以通过$v$和$h$和掩码的按元素相乘得到不同子模型$p(y | v ; \theta, \mu)$的实例</p><p>当集合需要将所有子模型的预测平均起来进行预测时，函数形式就变得非常重要。<br>多个指数模型的预测平均值可以简单的通过运行权重除以2的完整模型来得到。即当$p(y|v;\theta) = softmax(v^Tw+b)$时，通过重整$p(y|v;\theta,\mu)$的几何平均定义的预测分布，可以很简单的由$softmax(v^tw/2+b)$</p><p>dropout与bagging</p><ul><li>都是在不同子集上训练出不同模型</li><li>dropout只训练一次，且所有模型共享参数。像是在训练一个模型集合而不是训练单个模型，每次的更新都必须有重大的影响，这样才能使得该子模型能较好的拟合当前的输入$v$</li><li>bagging对子模型的输出进行算数平均，dropout是几何平均</li></ul><hr><h2><span id="14-模型maxout描述">1.4. 模型maxout描述</span></h2><ul><li>是一个简单的前馈框架模型</li><li>使用了一个新的激活函数：<strong>maxout unit</strong><br>给定一个输入$ x \in \mathbb{R}^d$ （$x$可能是输入$v$,也可能是隐含层的状态），maxout隐含层的采用下式实现：<script type="math/tex; mode=display">h_{i}(x)=\max _{j \in[1, k]} z_{i j}</script>其中$z_{i j}=x^{T} W_{\ldots i j}+b_{i j}$，$x \in \mathbb{R}^{d \times n}$，$W \in \mathbb{R}^{d \times m \times k}$, $b \in \mathbb{R}^{m \times k}$。$w$，$b$都是可训练参数。$k$表示每个隐藏节点对应k个“隐隐层”节点，这$k$个“隐隐层”节点都是线性输出。maxout的每个节点就从这k个“隐隐层”节点输出值中取最大的。所以使得maxout为一种非线性的变换</li></ul><p><strong>Notes</strong></p><ul><li>maxout因为有参数同时为非线性，所以既可以是网络也可以是激活器</li><li>单个maxout单元可以解释为对任意凸函数进行线性逼近。（任意的凸函数都可由分段线性函数来拟合）。它在每处都是局部线性的（k个“隐隐层”节点都是线性的，取其最大值则为局部线性，分段的个数与k值有关），而一般的激活函数都有明显的曲率。<br><img src="https://image.zkhweb.top/20200206171729.png" alt="20200206171729.png"></li><li>如同MLP一样，maxout网络也可以拟合任意连续函数。只要maxout单元含有任意多个“隐隐层”节点，那么只要两个隐层的maxout网络就可以实现任意连续函数的近似。</li><li>maxout网络不仅可以学习到隐层之间的关系，还可以学习到每个隐层单元的激活函数。</li><li>maxout放弃了传统激活函数的设计，它产生的表示不再是稀疏的，但是它的梯度是稀疏的，且dropout可以将它稀疏化。</li><li>maxout没有上下界，所以让它在某一端饱和是零概率事件。</li><li>如果训练时使用dropout，则dropout操作在矩阵相乘之前，而并不对max操作的输入执行dropout。</li><li>使用maxout会默认一个先验：样本集是凸集可分的。</li></ul><hr><h2><span id="15-maxout是一个通用的近似器">1.5. Maxout是一个通用的近似器</span></h2><p><img src="https://image.zkhweb.top/20200206165136.png" alt="20200206165136.png"></p><p><strong>命题1</strong>：对于任意的正整数$m$,$n$,都存在两组$n+1$维的实数参数向量$[W_{1j}, b_{1j}], j \in [1, k]$和$[W_{2j}, b_{2j}], j \in [1, k]$使得<script type="math/tex">g(v) = h_1(v) - h_(v)</script> 即任意的分段连续函数都可以使用两个凸分段线性函数的差来表示。</p><p><strong>命题2</strong>：根据Stone-Weierstrass近似定理，令$C$属于<a href="https://zh.wikipedia.org/wiki/%E7%B4%A7%E7%A9%BA%E9%97%B4" target="_blank" rel="noopener">紧空间(compact domain)</a>$C \subset \mathbb{R}^{n}$, 函数$f: C \rightarrow \mathbb{R}$是一个连续函数，一个正实数$\epsilon&gt;0$。存在分段线性函数(PWL function)$g$，使得$v \in C,|f(v)-g(v)|&lt;\epsilon$(取决于$\epsilon$)</p><p><strong>命题3</strong>：万能近似理论：任何连续函数$f$，在紧空间上都可以使用具有两个maxout单元的maxout网络近似。</p><p><strong>证明</strong>：</p><ul><li>命题2，一个分段线性函数可以尽可能近似（取决于$\epsilon$）一个连续函数；</li><li>命题1，一个分段线性函数的表示正好和一个maxout网络完全匹配，该maxout网络具有两个maxout单元$h_1(v)$和$h_2(v)$，且k足够大的，可以达到所需的近似程度$ \epsilon$。</li><li>综上所述，我们可以得出结论：一个具有两个maxout单元的maxout网络可以任意程度的逼近任何一个紧空间内的连续函数$f(v)$。通常情况下，近似程度越大（即$\epsilon \rightarrow 0$），k越大（即$ k \rightarrow \infty$）。</li></ul><hr><h2><span id="16-maxout与relu">1.6. maxout与relu</span></h2><p>relu表达式$h_{i}(x)=\operatorname{relu}\left(x^{T} W_{\cdots i}+b_{i}\right)=\max \left(x^{T} W_{\cdots i}+b_{i}, 0\right)$<br>maxout表达式$h_{i}(x)=\max _{j \in[1, k]}\left(x^{T} W \ldots i j+b_{i j}\right)$</p><p>唯一区别</p><ul><li>relu使用的max(x,0)是对隐层每一个单元执行的与0比较最大化操作</li><li>maxout是对$k$个“隐隐层”单元的值执行最大化操作(k为最大池化步长,max pooling stride。一般最大池化步长与k相等，如果步长小，则会有重叠最大池化)<br>（<strong>一种实现方式</strong>2-4-1，maxout是对5个“隐隐层”单元的值执行最大化操作。如果将“隐隐层”单元在隐层展开，那么隐层就有20个“隐隐层”单元，maxout做的就是在这20个中每5个取一个最大值作为最后的隐层单元，最后的隐层单元仍然为4个。实现的时候，可以将隐层单元数设置为20个，权重维度（2，20）偏置维度（1，20），然后在20个中每5个取一个最大值得到4个隐层单元。）</li></ul><hr><h2><span id="17-模型平均">1.7. 模型平均</span></h2><ul><li>单层softmax有对模型进行平均的能力，但是通过观察，多层模型中使用dropout也存在这样的模型平均，只是有拟合精度的问题。</li><li>训练中使用dropout使得maxout单元有了更大的输入附近的线性区域，因为每个子模型都要预测输出，每个maxout单元就要学习输出相同的预测而不管哪些输入被丢弃。改变dropout mask将经常明显移动有效输入，从而决定了输入被映射到分段线性函数的哪一段。使用dropout训练的maxout具有一种特性，即当dropout mask改变时每个maxout单元的最大化滤波器相对很少变化。</li><li><strong>maxout网络中的线性和最大化操作可以让dropout的拟合模型平均的精度很高</strong>。而一般的激活函数几乎处处都是弯曲的，因而dropout的拟合模型平均的精度不高。</li></ul><hr><h2><span id="18-优化">1.8. 优化</span></h2><ul><li>训练中使用dropout时，maxout的优化性能比relu+max pooling好</li><li>dropout使用更大的步长最有效，使得目标函数有持续的波动性。而一般的SGD会使用更小的步长，来使得目标函数平滑的下降。dropout快速的探索着许多不同的方向然后拒绝那些损害性能的方向，而SGD缓慢而平稳的朝向最可能的方向移动。</li><li>实验中SGD使得relu饱和在0值的时间少于5%，而dropout则超过60%。由于relu激活函数中的0值是一个常数，这就会阻止梯度在这些单元上传播（无论正向还是反向），这也就使得这些单元很难再次激活，这会导致很多单元由激活转变为非激活。而maxout就不会存在这样的问题，梯度在maxout单元上总是能够传播，即使maxout出现了0值，但是这些0值是参数的函数可以被改变，从而maxout单元总是激活的。单元中较高比例的且不易改变的0值会损害优化性能。</li><li>dropout要求梯度随着dropout mask的改变而明显改变，而一旦梯度几乎不随着dropout mask的改变而改变时，dropout就简化成为了SGD。relu网络的低层部分会有梯度衰减的问题（梯度的方差在高层较大而反向传播到低层后较小）。maxout更好的将变化的信息反向传播到低层并帮助dropout以类似bagging的方式训练低层参数。relu则由于饱和使得梯度损失，导致dropout在低层的训练类似于一般的SGD。</li></ul><hr><h2><span id="19-参考资料">1.9. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1302.4389" target="_blank" rel="noopener">Paper—-Maxout Networks</a><br><a href="https://blog.csdn.net/zhufenghao/article/details/52527047" target="_blank" rel="noopener">CSD—-Maxout Networks</a><br><a href="https://blog.csdn.net/maqian5/article/details/91880468" target="_blank" rel="noopener">CSDN—-论文笔记_Maxout Networks</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-maxout-networks&quot;&gt;1. Maxout Networks&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#11-摘要&quot;&gt;1.1. 摘要&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#12-介绍&quot;&gt;1.2
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>CGAN:Conditional Generative Adversarial Nets阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/07/2014-Conditional-Generative-Adversarial-Nets%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/07/2014-Conditional-Generative-Adversarial-Nets阅读笔记/</id>
    <published>2020-02-07T03:14:42.000Z</published>
    <updated>2020-02-12T15:20:50.050Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-conditional-generative-adversarial-nets">1. Conditional Generative Adversarial Nets</a><ul><li><a href="#11-摘要">1.1. 摘要</a></li><li><a href="#12-介绍">1.2. 介绍</a></li><li><a href="#13-条件对抗网络">1.3. 条件对抗网络</a><ul><li><a href="#131-符号定义">1.3.1. 符号定义</a></li><li><a href="#132-知识回顾生成对抗网络">1.3.2. 知识回顾——生成对抗网络</a></li><li><a href="#133-直观感受">1.3.3. 直观感受</a></li><li><a href="#134-目标函数">1.3.4. 目标函数</a></li><li><a href="#135-对抗">1.3.5. 对抗</a></li></ul></li><li><a href="#14-实验">1.4. 实验</a><ul><li><a href="#141-单模式mnist">1.4.1. 单模式——MNIST</a></li><li><a href="#142-多模式mir-flickr">1.4.2. 多模式——MIR Flickr</a></li></ul></li><li><a href="#15-参考资料">1.5. 参考资料</a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-conditional-generative-adversarial-nets">1. Conditional Generative Adversarial Nets</span></h1><blockquote><p>arXiv:1411.1784 [cs.LG]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-摘要">1.1. 摘要</span></h2><p>在GAN的基础上引入标签y，同时使用在生成器和判别器中.<br>可以应用于<a href="https://www.jiqizhixin.com/graph/technologies/4468592f-93e9-4575-be91-fd64c0c6afe0" target="_blank" rel="noopener">多模态模型</a>中。</p><hr><h2><span id="12-介绍">1.2. 介绍</span></h2><p>生成对抗网络</p><ul><li>规避了棘手的概率计算</li><li>不需要使用马尔科夫链，仅使用反向传播算法去获得梯度</li><li>训练时不需要推断，可以轻松的将各种因素和相互作用纳入模型</li></ul><p>但<strong>无条件生成模型无法控制生成的数据</strong>，给模型加入附加信息可以知道数据的生成</p><hr><h2><span id="13-条件对抗网络">1.3. 条件对抗网络</span></h2><h3><span id="131-符号定义">1.3.1. 符号定义</span></h3><p>$x$ $\rightarrow$ 真实数据<br>$y$ $\rightarrow$ 标签（辅助信息）<br>$z$ $\rightarrow$ 噪音（生成器的输入数据）<br>$p_x$ $\rightarrow$ 真实数据的分布<br>$p_{z}(z)$ $\rightarrow$ 原始噪音数据的分布<br>$p_g$ $\rightarrow$ 经过生成器后数据的分布<br>$G()$ $\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\theta_{g}$<br>$D()$ $\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\theta_{d}$<br>$G(z;\theta_{g})$ $\rightarrow$ 将噪音$z$映射到新的数据空间<br>$D(x ; \theta_{d})$ $\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）</p><h3><span id="132-知识回顾生成对抗网络">1.3.2. 知识回顾——生成对抗网络</span></h3><p>生成器G，判别器D，相互对抗使目标函数，达到最优。</p><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]</script><h3><span id="133-直观感受">1.3.3. 直观感受</span></h3><p><img src="https://image.zkhweb.top/20200205211839.png" alt="20200205211839.png"></p><h3><span id="134-目标函数">1.3.4. 目标函数</span></h3><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x|y)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z|y)))]</script><p>和原始GAN相近，只是G，D在y的条件下生成或判别</p><h3><span id="135-对抗">1.3.5. 对抗</span></h3><p>生成器G通过z，y联合生成图片<br>判别器D在y的条件下判别G(z)<br>主要是在y条件下的MinMax Game</p><hr><h2><span id="14-实验">1.4. 实验</span></h2><h3><span id="141-单模式mnist">1.4.1. 单模式——MNIST</span></h3><h3><span id="142-多模式mir-flickr">1.4.2. 多模式——MIR Flickr</span></h3><hr><h2><span id="15-参考资料">1.5. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1411.1784" target="_blank" rel="noopener">Paper—-Conditional Generative Adversarial Nets</a><br><a href="https://zhuanlan.zhihu.com/p/23648795" target="_blank" rel="noopener">知乎—-《Conditional Generative Adversarial Nets》阅读笔记</a><br><a href="https://blog.csdn.net/Chaolei3/article/details/78870858" target="_blank" rel="noopener">CSDN—-Conditional Generative Adversarial Nets论文翻译</a><br><a href="https://blog.csdn.net/wspba/article/details/54666907" target="_blank" rel="noopener">CSDN—-Conditional Generative Adversarial Nets论文笔记</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-conditional-generative-adversarial-nets&quot;&gt;1. Conditional Generative Adversarial Nets&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>GAN:Generative Adversarial Nets阅读笔记</title>
    <link href="http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.zkhweb.top/2020/02/05/2014-Generative-Adversarial-Networks阅读笔记/</id>
    <published>2020-02-05T03:14:42.000Z</published>
    <updated>2020-02-12T15:20:54.936Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#1-generative-adversarial-nets">1. Generative Adversarial Nets</a><ul><li><a href="#11-摘要">1.1. 摘要</a></li><li><a href="#12-介绍">1.2. 介绍</a></li><li><a href="#13-对抗网络">1.3. 对抗网络</a><ul><li><a href="#131-符号定义">1.3.1. 符号定义</a></li><li><a href="#132-极大似然估计">1.3.2. 极大似然估计</a></li><li><a href="#133-目标函数">1.3.3. 目标函数</a></li><li><a href="#134-对抗">1.3.4. 对抗</a></li><li><a href="#135-loss-function">1.3.5. Loss Function</a></li><li><a href="#136-具体算法过程">1.3.6. 具体算法过程</a></li></ul></li><li><a href="#14-改进">1.4. 改进</a><ul><li><a href="#141-g替代版的loss-function">1.4.1. G替代版的Loss Function</a></li></ul></li><li><a href="#15-补充知识">1.5. 补充知识</a><ul><li><a href="#151-信息量">1.5.1. 信息量</a></li><li><a href="#152-信息熵">1.5.2. 信息熵</a></li><li><a href="#153-交叉熵">1.5.3. 交叉熵</a></li><li><a href="#154-kl散度kullbackleibler散度相对熵">1.5.4. KL散度(Kullback–Leibler散度，相对熵)</a></li><li><a href="#155-js散度jensen-shannon散度">1.5.5. JS散度(Jensen-Shannon散度)</a></li></ul></li><li><a href="#16-理论结果">1.6. 理论结果</a><ul><li><a href="#161-最优判别器ddx-fracp_text-dataxp_text-dataxp_gx">1.6.1. 最优判别器D：$D^{*}(x) =\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}$</a></li><li><a href="#162-最优生成器p_gp_text-data">1.6.2. 最优生成器：$p_{g}=p_{\text {data }}$</a></li><li><a href="#163-定理1全局最优">1.6.3. 定理1：全局最优</a></li><li><a href="#164-算法的收敛性">1.6.4. 算法的收敛性</a></li></ul></li><li><a href="#17-优势和劣势">1.7. 优势和劣势</a><ul><li><a href="#171-优势">1.7.1. 优势</a></li><li><a href="#172-劣势">1.7.2. 劣势</a></li></ul></li><li><a href="#18-结论和未来研究方向">1.8. 结论和未来研究方向</a></li><li><a href="#19-参考资料">1.9. 参考资料</a></li></ul></li></ul><!-- tocstop --><hr><h1><span id="1-generative-adversarial-nets">1. Generative Adversarial Nets</span></h1><blockquote><p>arXiv:1406.2661 [stat.ML]<br>tensorflow2代码：<a href="https://github.com/zhangkaihua88/ML_Paper" target="_blank" rel="noopener">https://github.com/zhangkaihua88/ML_Paper</a></p></blockquote><hr><h2><span id="11-摘要">1.1. 摘要</span></h2><p>通过对抗过程估计生成模型的框架，同时训练两个模型：<br><strong>生成模型G</strong>用来获取数据分布<br><strong>判别模型D</strong>估计样本来自训练数据而不是G的概率<br>G的训练目标是为了最大化D产生错误的概率<br>在任意函数G和D的空间中存在唯一的解，其中G恢复训练数据分布，并且D处处都等于$\frac{1}{2}$。</p><hr><h2><span id="12-介绍">1.2. 介绍</span></h2><p>最成功的的模型之一就是<strong>判别式模型</strong><br>通常它们将高维丰富的感知器输入映射到类标签上。<br>主要是<strong>基于反向传播和丢弃算法</strong>来实现的，特别是具有特别良好梯度的分段线性单元。</p><p>对抗网络</p><ol><li>生成模型通过将随机噪声传输到多层感知机来生成样本的特例</li><li>判别模型通过多层感知机去判别一个样本是来自模型分布还是数据分布</li><li>生成模型和判别模型互相对抗</li></ol><p>可以仅使用非常成熟的反向传播和丢弃算法训练两个模型，生成模型在生成样本时只使用前向传播算法。并且不需要近似推理和马尔可夫链作为前提。</p><hr><h2><span id="13-对抗网络">1.3. 对抗网络</span></h2><p>对抗模型框架是最直接的应用是多层感知机</p><h3><span id="131-符号定义">1.3.1. 符号定义</span></h3><p>$x$ $\rightarrow$ 真实数据<br>$z$ $\rightarrow$ 噪音（生成器的输入数据）<br>$p_x$ $\rightarrow$ 真实数据的分布<br>$p_{z}(z)$ $\rightarrow$ 原始噪音数据的分布<br>$p_g$ $\rightarrow$ 经过生成器后数据的分布<br>$G()$ $\rightarrow$ 生成映射函数（可微），结构为多层感知机，参数$\theta_{g}$<br>$D()$ $\rightarrow$ 判别映射函数（可微），结构为多层感知机，参数$\theta_{d}$<br>$G(z;\theta_{g})$ $\rightarrow$ 将噪音$z$映射到新的数据空间<br>$D(x ; \theta_{d})$ $\rightarrow$ $x$来自真实数据而不是生成数据的概率（真=1，假=0）</p><h3><span id="132-极大似然估计">1.3.2. 极大似然估计</span></h3><p>对于真实数据$x$和生成数据$G(z)$，经过判别器判别后的，$D$认为$x$是真样本的概率为$D(x)$，$D$认为$G(z)$是假样本的概率为$1-D(G(z))$，那么对于$D$有$log$似然函数为：</p><script type="math/tex; mode=display">L=log[D(x)*(1-D(G(z)))] \tag{1}</script><h3><span id="133-目标函数">1.3.3. 目标函数</span></h3><script type="math/tex; mode=display">\min _{G}\max _{ D } V(D,G)={ \mathbb{E} }_{ x ～ { p }_  { data } (x) }[logD(x)] + { \mathbb{E} }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] \tag{2}</script><p>$D(x)$和$D(G(z))$分别表示$x$和$G(z)$经过判别器$D$的判别后，$D$认为输入样本是真样本的概率，则$1-D(G(z))$表示$D$将假样本判断为假的概率；那么，真实的概率分布与$D$判断出来的情况列表如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">$D$</th><th style="text-align:center">$D$将真样本$x$判断为真的概率:$D(x)$</th><th style="text-align:center">$D$将假样本$G(z)$判断为假的概率:$1-D(G(z))$</th></tr></thead><tbody><tr><td style="text-align:center">真实情况</td><td style="text-align:center">真样本$x$为真的概率:1</td><td style="text-align:center">假样本$G(z)$为假的概率:1</td></tr><tr><td style="text-align:center">用交叉熵作为目标函数</td><td style="text-align:center">$1*log[D(x)]对应第一项$</td><td style="text-align:center">$1*log[1-D(G(z))]$对应第二项</td></tr></tbody></table></div><p><strong>Note:$D$输出的是概率，那么$D$的输出层的激活函数必须是$sigmoid$</strong></p><h3><span id="134-对抗">1.3.4. 对抗</span></h3><p>判别器$D$的目标</p><ol><li>要尽可能把真的样本判断为真，对应最大化第一项：${ E }_{ x ～ { p }_  { data } (x) }[logD(x)]$</li><li>把假的样本判断为假，对应最大化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $</li></ol><ul><li>总之，也就是说<strong>判别器$D$要最大化目标函数</strong>；</li></ul><p>生成器$G$的目标</p><ol><li>要尽可能的让$D$将生成的假样本判断为真，对应最小化第二项：${ E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))] $</li></ol><ul><li>总之，也就是说<strong>生成器$G$要最小化目标函数</strong>；</li></ul><p>总的来说，这是一个<strong>MinMax Game</strong>；<br><strong>Note:实际训练当中，训练$G$的时候$D$的参数是固定的，$G$并不干扰$D$对真实数据的判断，$G$需要$D$的正确引导，$G$只是不断提升自己生成数据的能力。</strong></p><h3><span id="135-loss-function">1.3.5. Loss Function</span></h3><p>$D$的损失函数（最小化）：</p><script type="math/tex; mode=display">Loss_D = -[1*logD(x) + 1*log(1-D(G(z)))] \tag{3}</script><p>$G$的损失函数（最小化）：</p><script type="math/tex; mode=display">Loss_G = 0*logD(x) + 1*log(1-D(G(z)))=log(1-D(G(z))) \tag{4}</script><h3><span id="136-具体算法过程">1.3.6. 具体算法过程</span></h3><p><img src="https://image.zkhweb.top/20190816181118.png" alt="20190816181118.png"></p><p>Note：</p><ol><li>生成对抗网络的minibatch随机梯度下降训练 </li><li>先更新$D$，再更新$G$，只有$D$有了正确的判断能力，$G$才能按照$D$的指示来更新;</li><li>可以设置一个超参数k来协调$D$、$G$两者之间更新的次数比例，在实验中k=1，使消耗最小;</li><li>在训练$G$的时候$D$的参数要固定，在训练$D$的时候$G$的参数要固定;</li></ol><hr><h2><span id="14-改进">1.4. 改进</span></h2><h3><span id="141-g替代版的loss-function">1.4.1. G替代版的Loss Function</span></h3><p>由于$G(z)$是从噪声中生成的样本，所以在最开始$G$生成的样本非常假，很容易被$D$抓出来，也就是说$D(G(z))$非常小,那么$Loss_G = log(1-D(G(z)))$就非常接近0，在反向传播的时候就不能够传播足够的梯度给$G$来更新参数，所以我们从Heuristic的角度来理解：我们本身是要最小化$D$抓出来假样本的概率，现在我们可以换成最大化$D$抓不出来的概率（$\log D(G(z))$），也就是将$G$的损失函数换成：</p><script type="math/tex; mode=display">Loss_G=-logD(G(z))</script><p>由于$D$是按照：</p><script type="math/tex; mode=display">Loss_G = log(1-D(G(z)))</script><p>训练的，那么如果损失函数更换，这两项不是等价的，所以$D$给出的值就能够提供足够的梯度。</p><p><strong>Note:<br>$Loss_G =log(1-D(G(z)))$对应的GAN叫做MMGAN<br>$Loss_G=-logD(G(z)) $对应的GAN叫做NSGAN<br>改进后的仍然存在些许问题，见与<a href="#1">定理1：全局最优的Note3</a></strong></p><p>从函数图像上，可以直观的看出，两种损失函数的梯度变化趋势：<br><img src="https://image.zkhweb.top/损失函数图像" alt="损失函数图像"></p><hr><h2><span id="15-补充知识">1.5. 补充知识</span></h2><h3><span id="151-信息量">1.5.1. 信息量</span></h3><p>$ I(x) = -\log {p(x)} = \log { \frac { 1}{ p (x) }  } $<br>一个事件发生的概率越大，这件事情发生所包含的信息量就越小，比如说一个高富帅追求一个白富美，追到手了没有什么稀奇的，因为这是一件概率很高的事情，但是如果一个矮穷矬追求一个白富美，追到手了，这种事情发生的概率很低，其中一定有其他的原因：比如这个矮穷矬救过白富美的命或者这个矮穷矬器大活好不黏人，所以概率低的事情发生所包含的信息量大；两个相互独立的事情同时发生的信息量是两者单独发生的信息量之和。</p><h3><span id="152-信息熵">1.5.2. 信息熵</span></h3><p>信息量的均值</p><script type="math/tex; mode=display">H(x) = - \sum _{ x } p(x)log p(x)</script><h3><span id="153-交叉熵">1.5.3. 交叉熵</span></h3><script type="math/tex; mode=display">H(P, Q) = - \sum _{ x } p(x)log q(x)</script><p>用估计编码$q(x)$近似真实编码$p(x)$需要的平均编码长度</p><h3><span id="154-kl散度kullbackleibler散度相对熵">1.5.4. KL散度(Kullback–Leibler散度，相对熵)</span></h3><p>统计中的一个概念，时衡量两种概率分布的相似程度，其越小，表示两种概率分布越接近。（当P(x)和Q(x)的相似度越高，KL散度越小）<br>对于离散的概率分布定义如下：</p><script type="math/tex; mode=display">D_{KL}(P||Q)=- \sum _{ x } p(x)log q(x) + \sum _{ x } p(x)log p(x) =H(P, Q)-H(P)</script><p>对于连续的概率分布定义如下：</p><script type="math/tex; mode=display">D_{K L}(P \| Q)=\int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} d x</script><p>想要将一个随机高斯噪声$z$通过一个生成网络G得到一个和</p><ul><li>性质：<ol><li>不对称性<br>尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即$D(P||Q) \not= D(Q||P)$。</li><li>非负性<br>相对熵的值是非负值，即$D(P||Q)&gt;0$。</li></ol></li></ul><h3><span id="155-js散度jensen-shannon散度">1.5.5. JS散度(Jensen-Shannon散度)</span></h3><script type="math/tex; mode=display">D_{JS}(P||Q)={\frac{1}{2}} KL(P||M) + {\frac{1}{2}} KL(Q||M) \quad \quad M = {\frac{1}{2}}(P+Q)</script><ul><li>不同于KL主要又两方面：<ol><li>值域范围<br>JS散度的值域范围是[0,1]，相同则是0，相反为1。相较于KL，对相似度的判别更确切了。</li><li>对称性<br>即 JS(P||Q)=JS(Q||P)，从数学表达式中就可以看出。</li></ol></li></ul><hr><h2><span id="16-理论结果">1.6. 理论结果</span></h2><h3><span id="161-最优判别器ddx-fracp_text-dataxp_text-dataxp_gx">1.6.1. 最优判别器D：$D^{*}(x) =\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}$</span></h3><p>对于给定生成器G，最大化$V(D,G)$而得出最优判别器D。原论文中价值函数可写为在$x$上的积分，即将数学期望展开为积分形式：</p><script type="math/tex; mode=display">\begin{aligned}\max _{ D } V(D,G)&={ E }_{ x ～ { p }_  { data } (x) }[logD(x)] + { E }_{ z ～ { p }_{ z }(z) }[log(1-D(G(z)))]\\&=\int_{x} p_{d a t a}(x) \log D(x) \mathrm{d} x+\int_{z} p(z) \log (1-D(G(z))) \mathrm{d} z\\&=\int_{x} p_{d a t a}(x) \log D(x)+p_{G}(x) \log (1-D(x)) \mathrm{d} x\end{aligned}</script><p>取函数，求偏导数<br>（对于任意的$(a, b) \in \mathbb{R}^{2} \backslash\{0,0\}$,函数$y \rightarrow a \log (y)+b \log (1-y)$在$[0,1]$中的$\frac{a}{a+b}$处达到最大值）</p><script type="math/tex; mode=display">\begin{aligned}f(D) &=a \log (D)+b \log (1-D) \\\frac{d f(D)}{d D}&= a \times \frac{1}{D}+b \times \frac{1}{1-D} \times(-1)=0 \\a \times \frac{1}{D^{*}} &= b \times \frac{1}{1-D^{*}} \\\Leftrightarrow a \times & (1-D^{*}) =b \times D^{*} & \\\text{得到最优判别器}&{ D }^{ * }(x)：\\D^{*}(x) &=\frac{P_{\text {data}}(x)}{P_{\text {data}}(x)+P_{G}(x)}\end{aligned}</script><h3><span id="162-最优生成器p_gp_text-data">1.6.2. 最优生成器：$p_{g}=p_{\text {data }}$</span></h3><p>我们知道对于$G$来说，最好的$G$是让：</p><script type="math/tex; mode=display">{ P }_{ r }(x) = { P }_{ g }(x)</script><p>此时，有：</p><script type="math/tex; mode=display">{ D }^{ * }(x)=1/2</script><p>也就是说最好的生成器使最好的判别器无法判别出来样本是生成样本还是真实样本。</p><h3><span id="163-定理1全局最优">1.6.3. 定理1：全局最优</span></h3><p><strong>定理1：当且仅当$p_{g}=p_{\text {data }}$时，$C(G)$达到全局最小。此时，$C(G)$的值为$−log4$。</strong><br>注意到，判别器$D$的训练目标可以看作为条件概率$P(Y=y | x)$的最大似然估计，当$y=1$时，x来自于$p_{\text {data }}$；当$y=0$时，$x$来自$p_{g}$。公式1中的极小化极大问题可以变形为： </p><script type="math/tex; mode=display">\begin{aligned} C(G) &=\max _{D} V(G, D) \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}}\left[\log \left(1-D_{G}^{*}(G(\boldsymbol{z}))\right)\right] \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right] \\ &=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log \frac{p_{\text {data }}(\boldsymbol{x})}{P_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \frac{p_{g}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right] \\ &=\int_{x} p_{\text {data}}(x) \log \left(\frac{p_{\text {data}}(x)}{p_{\text {data}}(x)+p_{g}(x)}\right)+p_{g}(x) \log \left(\frac{p_{g}(x)}{p_{\text {data}}(x)+p_{g}(x)}\right) d x\\&=\int_{x} p_{d a t a}(x) \log \left(\frac{p_{d a t a}(x)}{\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\right)+p_{g}(x) \log \left(\frac{p_{g}(x)}{\frac{p_{d a t a}(x)+p_{g}(x)}{2}}\right) d x-\log (4)\\&=\underbrace{K L\left(p_{\text {data}}(x) \| \frac{p_{\text {data}}(x)+p_{g}(x)}{2}\right)}_{\geq 0}+\underbrace{K L\left(p_{g}(x) \| \frac{p_{\text {data}}(x)+p_{g}(x)}{2}\right)}_{\geq 0}-\log (4)\\&=2\underbrace{\cdot JSD(p_{data}\|p_{g})}_{\geq 0}-log(4)\\\min _{G} C(G)&=0+0-\log (4)=-\log (4)\end{aligned}</script><p>当且仅当$p_{\text {data}}(x)=\frac{p_{\text {data}}(x)+p_{g}(x)}{2}$即$p_{g}=p_{\text {data }}$时成立，此时$C(G)$达到全局最小，$C(G)$的值为$−log4$。<br><strong>Note1</strong><br>$KL$散度：$KL({ P }_{ 1 }||{ P }_{ 2 })={ P }_{ 1 }\log { \frac { { P }_{ 1 } }{ { P }_{ 2 } }  } $<br>$JS$散度：$ JS({ P }_{ 1 }||{ P }_{ 2 })=\frac { 1 }{ 2 } KL({ P }_{ 1 }||\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } )+\frac { 1 }{ 2 } KL({ P }_{ 2 }||\frac { { P }_{ 1 }+{ P }_{ 2 } }{ 2 } ) $<br><strong>Note2（MMGAN）</strong>$Loss_G =log(1-D(G(z)))$<br>当判别器$D$最优的时候，生成器$G$是在减小真实分布与生成分布之间的$JS$散度<br><strong><span id="1">Note3（NSGAN）</span></strong>$Loss_G=-logD(G(z)) $ </p><script type="math/tex; mode=display">\begin{aligned}KL({ P }_{ g }(x)||{ P }_{ r }(x))&={ P }_{ g }(x)*\log { \frac { { P }_{ g }(x) }{ { P }_{ r }(x) }  } \\ &={ P }_{ g }(x)*\log { \frac { { P }_{ g }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }{ { P }_{ r }(x)/({ P }_{ r }(x)+{ P }_{ g }(x)) }  } \\ &={ P }_{ g }(x)*\log  \frac { 1-D^{ * }(x) }{ D^{ * }(x) } \\ &={ P }_{ g }(x)log[1-D^{ * }(x)]-{ P }_{ g }(x)logD^{ * }(x)\\-{P}_{g}(x)*logD^*(x)&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\Loss_{ G }&=KL({ P }_{ g }(x)||{ P }_{ r }(x))-{ P }_{ g }(x)log[1-D^{ * }(x)]\\\because {P}_{r}(x)*log[D^*(x)] &+ {P}_{g}(x)*log[1-D^*(x)]=2JS({ P }_{ r }||{ P }_{ g })-2log2\\\therefore Loss_{ G }=KL({ P }_{ g }(&x)||{ P }_{ r }(x))-2JS({ P }_{ r }||{ P }_{ g })+{P}_{r}(x)*log[D^*(x)]+2log2[1-D^{ * }(x)]\end{aligned}</script><p><strong>从上面的式子可以看出KL散度和JS散度同时存在且方向相反，而JS散度和KL散度都是衡量两个分布距离的度量，且是单调性同步的函数，这样的话就会导致梯度的方向不稳定，一会儿上升一会儿下降，所以这个替代版的损失函数也不是一个好的选择。</strong></p><h3><span id="164-算法的收敛性">1.6.4. 算法的收敛性</span></h3><p>**命题：如果$G$和$D$有足够的性能，对于算法1中的每一步，给定$G$时，判别器能够达到它的最优，并且通过更新$p_g$来提高这个判别准则。 </p><script type="math/tex; mode=display">\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right]</script><p>则$p_g$收敛为$p_{data}$。**</p><!-- 证明.如上述准则，考虑$V(G, D)=U\left(p_{g}, D\right)$为关于$p_{g}$的函数。注意到$U\left(p_{g}, D\right)$为$p_g$的凸函数。该凸函数上确界的一次导数包括达到最大值处的该函数的导数。换句话说，如果$f(x)=\sup _{\alpha \in \mathcal{A}} f_{\alpha}(x)$且对于每一个$α$，$f_α(x)$ 是关于$x$的凸函数，那么如果$\beta=\operatorname{argsup}_{\alpha \in \mathcal{A}} f_{\alpha}(x)$，则$\partial f_{\beta}(x) \in \partial f$。这等价于给定对应的$G$和最优的$D$，计算$p_g$的梯度更新。如定理1所证明，$\sup _{D} U\left(p_{g}, D\right)$是关于$p_g$的凸函数且有唯一的全局最优解，因此，当$p_g$的更新足够小时，$p_g$收敛到$p_x$，证毕。 --><p><strong>Note</strong><br>优化$θ_g$而不是$p_g$本身</p><hr><h2><span id="17-优势和劣势">1.7. 优势和劣势</span></h2><h3><span id="171-优势">1.7.1. 优势</span></h3><ul><li>根据实际的结果，它们看上去可以比其它模型产生了更好的样本（图像更锐利、清晰）。</li><li>生成对抗式网络框架能训练任何一种生成器网络（理论上-实践中，用 REINFORCE 来训练带有离散输出的生成网络非常困难）。大部分其他的框架需要该生成器网络有一些特定的函数形式，比如输出层是高斯的。重要的是所有其他的框架需要生成器网络遍布非零质量（non-zero mass）。生成对抗式网络能学习可以仅在与数据接近的细流形（thin manifold）上生成点。</li><li>不需要设计遵循任何种类的因式分解的模型，任何生成器网络和任何鉴别器都会有用。</li><li>无需利用马尔科夫链反复采样，无需在学习过程中进行推断（Inference），回避了近似计算棘手的概率的难题。</li></ul><h3><span id="172-劣势">1.7.2. 劣势</span></h3><ul><li><p>解决不收敛（non-convergence）的问题。<br>目前面临的基本问题是：所有的理论都认为 GAN 应该在纳什均衡（Nash equilibrium）上有卓越的表现，但梯度下降只有在凸函数的情况下才能保证实现纳什均衡。当博弈双方都由神经网络表示时，在没有实际达到均衡的情况下，让它们永远保持对自己策略的调整是可能的【OpenAI Ian Goodfellow的Quora】。</p></li><li><p>难以训练：崩溃问题（collapse problem）<br>GAN模型被定义为极小极大问题，没有损失函数，在训练过程中很难区分是否正在取得进展。GAN的学习过程可能发生崩溃问题（collapse problem），生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。<a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">Improved Techniques for Training GANs</a></p></li><li><p>无需预先建模，模型过于自由不可控。<br>与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，即不需要formulate p(x)，而是使用一种分布直接进行采样sampling，从而真正达到理论上可以完全逼近真实数据，这也是GAN最大的优势。然而，这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了(超高维)。在GAN[Goodfellow Ian, Pouget-Abadie J] 中，每次学习参数的更新过程，被设为D更新k回，G才更新1回，也是出于类似的考虑。</p></li></ul><hr><h2><span id="18-结论和未来研究方向">1.8. 结论和未来研究方向</span></h2><p>该框架允许许多直接的扩展：</p><ul><li>条件生成模型$p(x | c)$可以通过将$c$作为$G$和$D$的输入来获得。</li><li>给定$x$，可以通过训练一个任意的模型来学习近似推理，以预测$z$。这和wake-sleep算法训练出的推理网络类似，但是它具有一个优势，就是在生成器训练完成后，这个推理网络可以针对固定的生成器进行训练。</li><li>能够用来近似模型所有的条件概率$p\left(\boldsymbol{x}_{S} | \boldsymbol{x}_{\beta}\right)$，其中$S$通过训练共享参数的条件模型簇的关于$x$索引的一个子集。本质上，可以使用生成对抗网络来随机拓展MP-DBM。</li><li>半监督学习：当标签数据有限时，判别网络或推理网络的特征不会提高分类器效果。</li><li>效率改善：为协调$G$和$D$设计更好的方法，或训练期间确定更好的分布来采样$z$，能够极大的加速训练。</li></ul><hr><h2><span id="19-参考资料">1.9. 参考资料</span></h2><p><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener">Paper—-Generative Adversarial Nets</a><br><a href="https://zhuanlan.zhihu.com/p/28853704" target="_blank" rel="noopener">知乎—-GAN入门理解及公式推导</a><br><a href="https://blog.csdn.net/stalbo/article/details/79283399" target="_blank" rel="noopener">CSDN—-GAN论文阅读——原始GAN（基本概念及理论推导）</a><br><a href="https://blog.csdn.net/FrankieHello/article/details/80614422" target="_blank" rel="noopener">CSDN—-KL散度、JS散度以及交叉熵对比</a><br><a href="https://blog.csdn.net/wspba/article/details/54582391" target="_blank" rel="noopener">CSDN—-Generative Adversarial Nets论文笔记+代码解析</a><br><a href="https://blog.csdn.net/wspba/article/details/54577236" target="_blank" rel="noopener">CSDN—-Generative Adversarial Nets（译）</a><br><a href="https://github.com/andyhujinzhao/Generative_Adversarial_Nets" target="_blank" rel="noopener">Github—-andyhujinzhao/Generative_Adversarial_Nets</a></p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-generative-adversarial-nets&quot;&gt;1. Generative Adversarial Nets&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#11-摘要&quot;&gt;1.1. 摘要&lt;/a&gt;&lt;/li&gt;

      
    
    </summary>
    
      <category term="深度学习论文阅读" scheme="http://www.zkhweb.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="深度学习" scheme="http://www.zkhweb.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文阅读" scheme="http://www.zkhweb.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>欢迎到我的博客= =（测试ing）</title>
    <link href="http://www.zkhweb.top/2019/06/02/%E6%AC%A2%E8%BF%8E%E5%88%B0%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2=%20=%EF%BC%88%E6%B5%8B%E8%AF%95ing%EF%BC%89/"/>
    <id>http://www.zkhweb.top/2019/06/02/欢迎到我的博客= =（测试ing）/</id>
    <published>2019-06-02T03:14:42.000Z</published>
    <updated>2019-06-05T05:02:16.045Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h2><span id="123">123</span></h2><h3><span id="352">352</span></h3><p>223s</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h2&gt;&lt;span id=&quot;123&quot;&gt;123&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span id=&quot;352&quot;&gt;352&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;223s&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="PS3" scheme="http://www.zkhweb.top/tags/PS3/"/>
    
      <category term="Games" scheme="http://www.zkhweb.top/tags/Games/"/>
    
  </entry>
  
</feed>
